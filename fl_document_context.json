{
  "fetch_timestamp": "2025-12-05T21:55:04.544996",
  "num_documents": 2,
  "task_name": "deep_research",
  "documents": [
    {
      "id": 1,
      "metadata": {
        "source": "arxiv_html",
        "paper_id": "2511.22616v1",
        "title": "Federated Learning Survey: A Multi-Level Taxonomy of Aggregation Techniques, Experimental Insights, and Future Frontiers",
        "authors": [
          "Meriem ARBAOUI",
          "Mohamed-el-Amine BRAHMIA",
          "Abdellatif RAHMOUN",
          "Mourad ZGHAL"
        ],
        "url": "https://arxiv.org/html/2511.22616v1",
        "abstract": "Abstract.The emerging integration of IoT (Internet of Things) and AI (Artificial Intelligence) has unlocked numerous opportunities for innovation across diverse industries. However, growing privacy concerns and data isolation issues have inhibited this promising advancement. Unfortunately, traditional centralized machine learning (ML) methods have demonstrated their limitations in addressing these hurdles. In response to this ever-evolving landscape, Federated Learning (FL) has surfaced as a cutting-edge machine learning paradigm, enabling collaborative training across decentralized devices. FL allows users to jointly construct AI models without sharing their local raw data, ensuring data privacy, network scalability, and minimal data transfer. One essential aspect of FL revolves around proficient knowledge aggregation within a heterogeneous environment. Yet, the inherent characteristics of FL have amplified the complexity of its practical implementation compared to centralized ML. This survey delves into three prominent clusters of FL research contributions: personalization, optimization, and robustness. The objective is to provide a well-structured and fine-grained classification scheme related to these research areas through a unique methodology for selecting related work. Unlike other survey papers, we employed a hybrid approach that amalgamates bibliometric analysis and systematic scrutinizing to find the most influential work in the literature. Therefore, we examine challenges and contemporary techniques related to heterogeneity, efficiency, security, and privacy. Another valuable asset of this study is its comprehensive coverage of FL aggregation strategies, encompassing architectural features, synchronization methods, and several federation motivations. To further enrich our investigation, we provide practical insights into evaluating novel FL proposals and conduct experiments to assess and compare aggregation methods under IID and non-IID data distributions. Finally, we present a compelling set of research avenues that call for further exploration to open up a treasure of advancement."
      },
      "content": "Title: Federated Learning Survey: A Multi-Level Taxonomy of Aggregation Techniques, Experimental Insights, and Future Frontiers\nAuthors: Meriem ARBAOUI, Mohamed-el-Amine BRAHMIA, Abdellatif RAHMOUN, Mourad ZGHAL\nAbstract:\nAbstract.The emerging integration of IoT (Internet of Things) and AI (Artificial Intelligence) has unlocked numerous opportunities for innovation across diverse industries. However, growing privacy concerns and data isolation issues have inhibited this promising advancement. Unfortunately, traditional centralized machine learning (ML) methods have demonstrated their limitations in addressing these hurdles. In response to this ever-evolving landscape, Federated Learning (FL) has surfaced as a cutting-edge machine learning paradigm, enabling collaborative training across decentralized devices. FL allows users to jointly construct AI models without sharing their local raw data, ensuring data privacy, network scalability, and minimal data transfer. One essential aspect of FL revolves around proficient knowledge aggregation within a heterogeneous environment. Yet, the inherent characteristics of FL have amplified the complexity of its practical implementation compared to centralized ML. This survey delves into three prominent clusters of FL research contributions: personalization, optimization, and robustness. The objective is to provide a well-structured and fine-grained classification scheme related to these research areas through a unique methodology for selecting related work. Unlike other survey papers, we employed a hybrid approach that amalgamates bibliometric analysis and systematic scrutinizing to find the most influential work in the literature. Therefore, we examine challenges and contemporary techniques related to heterogeneity, efficiency, security, and privacy. Another valuable asset of this study is its comprehensive coverage of FL aggregation strategies, encompassing architectural features, synchronization methods, and several federation motivations. To further enrich our investigation, we provide practical insights into evaluating novel FL proposals and conduct experiments to assess and compare aggregation methods under IID and non-IID data distributions. Finally, we present a compelling set of research avenues that call for further exploration to open up a treasure of advancement.\n\n\n================================================================================\n1.Introduction\n================================================================================\nIn today’s data-centric world, the widespread adoption of IoT devices has led to tremendous generated data, enabling access to intelligent and high-quality services. This wealth of data has fueled an unprecedented AI expansion across countless application domains. Specifically, it is essential to feed substantial amounts of data into Deep Learning (DL) models to achieve impressive accuracy results, paving the way for advanced services development(pandya2023federated). Historically, the storage and analysis of such massive data have been entrusted to the Cloud, owing to its immense capacities. However, the considerable drawbacks of centralized machine learning techniques, which rely on cloud-only-based solutions, have become evident in the face of sophisticated human needs.\n\nThe first limitation in this context stems from the undesirable processing latency introduced when offloading massive IoT data to remote servers, as the location of these data centers is typically far from data owners. As a result, this long-distance communication architecture incurs high computation costs(wahab2021federated). The second problem originates from the need for users to sacrifice their data privacy in exchange for improved AI services(imteaj2021survey). While data holders are increasingly becoming wary about sharing their data with third parties, regardless of their trustworthiness and reputation. This growing awareness has prompted organizations and governments to implement strict privacy regulations to safeguard data ownership and control.\n\nFor instance, within the European Commission’s General Data Protection Regulation (GDPR), articles 5 and 6 introduce two ethical concepts:data minimizationandpurpose limitation. The former stresses collecting only relevant and meaningful data for a study, while the latter restricts using collected data for future research purposes beyond its original intent. In order to comply with these legal legislations, researchers have employed pseudonymization or de-identification techniques, which involve removing identifiable details such as names, addresses, and social security numbers from collected datasets and replacing them with pseudonyms(pfitzner2021federated). Nonetheless, it is worth noting that these approaches may not provide absolute privacy protection. In some scenarios, re-identification mechanisms can potentially link the pseudonyms back to their associated entities, compromising the privacy of individuals(culnane2017health;rocher2019estimating).\n\nIn light of these concerns, federated learning emerges as an innovative solution to distribute the computational workload of training ML models across multiple nodes, while ensuring the data privacy of locally held data at each site(mcmahan2017communication). In other words, federated learning allows participating nodes to collaboratively train a robust AI model by harnessing the collective knowledge within their local data without uploading it to a remote server, as in centralized machine learning. In the typical FL setup, this paradigm operates with a central server that receives model weight updates from participating clients and aggregates them to create a global model, potentially enhancing performance.\n\nTo fully leverage the attractive benefits of FL in many application domains, it is essential to meet a set of requirements that we highlighted below so that the data holder will be encouraged to join this collaborative paradigm:\n\nAvailable high-quality data at each client:Data is the lifeblood of machine learning. Although each participating entity may independently decide how it collects, extracts, and organizes its data according to its environment and preferences, it is imperative to gather high-quality data and prepare them adequately to flourish the FL training procedure.\n\nComputation capacity at each client:Data alone is insufficient to fuel the FL process; power must accompany knowledge. To uncover the FL advantages, each client should participate in multiple communication rounds before achieving the desirable performance, whether it is a mobile device or a specialized company, and as such, a formidable computation capacity is mandatory, enabling each client to remain active in the long run.\n\nReliable communication between actors:The third vital necessity that underpins FL’s success is the establishment of reliable communication between the clients and the aggregator node. The exchange of local model updates and the global model weights, whether orchestrated through a central server or in a decentralized fashion, must occur with the utmost safety, security, and efficiency. Without such dependable communication channels, malicious actors could tamper with client models in transit or steal sensitive dataset information.\n\nReliable aggregation method:Careful contemplating of the algorithm that combines the knowledge harvested from individual clients during each communication round is indispensable to propel FL adoption worldwide. An aggregation method must not only be fair and reliable but also robust and capable of weaving together diverse insights despite the variations among clients.\n\nAs the FL landscape has witnessed a rapid evolution recently, active FL researchers are in constant pursuit of building the most efficient approaches to meet contemporary system requirements. By carefully assessing a range of evaluation metrics, they aim to ascertain the correctness and originality of their work. Usually, the new FL proposals effectively enhance one or more of the assessed metrics but lead to trade-offs that negatively impact the remaining ones. In our study, we intend to aid researchers in identifying the hot research topic in FL and ensure they are informed and up-to-date on the latest methods. For this aim, we present a high-level classification, as illustrated in Fig.1, that clusters these evaluation metrics into three research areas:optimization, personalization,androbustness. Additionally, our investigation will primarily focus on aggregation-based solutions (please refer to Section4) to elucidate recent advancements within each cluster. Simultaneously, we will explore relevant complementary techniques that may enhance the aggregation process.\nThe potential of aggregation as a solution area for addressing inherent challenges in Federated Learning is clear. Regardless, it’s crucial to note that only a minority of survey articles have given significant attention to tackling challenges and showcasing contributions from the federated learning aggregation vision.\n\nPersonalization.\n\nThis category concerns the ability of the FL model to accommodate the varied characteristics and requirements of individual clients, regardless of their heterogeneity. The heterogeneity in the FL ecosystem may manifest in manifold ways. For instance, we briefly distinguish two forms of heterogeneity:statisticalandsystemheterogeneity. The former deals with the different data quality, quantity, and distribution, while the latter is associated with the diversified hardware capacities, operating systems, and available resources across all clients. On the other hand, the FL framework must also consider a fair aggregation that does not discriminate based on the user’s localization, sex, or other properties. Generally speaking, the ultimate goal in this context is to handle a good trade-off between personalization, bias mitigation, and privacy preservation. Thus, implementing a personalized federated learning solution can be an arduous endeavor. The motivated researchers towards tackling this class of challenges are required to successfully evaluate the confronted heterogeneity types and design an appropriate approach that accounts for these factors without compromising the private-preserving aspect of the FL mechanism.\nSection3.1pinpoints the origins of heterogeneity. While in Section4.1, we offer systematic categorization for the respective solutions in this context.\n\nOptimization.\n\nThis category pertains to the various parameters to devise a practical FL model that converges rapidly. In other words, scientists interested in this class are willing to attain a gain in convergence rate. Accordingly, it is necessary to embrace the implementation of meticulous client selection, efficient communication, and an optimized scheme for resource allocation. However, several constraints may inhibit the achievement of this research target. For example, the FL systems encounter unfavorable environmental factors, including network latency, noisy communication channels, client mobility, and diverse types of heterogeneity among the participating entities. To expedite the convergence rate and adopt a rigorous approach that falls into this category, researchers need to ensure that the FL model is highly efficient, valid, and profitable under real-life conditions.\nIn section3.2, we will exhaustively elaborate on the communication constraints and client selection challenges, followed by their related solutions as found in the literature, in Section4.2.\n\nRobustness.\n\nSince FL was initially introduced to ensure data privacy and facilitate more secure protocols, it becomes imperative to alleviate and remediate the security and privacy concerns that impede the realization of a resilient FL solution. The obstacles may either be inherent in the traditional ML model or have arisen due to the distributed nature of FL. The proposals belonging to this category aim to guarantee robustness against numerous threats. While developing their contributions, researchers must incorporate security measures to counter potential attacks, privacy-preserving mechanisms to prevent information disclosure, and fault-tolerance techniques to handle network failures and malicious actors. Introducing innovative solutions that pertain to this category has gained growing interest, especially in sectors handling sensitive data, such as healthcare and insurance.\nwe conduct in Section3.3an in-depth analysis of the security and privacy issues to foster a better understanding of the corresponding security breaches and privacy violations. Separately, the contemporary defense strategies proposed in the arts are extensively discussed in Section4.3.\n\nSince its inception in 2016, Federated Learning has garnered significant attention, resulting in a notable surge in research publications over the past few years. Several detailed surveys have emerged to explore the FL area, each with a different focus. To categorize the evolving perspectives observed in FL surveys based on our in-depth lectures, we have discerned the primary optics characterizing the trajectory of FL survey papers over time as follows:\n\nBroad Description and General Concepts Examination [2016-2020]:In the earlier years, up until 2020, researchers from diverse backgrounds, including distributed ML, databases, and edge intelligence, conducted fundamental efforts to provide a descriptive and broad overview of general concepts surrounding FL during its nascent stages, such as enabling technologies, protocols, architectures, frameworks, and application domains(aledhari2020federated;abdulrahman2020survey). However, the research contributions landscape has gradually shifted from general perspectives toward a more specialized analysis of FL.\n\nSpecialized FL Examination: Projecting FL onto a Specific Domain Application [2020-2024]:Reflecting the maturation of FL research, this line focuses on projecting FL onto a specific domain application, such as healthcare(pfitzner2021federated;nguyen2022federatedhealth), resource-constrained environment(imteaj2021survey), and recommendation systems(yin2024device), delivering specialized examinations of FL within distinct domain applications.\n\nSpecialized FL Examination: In-depth Exploration over Limited Aspects [2020-2024]:The second direction in specialized FL surveys involves in-depth explorations of specific aspects (one or two) of the FL ecosystem, such as personalization(tan2022towards)heterogeneity(criado2022non), privacy(lyu2022privacy;rodriguez2023survey), or resource efficiency(almanifi2023communication). Remarkably, some works amalgamate these two approaches, as exemplified in(mothukuri2021survey), wherein the authors conduct an intriguing FL study in the healthcare domain, delving into privacy and robustness.\n\nIntegration of Federated Learning with Emerging Technologies [2020-2024]:An alternative and contemporary trend breaks down the integration of FL with emerging technologies, such as IoT(nguyen2021federated), IoMT, and blockchain(nguyen2021federatedblockchain), seeking to harness the synergistic potential of their fusion.\n\nIn order to position our work in the existing literature, we have carefully selected relevant surveys published in [2020-2023], which are encapsulated in Table1, to accentuate the primary topics and the main limitations in their work.\n\nNotwithstanding the diversity of existing work on FL, the current literature lacks an all-encompassing survey paper that considers numerous perspectives we have observed during our state-of-the-art analysis. The motivation for this survey stems from the following observations:\n\nThe first observation is thatrecent efforts have primarily focused on fundamental knowledge and well-known challenges, such as statistical heterogeneity, security attacks, and energy efficiency. Nonetheless, there is a pressing need for up-to-date and more comprehensive research that delves deeper beyond these common aspects, examining the less-discussed FL considerations, such as client selection, model architecture, knowledge distillation, bias mitigation, and fairness.\n\nThe second finding is thatexisting surveys have not adequately met the need for a finely structured and multilevel classification scheme that effectively organizes work contributions and showcases recent advances in the field. Instead, their classification schemes typically rely on a narrow perspective, focusing solely on FL challenges, architectures, or scales, often without providing clear and logical criteria for defining encapsulated categories. This lack of clarity and hierarchy results in an ambiguous content structure that makes it difficult for researchers to rapidly extract and comprehend relevant information aligned with their specific subject of interest.\n\nThe third insight is thatprevious studies have largely neglected the critical aspect of FL aggregation. To the best of our knowledge, none of the prior studies have placed an exceptional emphasis on FL aggregation. Although, the choice of aggregation algorithm and pipeline are pivotal features that affect the overall FL system performance significantly, especially in centralized FL. In this setup, a single server controls all the orchestration tasks. Therefore, any failure or breach of information on the server side can lead to flawed models and suboptimal outcomes.\n\nThe last notable point pertains tothe lack of complete guidelines that outline systematic methodologies for conducting realistic experiments to quantify the contribution of novel FL proposals. Researchers often spend significant time and effort identifying relevant parameters for their evaluation testbeds. By carefully selecting a testbed, they can effectively demonstrate the efficiency of their FL solutions. However, the absence of a notable reference source that provides substantial insights in this context presents a challenge. The evaluation configuration encompasses numerous FL components, including realistic or benchmark datasets, diverse types of heterogeneous data distribution at various levels, performance metrics tailored to different FL scenarios, DL model architecture and hyperparameters, and the number of participating clients.\n\nTo fill these gaps in the literature, we have been motivated to present an exhaustive FL survey that accounts for the following contributions:\n\nWe present a state-of-the-art survey that delves into the latest advances in federated learning. Our hybrid methodology for paper selection combines a bibliometric analysis with a systematic approach that offers a more vast and in-depth view of the FL paradigm.\n\nWe investigated the holistic and contemporary techniques found in the current literature to address the inherent challenges of federated learning. In order to improve the organization of our paper, we first identified three prominent clusters of research contributions as the top-level view of our advanced FL taxonomy:personalization, optimization, and robustness.\n\nTo promote a deeper understanding, we go beyond the traditional path and organize the reviewed works by their respective cluster of FL advances. We introduce then a well-structured and multilevel classification scheme for each encountered challenge and its corresponding solutions, separately, resulting in six distinct schemes.\n\nMoreover, the classification criteria of our FL taxonomy, on which we will elaborate later in the paper, are carefully defined to ensure clarity, hierarchical presentation, and comprehensiveness. This systematic FL map facilitates a straightforward analysis of the various facets of the FL domain, assisting researchers in effectively navigating the complexities and identifying emerging trends in the field.\n\nTo our knowledge, this is the first study comprehensively examining FL aggregation. Our focus spans from fundamental considerations, such as the aggregation architectures and scales, to more sophisticated aspects, such as the underlying motivations and synchronization modes, resulting in a complete FL aggregation classification.\n\nBased on this aggregation lens, we consistently explored the environment and goals of most surveyed papers throughout this study. This strategy allowed us to shed light on the context and the achieved purposes of researchers’ efforts across broader lines of investigation.\n\nWe conducted a series of experiments to guide researchers and provide practical insights into the process of evaluating FL proposals by simulating real-world settings. Specifically, we selected four algorithms from different classes of solutions and compared their performance in response to various and pertinent parameters. Through this experimental comparison, we discuss behavioral trends of algorithms incorporating various mechanisms to tackle FL challenges.\n\nTo aid fellow researchers in identifying future trends, we offer a captivating array of research paths that beckon further investigation, unlocking a wealth of opportunities for advancement.\n\nTable1presents the conducted analysis comparing our contributions with those of other survey papers, illuminating the distinctive value we bring to the research community. To facilitate the comparison, we have established a multi-level, multi-criteria framework to evaluate the similarities and differences between the existing literature and our work.\n\nFirstly, we consider the main covered facets of federated learning, encompassing:\n\nFL Basics:This criterion assesses whether the paper provides an overview of an FL system.\n\nHeterogeneity:Here, we evaluate if the paper covers common types of heterogeneity in FL systems.\n\nEfficiency:This criterion examines the extent to which the paper addresses efficiency within the FL domain.\n\nSecurity and Privacy:These criteria focus on the paper’s treatment of security breaches and privacy violations observed within the context of FL.\n\nSecondly, we delve into the organizational structure of the paper, prioritizing readability and clarity. To assess whether the survey paper is easily navigable and reader-friendly comprehension, we have defined the following metrics:\n\nSeparation between System and Challenges:An effectively organized survey would feature distinct sections dedicated to the operational aspects of the FL system and its inherent challenges. However, overlooking this detail by presenting them jointly in a monolith format impedes audience comprehension.\n\nSeparation between Challenges and Solutions:Similarly, we advocate for separate sections discussing FL challenges and the contemporary techniques employed to address them, facilitating a clear understanding.\n\nMulti-level Classification:We scrutinized whether the survey paper employs a hierarchical framework for structuring FL aspects, challenges, and techniques, enabling readers to effectively identify relevant information.\n\nClear Criteria for Classification:While some FL surveys provide a taxonomy for presenting their content, a luck of clarity regarding the criteria guiding their classification is prevalent.\n\nThirdly, we identify the distinctive research features that significantly enhance the survey’s quality and set it apart from other similar works.\n\nFocus on Aggregation:As elaborated earlier in the paper, aggregation profoundly impacts the FL system’s performance. Nonetheless, existing literature often lacks thorough discussions on this aspect. Tackling this research gap is a primary motivation and distinguishes our survey.\n\nDetailed Methodology:This pertains to the methodology used by authors for selecting relevant references. A comprehensive survey carefully attends to selection strategies, typically employing standard and robust tools to filter vast research databases.\n\nEvaluation of FL Proposals:Survey papers outline accomplishments in distinct domains, but evaluating surveyed papers against pertinent and diverse criteria is crucial. The tabulated comparison presents a concise summary and highlights notable strengths and weaknesses of each proposal.\n\nExperimentation:Generally, simulations validate proposed algorithms and reveal their behavioral trends. However, a notable minority of FL survey papers integrate experimental aspects with theoretical examinations, leading to an incomplete analytical framework.\n\nIn order to deliver reliable and engaging state-of-the-art analysis, we have combined two robust methodologies, leveraging their notable strengths. We have started with an initialbibliometric study, utilizing a software-assisted mechanism to explore vast scholarly databases and discern pivotal FL specifications. Building upon this foundation, we undertake asystematic literature review, probing deeper into the influential works and emerging techniques. This hybrid strategy, rarely observed in previous FL research, ensures transparency, objectivity, and ample coverage of the FL realm. Hereafter, we will explain in detail each of these steps.\n\nCitespace is a Java application designed for analyzing and visualizing scholarly literature(chen2006citespace). It facilitates intricate patterns, trends, and connections uncovering within large-scale academic databases. Specifically, CiteSpace offers many research features such as co-citation analysis, co-keyword analysis, network visualization, and knowledge mapping. Additionally, it allows various filtering options, including time slicing, burst detection, and cluster identification, which empower scholars to track the essence of a research front and understand its dynamics as it evolves constantly. Thereby, scientists and analysts will be able to keep up with the rapid advances and remain informed about the latest trends in the body of the domain of interest.\n\nWe utilized Dimensions(dimensions)as our primary data source, renowned for its daily updates with fresh articles from over 130 publishers, accessing an extensive collection of scholarly publications. Our research in the initial phase, conducted throughout the first half of 2023, involved a detailed analysis of titles and abstracts of research publications. To achieve this, we focused on articles, conference proceedings, and preprints published between 2020 and 2023, aiming to capture the latest advances in FL. As our study advanced, we broadened our data collection to include influential works from the latter half of 2023, ensuring a more comprehensive coverage. Moreover, It is important to note that in the subsequent phase of our methodology, we conducted a thorough traditional review, incorporating numerous papers predating 2020, acknowledging their foundational contributions to the field of FL.\n\nTo ensure a comprehensive investigation through our research queries, we compiled a set of keywords commonly associated with federated learning, including :(”federated learning” OR ”federated training” OR ”federated machine learning” … OR ”federated implementation”)By combining these keywords with various FL-specific-area terms, we sought to capture a clear view of the subject. For instance, to gain a high-level standpoint, we have combined the abovementioned words set with other survey-related keywords to form the following query:\n\n[federated-learning-keywords] AND (”survey” OR ”overview” OR ”review” OR ”trends” OR ”challenges”)\n\nThis query yielded 4040 relevant documents, which we used as our input for the bibliometric mapping by CiteSpace.\n\nIn this section, we explore the network visualizations provided by CiteSpace tools. While we utilized diverse project configurations and application tools, we focus here on presenting an overview of the clustering results as one of the most powerful features. The clustering function organizes the nodes into clusters, each depicted by a unique color and title. The node corresponds to a specific type of data in each project case.\n\nOne of the scenarios explored is co-reference-based clustering. Here, each node within a cluster represents the papers from our input dataset along with their cited references. As a result, a cluster will group together papers that examine similar or closely related topics. However, it is important to note that the automatically assigned titles are solely based on the paper titles and might not fully articulate the subject of interest within each class. Aiming for better insights, we utilize the cluster explorer tool, which provides more comprehensive details and statistics. Fig.2displays the top height (8) ranked clusters.\n\nWe used the knowledge extracted from CiteSpace visualization to inform the second step of our survey methodology, which we started by asking the question:\n\nQ1: What are the prominent clusters of contributions under which fall most of the work in FL?\n\nAnswering this question allowed us to provide a high-level view of the FL landscape by dividing it into three clusters:Personalization, Optimization, and Robustness. Then, using these clusters as our compass, we embarked on a more detailed exploration of FL concerns, which guided us to our second question:\n\nQ2: What are the recent FL advances within each identified cluster?\n\nAddressing this question, we identified four system constraints: Heterogeneity, Efficiency, Security, and Privacy, which present the second level of our content organization (see Sections3.1,3.2,3.3, respectively). Since we found impressively a significant number of publications that fall under these FL aspects, we conducted rigorous readings of FL research papers, selectively curated based on CiteSpace statistics, to answer the third question:\n\nQ3: What are the corresponding encountered impediments and employed techniques within each FL aspect?\n\nWe thoughtfully organized the results of our analysis regarding this question into classes and subclasses to separately highlight the challenges and recent solutions for each aspect.\n\nIn the final stage, we refined our content from the perspective of FL aggregation. This meticulous process led to the formulation of three unique classification schemes, outlining the impediments associated with efficient FL aggregation (See Section3). Also, it results in three other classification schemes showcasing the most recent and widely adopted techniques for FL advancements (See section4). Fig.3presents a visualization of the entire strategy’s flowchart diagram.\n\nDimensions remains our data source for selecting the surveyed paper. By leveraging the classification schemes obtained in the previous step, we formulated precise research queries relying on the third organizational level. In other words, we captured the terminology used to describe recent FL techniques as our research keywords. This methodology interestingly streamlined our research and limited the number of listed results. While at the same time, it enables us to emphasize the relevant studies that extensively dug into the underlying techniques.\n\nThe results of the numerical analysis conducted on the surveyed papers, which encompassed a substantial list of publications, are illustrated in Fig.4. Fig.4(a)provides a percentage breakdown of the included literature on federated learning based on the respective publisher. Notably, more than two-thirds of the papers were found in reputable sources such as IEEE and arXiv, accounting for 34% and 31%, respectively. The remaining reviewed papers are distributed across other databases, including Springer, Elsevier, and ACM, with percentages of 9%, 7%, and 5%, respectively.\n\nFig.4(b)shows the distribution of publication years across the examined federated learning literature. Remarkably, 38% of the papers were published in 2022, which aligns with our objective to provide an up-to-date study covering recent research advancements. Besides, 28% of the works were published in 2023, as we continued to look for influential studies until the middle of this year. However, the proportion of papers published in 2021 and 2020 is relatively lower, accounting for 18% and 16%, respectively, as we excluded studies that were widely cited in earlier reviews.\nIt is worth highlighting that while our primary emphasis on these statistics relies on the latest research findings, we also surveyed relevant papers predating 2020, which have significantly impacted the evolution of FL and garnered widespread adoption within the research community.\n\nWe present in Fig.4(c)the last percentage breakdown illustrating the top-level classification scheme clusters. From this figure, we can conclude that security and privacy have been investigated the most, comprising 41% of the cited literature. The heterogeneity cluster follows closely with 39%. The last line of our examination consists of communication efficiency with 20% of the total content.\nAlso, it is noteworthy that within our survey, 40% of the integrated references are scholarly articles. While conference papers contribute to 29% of the surveyed literature. Additionally, preprints constitute 31% of the examined work, as illustrated in Figure4(d).\n\nThe remaining sections of this survey are structured as follows: In Section2, we provide an overview of fundamental concepts in federated learning, covering its basic principles, formal definition, procedural steps, and various FL types based on data distribution. Additionally, we present a comprehensive classification of federated learning aggregation, emphasizing its pivotal role in overall system performance and reflecting our primary focus on studying the FL landscape. Section3delves into the characteristics of the federated learning ecosystem, exploring aspects such as heterogeneity, efficiency, security, and privacy. These discussions align with the three clusters identified in our high-level classification of the FL domain, spanning personalization, optimization, and robustness areas. Subsequently, Section4outlines the latest advancements in FL solutions, encompassing aggregation proposals as well as other relevant techniques that enhance the aggregation process. To enhance readability and navigability for readers, we offer a multi-level classification scheme for each FL cluster and summarize surveyed papers in dedicated tables, employing a multi-criteria framework for evaluation and comparison. Section5is dedicated to the experimental guidelines, simulation results, and interpretations. Specifically, we compare the performance of four FL aggregation algorithms and analyze their behavior across various real-world FL settings. Before concluding, Section6highlights emerging trends and areas of interest, aiding researchers to pinpoint exciting directions for their future research endeavors. Finally, in Section7, we discuss and recap our findings. Fig.5provides an overview of the survey’s organization.\n\n\n================================================================================\n1.1.Related Work\n================================================================================\nSince its inception in 2016, Federated Learning has garnered significant attention, resulting in a notable surge in research publications over the past few years. Several detailed surveys have emerged to explore the FL area, each with a different focus. To categorize the evolving perspectives observed in FL surveys based on our in-depth lectures, we have discerned the primary optics characterizing the trajectory of FL survey papers over time as follows:\n\nBroad Description and General Concepts Examination [2016-2020]:In the earlier years, up until 2020, researchers from diverse backgrounds, including distributed ML, databases, and edge intelligence, conducted fundamental efforts to provide a descriptive and broad overview of general concepts surrounding FL during its nascent stages, such as enabling technologies, protocols, architectures, frameworks, and application domains(aledhari2020federated;abdulrahman2020survey). However, the research contributions landscape has gradually shifted from general perspectives toward a more specialized analysis of FL.\n\nSpecialized FL Examination: Projecting FL onto a Specific Domain Application [2020-2024]:Reflecting the maturation of FL research, this line focuses on projecting FL onto a specific domain application, such as healthcare(pfitzner2021federated;nguyen2022federatedhealth), resource-constrained environment(imteaj2021survey), and recommendation systems(yin2024device), delivering specialized examinations of FL within distinct domain applications.\n\nSpecialized FL Examination: In-depth Exploration over Limited Aspects [2020-2024]:The second direction in specialized FL surveys involves in-depth explorations of specific aspects (one or two) of the FL ecosystem, such as personalization(tan2022towards)heterogeneity(criado2022non), privacy(lyu2022privacy;rodriguez2023survey), or resource efficiency(almanifi2023communication). Remarkably, some works amalgamate these two approaches, as exemplified in(mothukuri2021survey), wherein the authors conduct an intriguing FL study in the healthcare domain, delving into privacy and robustness.\n\nIntegration of Federated Learning with Emerging Technologies [2020-2024]:An alternative and contemporary trend breaks down the integration of FL with emerging technologies, such as IoT(nguyen2021federated), IoMT, and blockchain(nguyen2021federatedblockchain), seeking to harness the synergistic potential of their fusion.\n\nIn order to position our work in the existing literature, we have carefully selected relevant surveys published in [2020-2023], which are encapsulated in Table1, to accentuate the primary topics and the main limitations in their work.\n\n\n================================================================================\n1.2.Motivations and Contributions\n================================================================================\nNotwithstanding the diversity of existing work on FL, the current literature lacks an all-encompassing survey paper that considers numerous perspectives we have observed during our state-of-the-art analysis. The motivation for this survey stems from the following observations:\n\nThe first observation is thatrecent efforts have primarily focused on fundamental knowledge and well-known challenges, such as statistical heterogeneity, security attacks, and energy efficiency. Nonetheless, there is a pressing need for up-to-date and more comprehensive research that delves deeper beyond these common aspects, examining the less-discussed FL considerations, such as client selection, model architecture, knowledge distillation, bias mitigation, and fairness.\n\nThe second finding is thatexisting surveys have not adequately met the need for a finely structured and multilevel classification scheme that effectively organizes work contributions and showcases recent advances in the field. Instead, their classification schemes typically rely on a narrow perspective, focusing solely on FL challenges, architectures, or scales, often without providing clear and logical criteria for defining encapsulated categories. This lack of clarity and hierarchy results in an ambiguous content structure that makes it difficult for researchers to rapidly extract and comprehend relevant information aligned with their specific subject of interest.\n\nThe third insight is thatprevious studies have largely neglected the critical aspect of FL aggregation. To the best of our knowledge, none of the prior studies have placed an exceptional emphasis on FL aggregation. Although, the choice of aggregation algorithm and pipeline are pivotal features that affect the overall FL system performance significantly, especially in centralized FL. In this setup, a single server controls all the orchestration tasks. Therefore, any failure or breach of information on the server side can lead to flawed models and suboptimal outcomes.\n\nThe last notable point pertains tothe lack of complete guidelines that outline systematic methodologies for conducting realistic experiments to quantify the contribution of novel FL proposals. Researchers often spend significant time and effort identifying relevant parameters for their evaluation testbeds. By carefully selecting a testbed, they can effectively demonstrate the efficiency of their FL solutions. However, the absence of a notable reference source that provides substantial insights in this context presents a challenge. The evaluation configuration encompasses numerous FL components, including realistic or benchmark datasets, diverse types of heterogeneous data distribution at various levels, performance metrics tailored to different FL scenarios, DL model architecture and hyperparameters, and the number of participating clients.\n\nTo fill these gaps in the literature, we have been motivated to present an exhaustive FL survey that accounts for the following contributions:\n\nWe present a state-of-the-art survey that delves into the latest advances in federated learning. Our hybrid methodology for paper selection combines a bibliometric analysis with a systematic approach that offers a more vast and in-depth view of the FL paradigm.\n\nWe investigated the holistic and contemporary techniques found in the current literature to address the inherent challenges of federated learning. In order to improve the organization of our paper, we first identified three prominent clusters of research contributions as the top-level view of our advanced FL taxonomy:personalization, optimization, and robustness.\n\nTo promote a deeper understanding, we go beyond the traditional path and organize the reviewed works by their respective cluster of FL advances. We introduce then a well-structured and multilevel classification scheme for each encountered challenge and its corresponding solutions, separately, resulting in six distinct schemes.\n\nMoreover, the classification criteria of our FL taxonomy, on which we will elaborate later in the paper, are carefully defined to ensure clarity, hierarchical presentation, and comprehensiveness. This systematic FL map facilitates a straightforward analysis of the various facets of the FL domain, assisting researchers in effectively navigating the complexities and identifying emerging trends in the field.\n\nTo our knowledge, this is the first study comprehensively examining FL aggregation. Our focus spans from fundamental considerations, such as the aggregation architectures and scales, to more sophisticated aspects, such as the underlying motivations and synchronization modes, resulting in a complete FL aggregation classification.\n\nBased on this aggregation lens, we consistently explored the environment and goals of most surveyed papers throughout this study. This strategy allowed us to shed light on the context and the achieved purposes of researchers’ efforts across broader lines of investigation.\n\nWe conducted a series of experiments to guide researchers and provide practical insights into the process of evaluating FL proposals by simulating real-world settings. Specifically, we selected four algorithms from different classes of solutions and compared their performance in response to various and pertinent parameters. Through this experimental comparison, we discuss behavioral trends of algorithms incorporating various mechanisms to tackle FL challenges.\n\nTo aid fellow researchers in identifying future trends, we offer a captivating array of research paths that beckon further investigation, unlocking a wealth of opportunities for advancement.\n\nTable1presents the conducted analysis comparing our contributions with those of other survey papers, illuminating the distinctive value we bring to the research community. To facilitate the comparison, we have established a multi-level, multi-criteria framework to evaluate the similarities and differences between the existing literature and our work.\n\nFirstly, we consider the main covered facets of federated learning, encompassing:\n\nFL Basics:This criterion assesses whether the paper provides an overview of an FL system.\n\nHeterogeneity:Here, we evaluate if the paper covers common types of heterogeneity in FL systems.\n\nEfficiency:This criterion examines the extent to which the paper addresses efficiency within the FL domain.\n\nSecurity and Privacy:These criteria focus on the paper’s treatment of security breaches and privacy violations observed within the context of FL.\n\nSecondly, we delve into the organizational structure of the paper, prioritizing readability and clarity. To assess whether the survey paper is easily navigable and reader-friendly comprehension, we have defined the following metrics:\n\nSeparation between System and Challenges:An effectively organized survey would feature distinct sections dedicated to the operational aspects of the FL system and its inherent challenges. However, overlooking this detail by presenting them jointly in a monolith format impedes audience comprehension.\n\nSeparation between Challenges and Solutions:Similarly, we advocate for separate sections discussing FL challenges and the contemporary techniques employed to address them, facilitating a clear understanding.\n\nMulti-level Classification:We scrutinized whether the survey paper employs a hierarchical framework for structuring FL aspects, challenges, and techniques, enabling readers to effectively identify relevant information.\n\nClear Criteria for Classification:While some FL surveys provide a taxonomy for presenting their content, a luck of clarity regarding the criteria guiding their classification is prevalent.\n\nThirdly, we identify the distinctive research features that significantly enhance the survey’s quality and set it apart from other similar works.\n\nFocus on Aggregation:As elaborated earlier in the paper, aggregation profoundly impacts the FL system’s performance. Nonetheless, existing literature often lacks thorough discussions on this aspect. Tackling this research gap is a primary motivation and distinguishes our survey.\n\nDetailed Methodology:This pertains to the methodology used by authors for selecting relevant references. A comprehensive survey carefully attends to selection strategies, typically employing standard and robust tools to filter vast research databases.\n\nEvaluation of FL Proposals:Survey papers outline accomplishments in distinct domains, but evaluating surveyed papers against pertinent and diverse criteria is crucial. The tabulated comparison presents a concise summary and highlights notable strengths and weaknesses of each proposal.\n\nExperimentation:Generally, simulations validate proposed algorithms and reveal their behavioral trends. However, a notable minority of FL survey papers integrate experimental aspects with theoretical examinations, leading to an incomplete analytical framework.\n\n\n================================================================================\n1.3.Survey Methodology\n================================================================================\nIn order to deliver reliable and engaging state-of-the-art analysis, we have combined two robust methodologies, leveraging their notable strengths. We have started with an initialbibliometric study, utilizing a software-assisted mechanism to explore vast scholarly databases and discern pivotal FL specifications. Building upon this foundation, we undertake asystematic literature review, probing deeper into the influential works and emerging techniques. This hybrid strategy, rarely observed in previous FL research, ensures transparency, objectivity, and ample coverage of the FL realm. Hereafter, we will explain in detail each of these steps.\n\nCitespace is a Java application designed for analyzing and visualizing scholarly literature(chen2006citespace). It facilitates intricate patterns, trends, and connections uncovering within large-scale academic databases. Specifically, CiteSpace offers many research features such as co-citation analysis, co-keyword analysis, network visualization, and knowledge mapping. Additionally, it allows various filtering options, including time slicing, burst detection, and cluster identification, which empower scholars to track the essence of a research front and understand its dynamics as it evolves constantly. Thereby, scientists and analysts will be able to keep up with the rapid advances and remain informed about the latest trends in the body of the domain of interest.\n\nWe utilized Dimensions(dimensions)as our primary data source, renowned for its daily updates with fresh articles from over 130 publishers, accessing an extensive collection of scholarly publications. Our research in the initial phase, conducted throughout the first half of 2023, involved a detailed analysis of titles and abstracts of research publications. To achieve this, we focused on articles, conference proceedings, and preprints published between 2020 and 2023, aiming to capture the latest advances in FL. As our study advanced, we broadened our data collection to include influential works from the latter half of 2023, ensuring a more comprehensive coverage. Moreover, It is important to note that in the subsequent phase of our methodology, we conducted a thorough traditional review, incorporating numerous papers predating 2020, acknowledging their foundational contributions to the field of FL.\n\nTo ensure a comprehensive investigation through our research queries, we compiled a set of keywords commonly associated with federated learning, including :(”federated learning” OR ”federated training” OR ”federated machine learning” … OR ”federated implementation”)By combining these keywords with various FL-specific-area terms, we sought to capture a clear view of the subject. For instance, to gain a high-level standpoint, we have combined the abovementioned words set with other survey-related keywords to form the following query:\n\n[federated-learning-keywords] AND (”survey” OR ”overview” OR ”review” OR ”trends” OR ”challenges”)\n\nThis query yielded 4040 relevant documents, which we used as our input for the bibliometric mapping by CiteSpace.\n\nIn this section, we explore the network visualizations provided by CiteSpace tools. While we utilized diverse project configurations and application tools, we focus here on presenting an overview of the clustering results as one of the most powerful features. The clustering function organizes the nodes into clusters, each depicted by a unique color and title. The node corresponds to a specific type of data in each project case.\n\nOne of the scenarios explored is co-reference-based clustering. Here, each node within a cluster represents the papers from our input dataset along with their cited references. As a result, a cluster will group together papers that examine similar or closely related topics. However, it is important to note that the automatically assigned titles are solely based on the paper titles and might not fully articulate the subject of interest within each class. Aiming for better insights, we utilize the cluster explorer tool, which provides more comprehensive details and statistics. Fig.2displays the top height (8) ranked clusters.\n\nWe used the knowledge extracted from CiteSpace visualization to inform the second step of our survey methodology, which we started by asking the question:\n\nQ1: What are the prominent clusters of contributions under which fall most of the work in FL?\n\nAnswering this question allowed us to provide a high-level view of the FL landscape by dividing it into three clusters:Personalization, Optimization, and Robustness. Then, using these clusters as our compass, we embarked on a more detailed exploration of FL concerns, which guided us to our second question:\n\nQ2: What are the recent FL advances within each identified cluster?\n\nAddressing this question, we identified four system constraints: Heterogeneity, Efficiency, Security, and Privacy, which present the second level of our content organization (see Sections3.1,3.2,3.3, respectively). Since we found impressively a significant number of publications that fall under these FL aspects, we conducted rigorous readings of FL research papers, selectively curated based on CiteSpace statistics, to answer the third question:\n\nQ3: What are the corresponding encountered impediments and employed techniques within each FL aspect?\n\nWe thoughtfully organized the results of our analysis regarding this question into classes and subclasses to separately highlight the challenges and recent solutions for each aspect.\n\nIn the final stage, we refined our content from the perspective of FL aggregation. This meticulous process led to the formulation of three unique classification schemes, outlining the impediments associated with efficient FL aggregation (See Section3). Also, it results in three other classification schemes showcasing the most recent and widely adopted techniques for FL advancements (See section4). Fig.3presents a visualization of the entire strategy’s flowchart diagram.\n\n\n================================================================================\nData Extraction\n================================================================================\nWe utilized Dimensions(dimensions)as our primary data source, renowned for its daily updates with fresh articles from over 130 publishers, accessing an extensive collection of scholarly publications. Our research in the initial phase, conducted throughout the first half of 2023, involved a detailed analysis of titles and abstracts of research publications. To achieve this, we focused on articles, conference proceedings, and preprints published between 2020 and 2023, aiming to capture the latest advances in FL. As our study advanced, we broadened our data collection to include influential works from the latter half of 2023, ensuring a more comprehensive coverage. Moreover, It is important to note that in the subsequent phase of our methodology, we conducted a thorough traditional review, incorporating numerous papers predating 2020, acknowledging their foundational contributions to the field of FL.\n\nTo ensure a comprehensive investigation through our research queries, we compiled a set of keywords commonly associated with federated learning, including :(”federated learning” OR ”federated training” OR ”federated machine learning” … OR ”federated implementation”)By combining these keywords with various FL-specific-area terms, we sought to capture a clear view of the subject. For instance, to gain a high-level standpoint, we have combined the abovementioned words set with other survey-related keywords to form the following query:\n\n[federated-learning-keywords] AND (”survey” OR ”overview” OR ”review” OR ”trends” OR ”challenges”)\n\nThis query yielded 4040 relevant documents, which we used as our input for the bibliometric mapping by CiteSpace.\n\n\n================================================================================\nNetwork Mapping and Clustering\n================================================================================\nIn this section, we explore the network visualizations provided by CiteSpace tools. While we utilized diverse project configurations and application tools, we focus here on presenting an overview of the clustering results as one of the most powerful features. The clustering function organizes the nodes into clusters, each depicted by a unique color and title. The node corresponds to a specific type of data in each project case.\n\nOne of the scenarios explored is co-reference-based clustering. Here, each node within a cluster represents the papers from our input dataset along with their cited references. As a result, a cluster will group together papers that examine similar or closely related topics. However, it is important to note that the automatically assigned titles are solely based on the paper titles and might not fully articulate the subject of interest within each class. Aiming for better insights, we utilize the cluster explorer tool, which provides more comprehensive details and statistics. Fig.2displays the top height (8) ranked clusters.\n\n\n================================================================================\n1.4.Survey Insights\n================================================================================\nDimensions remains our data source for selecting the surveyed paper. By leveraging the classification schemes obtained in the previous step, we formulated precise research queries relying on the third organizational level. In other words, we captured the terminology used to describe recent FL techniques as our research keywords. This methodology interestingly streamlined our research and limited the number of listed results. While at the same time, it enables us to emphasize the relevant studies that extensively dug into the underlying techniques.\n\nThe results of the numerical analysis conducted on the surveyed papers, which encompassed a substantial list of publications, are illustrated in Fig.4. Fig.4(a)provides a percentage breakdown of the included literature on federated learning based on the respective publisher. Notably, more than two-thirds of the papers were found in reputable sources such as IEEE and arXiv, accounting for 34% and 31%, respectively. The remaining reviewed papers are distributed across other databases, including Springer, Elsevier, and ACM, with percentages of 9%, 7%, and 5%, respectively.\n\nFig.4(b)shows the distribution of publication years across the examined federated learning literature. Remarkably, 38% of the papers were published in 2022, which aligns with our objective to provide an up-to-date study covering recent research advancements. Besides, 28% of the works were published in 2023, as we continued to look for influential studies until the middle of this year. However, the proportion of papers published in 2021 and 2020 is relatively lower, accounting for 18% and 16%, respectively, as we excluded studies that were widely cited in earlier reviews.\nIt is worth highlighting that while our primary emphasis on these statistics relies on the latest research findings, we also surveyed relevant papers predating 2020, which have significantly impacted the evolution of FL and garnered widespread adoption within the research community.\n\nWe present in Fig.4(c)the last percentage breakdown illustrating the top-level classification scheme clusters. From this figure, we can conclude that security and privacy have been investigated the most, comprising 41% of the cited literature. The heterogeneity cluster follows closely with 39%. The last line of our examination consists of communication efficiency with 20% of the total content.\nAlso, it is noteworthy that within our survey, 40% of the integrated references are scholarly articles. While conference papers contribute to 29% of the surveyed literature. Additionally, preprints constitute 31% of the examined work, as illustrated in Figure4(d).\n\n\n================================================================================\n1.5.Survey Organization\n================================================================================\nThe remaining sections of this survey are structured as follows: In Section2, we provide an overview of fundamental concepts in federated learning, covering its basic principles, formal definition, procedural steps, and various FL types based on data distribution. Additionally, we present a comprehensive classification of federated learning aggregation, emphasizing its pivotal role in overall system performance and reflecting our primary focus on studying the FL landscape. Section3delves into the characteristics of the federated learning ecosystem, exploring aspects such as heterogeneity, efficiency, security, and privacy. These discussions align with the three clusters identified in our high-level classification of the FL domain, spanning personalization, optimization, and robustness areas. Subsequently, Section4outlines the latest advancements in FL solutions, encompassing aggregation proposals as well as other relevant techniques that enhance the aggregation process. To enhance readability and navigability for readers, we offer a multi-level classification scheme for each FL cluster and summarize surveyed papers in dedicated tables, employing a multi-criteria framework for evaluation and comparison. Section5is dedicated to the experimental guidelines, simulation results, and interpretations. Specifically, we compare the performance of four FL aggregation algorithms and analyze their behavior across various real-world FL settings. Before concluding, Section6highlights emerging trends and areas of interest, aiding researchers to pinpoint exciting directions for their future research endeavors. Finally, in Section7, we discuss and recap our findings. Fig.5provides an overview of the survey’s organization.\n\n\n================================================================================\n2.Preliminaries\n================================================================================\nFederated Learning is a variant of Distributed Machine Learning paradigms where the data and the computational workload are distributed across multiple nodes connected to a network. This approach offers increased efficiency for training a robust and sophisticated ML model on large-scale datasets, which would be infeasible to process in one machine. Moreover, federated learning takes this concept further by focusing on data privacy. In the FL ecosystem, a set of participants calledclientscollaboratively train high-quality AI models under the orchestration of a remote server called aparameter serverwithout the need to access their local data. The crucial aspect is that the private data never leaves the client site, but only the locally-built models are transmitted to the server. In response, the server aggregates these updates from all entities to form a global model and communicates it back to the active participants. The iterative process of local-global model exchanges, illustrated in Fig.6, continues until achieving a desirable utility.\n\nThe generic FL procedure incorporates the following steps:\n\nSystem Initialization:In the first phase, it is the responsibility of the server to decide the intended task application (e.g., disease prediction, system recommendation, activity detection) as well as the essential model parameters (model type and architecture, learning rates, number of clients per round). Furthermore, the server initiates the global model gradients and selects a group of clients to be involved in the next iteration.\n\nDistributed Local Training:The parameter server broadcasts the initial global model across the chosen clients to kickstart the distributed learning process. Upon receiving the global model, each node independently trains a local model leveraging its respective data to generate the updated gradients. The locally optimized models are then uploaded back to the server.\n\nServer Aggregation:After receiving the updates from all participating clients, the server executes the aggregation algorithm to consolidate the gradients into a unified model (e.g., through averaging). Subsequently, the latest version of the global model is disseminated again to the involved entities.\n\nSteps 2 and 3 are iterated until the desired performance is achieved.\n\nIn a formal context, we designate the selected client indices asc=1,2,3,…,Cc=1,2,3,\\ldots,C, directed by the central server, whereC⊆NC\\subseteq N. Each node possesses its private datasetDc={Xc,Yc},where​Xc∈ℝ|Dc|×dD_{c}=\\{X_{c},Y_{c}\\},\\text{ where }X_{c}\\in\\mathbb{R}^{|D_{c}|\\times d}represents the feature space vector, andYc∈ℝ|Dc|×mY_{c}\\in\\mathbb{R}^{|D_{c}|\\times m}denotes the associated label matrix. During communication roundtt, clientccdownloads the latest global modelwtw_{t}and uses its local data for training. The primary objective is to optimize a loss function that penalizes inaccuracies in the model’s predictions for data points. Specifically, we denotel​(W;xi,yi)l(W;x_{i},y_{i})as the loss function for theii-th data point, with W representing a matrix of model weights in a neuron network, then the mathematical equation for the local loss function of client c is given in Equation1.\n\nSimilarly, we present the global loss function encompassing all clients in Equation2, whereinM=∑c=1C|Dc|M=\\sum_{c=1}^{C}|D_{c}|denotes the total number of data points across all C clients.\n\nDuring the aggregation phase, the parameter server leverages an aggregation algorithm to generate the global model for round t+1 once all clients complete uploading their local models. The first widely-recognized method is FedAVG, which performs straightforward averaging of all the model weights as introduced in the pseudo-code1. It is worth noting that the aggregation component plays a crucial role in FL since it facilitates the effective integration of knowledge learned by individual clients. Thus, it results in a more accurate and refined global model after each communication round. However, scholars have confirmed that this simplistic approach used in FedAVG may not fully address all the requirements of FL systems, which has spurred numerous research endeavors in this line of investigation.\n\nThe key foundation of FL is the data matrix, which defines the distinct distribution patterns of data sample space and data feature space. As depicted in Fig.7, FL can be classified into three categories depending on the data distribution of the participating clients, as follows:\n\nHorizontal Federated Learning:In Horizontal Federated Learning (HFL), the participating clients share the same type of data features while possessing different sets of data samples. To better understand this, let’s consider a medical scenario where different hospitals collaborate to develop an AI model for predicting disease outcomes. In this case, all hospitals present the patients using their medical records, which form a common feature space. However, the patients associated with each hospital may differ, meaning they correspond to distinct populations with non-overlapping sets of patients. Despite this difference, HFL enables hospitals aimed at joining forces to collectively train a robust AI model using their shared feature space while respecting patients’ privacy.\n\nVertical Federated Learning:In Vertical Federated Learning (VFL), the datasets of the engaged nodes have a common simple space, but with different data features, which results in a combined dataset that is more diverse in terms of data types. For instance, consider a credit risk prediction task where the clients are banks within one country, each having a separate dataset. Some banks have stored the credit history data of their customers, while others have financial transaction records. In this case, there is substantial intersection at the level of clientele they serve. By pooling together the knowledge of their unique datasets, they can create a more comprehensive credit risk prediction model with improved accuracy.\n\nFederated Transfer Learning:Federated Transfer Learning (FTL) came to the fore when both HFL and VFL would not be effective. FTL can handle datasets in which the data features and samples are distinct across clients. When the intersection of the overlapping data samples and features is negligible considering all the participating clients, Transfer Learning methods are applied to map the various feature spaces into a new shared representation space to learn all the sample labels.\n\nOne of the crucial concerns of federated learning is how to combine the local models’ updates from different clients into a global model that can generalize well to new data, regardless of the diversity of the participating parties. The aggregation methods are an integral part of the federated learning ecosystem as they provide a solution to this challenge. Furthermore, it has been determined that the aggregation techniques hold promise as a research direction to address the various challenges inherent to federated learning. Different algorithms have been proposed in the literature, ranging from simple averaging to more sophisticated techniques. Nonetheless, the choice of a specific one to adopt can significantly affect the performance of all the FL system evaluation metrics, from the convergence speed and accuracy to communication cost and privacy. Therefore, it is indispensable to understand the strengths and weaknesses of different aggregation strategies and select the proper option for the particular application and data distribution at hand. In this section, we will describe the aggregation process in federated learning, providing a comprehensive classification from various perspectives, according to the federated learning configuration, including the federation scale, the topology, the updates synchronization mode, and the motivation for joining the collaborative training. These perspectives are illustrated in Fig.8. Later in the paper, we will review the latest advancements in aggregation techniques put forth in scholarly publications and delve into their respective methodologies that aim to fulfill the FL requisites (see Section4).\n\nAggregation methods in federated learning can be classified based on the number of active participants and the amount of data held by each one. Two main categories of aggregation methods based on the scale of the federation and the data distribution arecross-deviceaggregation andcross-siloaggregation, as depicted in Fig.9.\nTable2summarizes the unique features of each category, facilitating a clear understanding of their differences.\n\nCross-Device Aggregation.The advent of federated learning stemmed primarily from the need to facilitate efficient machine learning on mobile and edge devices, which typically possess constrained computational capabilities and limited storage capacity. In this cross-device setting, local models are trained on data generated by individual users, making it well-suited for scenarios where FL users are mobile, and their number is quite large, practically in the range of​1010{10}^{10}. Notably, the first example of cross-device federated learning was Google’s implementation of the Gboard mobile keyboard to build next-word prediction models.\n\nCross-Silo Aggregation.Given the promising outcomes of cross-device FL applications, a growing interest in extending FL usage into other applications has rapidly emerged. Cross-silos FL refers to the collective training between large institutions in various domains, including smart manufacturing, finance risk prediction for reinsurance, and medical data segmentation. The participants in cross-silo scenarios possess significant amounts of data and are relatively limited in number, typically less than 100 clients. In this context, it is reasonable to expect organizations such as hospitals and banks to be consistently involved in each round, owing to their substantial computing capabilities and relatively stable environments.\n\nThe architectural aspect of the federated learning process is also an essential factor for aggregation classification. The network topology that defines how the involved parties interact with each other or with a central server might be either centralized, decentralized, or hierarchical. Fig.10presents an illustration of the three architectures. While Table2sheds light on their characteristics, respectively.\n\nCentralized Federation.The centralized design is the most commonly used FL architecture, where a central server is responsible for learning coordination. This means that the client devices interact only with the server to send and receive model updates, in a synchronous or asynchronous communication regime. The single-server topology ensures that the whole training process is in the hand of one powerful actor, which helps avoid errors and facilitate a simple aggregation pipeline. However, it demands a robust and secure server that can handle extreme conditions (e.g., the high number of participants, the large model updates dimension) and alleviate the potential security and privacy attacks.\n\nDecentralized Federation.In decentralized FL architecture, clients can communicate with each other in a peer-to-peer (P2P) fashion to build a global model without needing a central server. The main idea behind this design is to release the dependency on a central entity. Besides, it weakens the impact of the server becoming malicious or curious while ensuring the model’s utility. On the flip side, it can become challenging to implement the Fl aggregation under a decentralized architecture that converges efficiently, especially in large-scale FL.\n\nHierarchical Federation.The novelty of hierarchical federation has come to the fore from the need to tackle the limitations of centralized and decentralized settings, specifically in scenarios where the participating clients are distributed across multiple levels or tiers of a hierarchy. This new approach allows for multi-level coordination by introducing an intermediate layer above the local clients for first-level aggregation, followed by a global one. Accordingly, the local workers are grouped in clusters considering different criteria, such as locations, data distributions, etc., and they only communicate with their associated parameter server, usually an edge or fog device, which is responsible for averaging the respected local updates. After a number of intra-cluster iterations, an inter-cluster model aggregation is performed, usually in the cloud, to establish a global consensus. Hence, the tree-like structure introduced by the hierarchical structure can reduce communication overhead, enhance privacy protection, and improve participation flexibility and scalability.\n\nThe synchronization mode in federated learning refers to how the involved clients synchronize their local model updates with the aggregator node. We can find four distinct ways for synchronizing the aggregation process, including synchronous, asynchronous, semi-synchronous, and semi-asynchronous aggregation. We will elucidate in the following the advantages and disadvantages of each mode and summarize the provided description in Table2.\n\nSynchronous Aggregation.\nFederated learning is widely employed using the synchronous policy, where the participating devices upload their locally trained models simultaneously. By adopting this approach, the server performs the aggregation operation only after receiving updates from all clients, ensuring consistency in model updates and yielding improved accuracy. However, this synchronous aggregation method entails a significant drawback in the form of high communication overhead. This overhead can adversely impact the convergence speed, particularly in heterogeneous and expansive environments (e.g., when handling massive edge IoT devices).\n\nAsynchronous Aggregation.\nThe primary objective behind introducing asynchronous FL aggregation is to handle the stragglers’ issue in cross-device FL settings and to mitigate scalability concerns. In this approach, clients autonomously update their local models and communicate with the aggregator (e.g., the server) whenever available. Similarly, the server independently aggregates the received updates. As a result, asynchronous aggregation substantially diminishes the communication overhead compared to its synchronous counterpart, as clients do not need to await others’ updates. Yet, it is worth noting that this approach may lead to slower convergence, decreased accuracy, and a less stable model. The potential flaws arise from the fact that the updates might be outdated or conflicting, introducing uncertainties and complexities into the aggregation process.\n\nSemi-synchronous Aggregation.\nIt represents a hybrid approach that integrates synchronous and asynchronous aggregation techniques, offering a middle ground between their benefits. In semi-synchronous aggregation mode, the server waits for a subset of clients to complete their computations before aggregating their parameters. This approach strives to strike a delicate balance between convergence speed and communication overhead.\n\nSemi-asynchronous Aggregation.\nThis approach is akin to the process employed in semi-synchronous aggregation in how it combines synchronous and asynchronous perspectives. Regardless, what sets the semi-asynchronous method apart lies in which part of the aggregation pipeline is synchronous and which part is asynchronous. In a typical implementation of this approach, each client device conducts a specific number of local iterations, updating its model parameters asynchronously. Then, the clients upload their updates to the central server, which performs synchronous aggregation at fixed intervals. The challenge, however, resides in the optimal synchronization interval choice that requires careful calibration.\n\nAs a distributed machine learning paradigm, federated learning has been the subject of extensive research aimed at addressing not only privacy-preserving concerns but also attaining numerous other remarkable advancements and overcoming traditional limitations in machine learning. Proposing an aggregation method to serve these ambitious goals has drawn significant attention recently since it directly and potentially impacts the overall system performance. Moreover, the unique characteristics of each aggregation approach make it more suitable for some applications and environments, and less for others. This subsequent section highlights the motivations behind proposing various aggregation methods in the literature. Furthermore, to effectively categorize the diverse research visions, we have structured them into three essential families: process-related, model-related, and system-related objectives, as tabulated in Table2. Later in the paper (see Section4), we will present an extensive collection of the existing aggregation algorithms and evaluate each solution based on the associated configuration and the confirmed goals.\n\n\n================================================================================\n2.1.Federated Learning Basics\n================================================================================\nFederated Learning is a variant of Distributed Machine Learning paradigms where the data and the computational workload are distributed across multiple nodes connected to a network. This approach offers increased efficiency for training a robust and sophisticated ML model on large-scale datasets, which would be infeasible to process in one machine. Moreover, federated learning takes this concept further by focusing on data privacy. In the FL ecosystem, a set of participants calledclientscollaboratively train high-quality AI models under the orchestration of a remote server called aparameter serverwithout the need to access their local data. The crucial aspect is that the private data never leaves the client site, but only the locally-built models are transmitted to the server. In response, the server aggregates these updates from all entities to form a global model and communicates it back to the active participants. The iterative process of local-global model exchanges, illustrated in Fig.6, continues until achieving a desirable utility.\n\nThe generic FL procedure incorporates the following steps:\n\nSystem Initialization:In the first phase, it is the responsibility of the server to decide the intended task application (e.g., disease prediction, system recommendation, activity detection) as well as the essential model parameters (model type and architecture, learning rates, number of clients per round). Furthermore, the server initiates the global model gradients and selects a group of clients to be involved in the next iteration.\n\nDistributed Local Training:The parameter server broadcasts the initial global model across the chosen clients to kickstart the distributed learning process. Upon receiving the global model, each node independently trains a local model leveraging its respective data to generate the updated gradients. The locally optimized models are then uploaded back to the server.\n\nServer Aggregation:After receiving the updates from all participating clients, the server executes the aggregation algorithm to consolidate the gradients into a unified model (e.g., through averaging). Subsequently, the latest version of the global model is disseminated again to the involved entities.\n\nSteps 2 and 3 are iterated until the desired performance is achieved.\n\nIn a formal context, we designate the selected client indices asc=1,2,3,…,Cc=1,2,3,\\ldots,C, directed by the central server, whereC⊆NC\\subseteq N. Each node possesses its private datasetDc={Xc,Yc},where​Xc∈ℝ|Dc|×dD_{c}=\\{X_{c},Y_{c}\\},\\text{ where }X_{c}\\in\\mathbb{R}^{|D_{c}|\\times d}represents the feature space vector, andYc∈ℝ|Dc|×mY_{c}\\in\\mathbb{R}^{|D_{c}|\\times m}denotes the associated label matrix. During communication roundtt, clientccdownloads the latest global modelwtw_{t}and uses its local data for training. The primary objective is to optimize a loss function that penalizes inaccuracies in the model’s predictions for data points. Specifically, we denotel​(W;xi,yi)l(W;x_{i},y_{i})as the loss function for theii-th data point, with W representing a matrix of model weights in a neuron network, then the mathematical equation for the local loss function of client c is given in Equation1.\n\nSimilarly, we present the global loss function encompassing all clients in Equation2, whereinM=∑c=1C|Dc|M=\\sum_{c=1}^{C}|D_{c}|denotes the total number of data points across all C clients.\n\nDuring the aggregation phase, the parameter server leverages an aggregation algorithm to generate the global model for round t+1 once all clients complete uploading their local models. The first widely-recognized method is FedAVG, which performs straightforward averaging of all the model weights as introduced in the pseudo-code1. It is worth noting that the aggregation component plays a crucial role in FL since it facilitates the effective integration of knowledge learned by individual clients. Thus, it results in a more accurate and refined global model after each communication round. However, scholars have confirmed that this simplistic approach used in FedAVG may not fully address all the requirements of FL systems, which has spurred numerous research endeavors in this line of investigation.\n\nThe key foundation of FL is the data matrix, which defines the distinct distribution patterns of data sample space and data feature space. As depicted in Fig.7, FL can be classified into three categories depending on the data distribution of the participating clients, as follows:\n\nHorizontal Federated Learning:In Horizontal Federated Learning (HFL), the participating clients share the same type of data features while possessing different sets of data samples. To better understand this, let’s consider a medical scenario where different hospitals collaborate to develop an AI model for predicting disease outcomes. In this case, all hospitals present the patients using their medical records, which form a common feature space. However, the patients associated with each hospital may differ, meaning they correspond to distinct populations with non-overlapping sets of patients. Despite this difference, HFL enables hospitals aimed at joining forces to collectively train a robust AI model using their shared feature space while respecting patients’ privacy.\n\nVertical Federated Learning:In Vertical Federated Learning (VFL), the datasets of the engaged nodes have a common simple space, but with different data features, which results in a combined dataset that is more diverse in terms of data types. For instance, consider a credit risk prediction task where the clients are banks within one country, each having a separate dataset. Some banks have stored the credit history data of their customers, while others have financial transaction records. In this case, there is substantial intersection at the level of clientele they serve. By pooling together the knowledge of their unique datasets, they can create a more comprehensive credit risk prediction model with improved accuracy.\n\nFederated Transfer Learning:Federated Transfer Learning (FTL) came to the fore when both HFL and VFL would not be effective. FTL can handle datasets in which the data features and samples are distinct across clients. When the intersection of the overlapping data samples and features is negligible considering all the participating clients, Transfer Learning methods are applied to map the various feature spaces into a new shared representation space to learn all the sample labels.\n\n\n================================================================================\n2.2.Federated Learning Aggregation\n================================================================================\nOne of the crucial concerns of federated learning is how to combine the local models’ updates from different clients into a global model that can generalize well to new data, regardless of the diversity of the participating parties. The aggregation methods are an integral part of the federated learning ecosystem as they provide a solution to this challenge. Furthermore, it has been determined that the aggregation techniques hold promise as a research direction to address the various challenges inherent to federated learning. Different algorithms have been proposed in the literature, ranging from simple averaging to more sophisticated techniques. Nonetheless, the choice of a specific one to adopt can significantly affect the performance of all the FL system evaluation metrics, from the convergence speed and accuracy to communication cost and privacy. Therefore, it is indispensable to understand the strengths and weaknesses of different aggregation strategies and select the proper option for the particular application and data distribution at hand. In this section, we will describe the aggregation process in federated learning, providing a comprehensive classification from various perspectives, according to the federated learning configuration, including the federation scale, the topology, the updates synchronization mode, and the motivation for joining the collaborative training. These perspectives are illustrated in Fig.8. Later in the paper, we will review the latest advancements in aggregation techniques put forth in scholarly publications and delve into their respective methodologies that aim to fulfill the FL requisites (see Section4).\n\nAggregation methods in federated learning can be classified based on the number of active participants and the amount of data held by each one. Two main categories of aggregation methods based on the scale of the federation and the data distribution arecross-deviceaggregation andcross-siloaggregation, as depicted in Fig.9.\nTable2summarizes the unique features of each category, facilitating a clear understanding of their differences.\n\nCross-Device Aggregation.The advent of federated learning stemmed primarily from the need to facilitate efficient machine learning on mobile and edge devices, which typically possess constrained computational capabilities and limited storage capacity. In this cross-device setting, local models are trained on data generated by individual users, making it well-suited for scenarios where FL users are mobile, and their number is quite large, practically in the range of​1010{10}^{10}. Notably, the first example of cross-device federated learning was Google’s implementation of the Gboard mobile keyboard to build next-word prediction models.\n\nCross-Silo Aggregation.Given the promising outcomes of cross-device FL applications, a growing interest in extending FL usage into other applications has rapidly emerged. Cross-silos FL refers to the collective training between large institutions in various domains, including smart manufacturing, finance risk prediction for reinsurance, and medical data segmentation. The participants in cross-silo scenarios possess significant amounts of data and are relatively limited in number, typically less than 100 clients. In this context, it is reasonable to expect organizations such as hospitals and banks to be consistently involved in each round, owing to their substantial computing capabilities and relatively stable environments.\n\nThe architectural aspect of the federated learning process is also an essential factor for aggregation classification. The network topology that defines how the involved parties interact with each other or with a central server might be either centralized, decentralized, or hierarchical. Fig.10presents an illustration of the three architectures. While Table2sheds light on their characteristics, respectively.\n\nCentralized Federation.The centralized design is the most commonly used FL architecture, where a central server is responsible for learning coordination. This means that the client devices interact only with the server to send and receive model updates, in a synchronous or asynchronous communication regime. The single-server topology ensures that the whole training process is in the hand of one powerful actor, which helps avoid errors and facilitate a simple aggregation pipeline. However, it demands a robust and secure server that can handle extreme conditions (e.g., the high number of participants, the large model updates dimension) and alleviate the potential security and privacy attacks.\n\nDecentralized Federation.In decentralized FL architecture, clients can communicate with each other in a peer-to-peer (P2P) fashion to build a global model without needing a central server. The main idea behind this design is to release the dependency on a central entity. Besides, it weakens the impact of the server becoming malicious or curious while ensuring the model’s utility. On the flip side, it can become challenging to implement the Fl aggregation under a decentralized architecture that converges efficiently, especially in large-scale FL.\n\nHierarchical Federation.The novelty of hierarchical federation has come to the fore from the need to tackle the limitations of centralized and decentralized settings, specifically in scenarios where the participating clients are distributed across multiple levels or tiers of a hierarchy. This new approach allows for multi-level coordination by introducing an intermediate layer above the local clients for first-level aggregation, followed by a global one. Accordingly, the local workers are grouped in clusters considering different criteria, such as locations, data distributions, etc., and they only communicate with their associated parameter server, usually an edge or fog device, which is responsible for averaging the respected local updates. After a number of intra-cluster iterations, an inter-cluster model aggregation is performed, usually in the cloud, to establish a global consensus. Hence, the tree-like structure introduced by the hierarchical structure can reduce communication overhead, enhance privacy protection, and improve participation flexibility and scalability.\n\nThe synchronization mode in federated learning refers to how the involved clients synchronize their local model updates with the aggregator node. We can find four distinct ways for synchronizing the aggregation process, including synchronous, asynchronous, semi-synchronous, and semi-asynchronous aggregation. We will elucidate in the following the advantages and disadvantages of each mode and summarize the provided description in Table2.\n\nSynchronous Aggregation.\nFederated learning is widely employed using the synchronous policy, where the participating devices upload their locally trained models simultaneously. By adopting this approach, the server performs the aggregation operation only after receiving updates from all clients, ensuring consistency in model updates and yielding improved accuracy. However, this synchronous aggregation method entails a significant drawback in the form of high communication overhead. This overhead can adversely impact the convergence speed, particularly in heterogeneous and expansive environments (e.g., when handling massive edge IoT devices).\n\nAsynchronous Aggregation.\nThe primary objective behind introducing asynchronous FL aggregation is to handle the stragglers’ issue in cross-device FL settings and to mitigate scalability concerns. In this approach, clients autonomously update their local models and communicate with the aggregator (e.g., the server) whenever available. Similarly, the server independently aggregates the received updates. As a result, asynchronous aggregation substantially diminishes the communication overhead compared to its synchronous counterpart, as clients do not need to await others’ updates. Yet, it is worth noting that this approach may lead to slower convergence, decreased accuracy, and a less stable model. The potential flaws arise from the fact that the updates might be outdated or conflicting, introducing uncertainties and complexities into the aggregation process.\n\nSemi-synchronous Aggregation.\nIt represents a hybrid approach that integrates synchronous and asynchronous aggregation techniques, offering a middle ground between their benefits. In semi-synchronous aggregation mode, the server waits for a subset of clients to complete their computations before aggregating their parameters. This approach strives to strike a delicate balance between convergence speed and communication overhead.\n\nSemi-asynchronous Aggregation.\nThis approach is akin to the process employed in semi-synchronous aggregation in how it combines synchronous and asynchronous perspectives. Regardless, what sets the semi-asynchronous method apart lies in which part of the aggregation pipeline is synchronous and which part is asynchronous. In a typical implementation of this approach, each client device conducts a specific number of local iterations, updating its model parameters asynchronously. Then, the clients upload their updates to the central server, which performs synchronous aggregation at fixed intervals. The challenge, however, resides in the optimal synchronization interval choice that requires careful calibration.\n\nAs a distributed machine learning paradigm, federated learning has been the subject of extensive research aimed at addressing not only privacy-preserving concerns but also attaining numerous other remarkable advancements and overcoming traditional limitations in machine learning. Proposing an aggregation method to serve these ambitious goals has drawn significant attention recently since it directly and potentially impacts the overall system performance. Moreover, the unique characteristics of each aggregation approach make it more suitable for some applications and environments, and less for others. This subsequent section highlights the motivations behind proposing various aggregation methods in the literature. Furthermore, to effectively categorize the diverse research visions, we have structured them into three essential families: process-related, model-related, and system-related objectives, as tabulated in Table2. Later in the paper (see Section4), we will present an extensive collection of the existing aggregation algorithms and evaluate each solution based on the associated configuration and the confirmed goals.\n\n\n================================================================================\n3.Federated Learning Ecosystem\n================================================================================\nThe problem of heterogeneity in the FL settings has been extensively studied over the past few years(gao2022survey;xu2021asynchronous). It arises from the fact that the clients involved in the training process often have different systems and data characteristics, despite their shared goal of building a robust and powerful intelligent model.\nTo offer a broader perspective, we classify the encompassed types of heterogeneity in FL into three distinct categories:(i) statistical heterogeneity,(ii) system heterogeneity, and(iii) model heterogeneity. In the following, we will delve into the sources of heterogeneity as one of the most demanding challenges. The provided classification is summarized in Fig.11.\n\nStatistical heterogeneity refers to the non-independent and not identically distributed (non-IID) nature of data(li2020federated). The issue of non-IID data emerges as a consequence of the data generation paradigm in the context of FL systems. The traditional ML models assume the data to be in IID distribution, which stands in contrast to the real-life situation of collaborative training, where each device collects data differently depending on the user’s needs, preferences, location, and available resources(criado2022non). As a result, the assembled datasets will contain dissimilar data features, target class distributions, and even unbalanced sizes. Technically, it means that the data held locally in a single client can not be representative of the overall data distribution across all the active participants. Hence, the development of an effective federated learning framework will be compounded by an additional layer of complexity. The challenge is to propose a global model that can satisfy both a high level of generalization and an optimal personalization that accounts for the unique characteristics of each client(tan2022towards).\n\nTo dig deeper into the possible causes of statistical heterogeneity we divide the non-IID data distribution into two classes:violations of identicalnessandviolations of independence.\n\nAs mentioned in(kairouz2021advances), the non-Identical data can pertain to five distinct subclasses:\n\nFeature distribution skew.\nThis scenario occurs when the input feature space varies across clients even if their knowledge is the same.\n\nLabel distribution skew.\nIt arises due to regional differences, which can impact the label distribution.\n\nSame label, different features.\nFor the same label, disparate vectors of input features may be associated.\n\nSame features, different labels.\nSince users have personal preferences and geo-regions, one vector of input feature may lead to distinct labels.\n\nQuantity skew or unbalancedness.\nClients may have vastly varying amounts of collected data, depending on their device capabilities.\n\nBesides the effects of non-identical data distribution, there are common patterns of data deviation from being independently drawn from an overall distribution. For example, if the data is in an insufficiently-random order (e.g. ordered by time or/and by localization), it will cause a cycling situation in which a regime of data sample permutation is established.\n\nThe heterogeneity of the federated learning ecosystem may also stem from the varying nature of the device systems employed by each client. When a group of devices trains over different datasets, they often use varying hardware. The heterogeneity of device systems can be observed through differences in hardware capabilities (CPU, GPU, memory), network connectivity (4G, 5G, WiFi), and resource availability (battery power and lifespan)(jiang2022towards;fedlbs24iwcmc). This diversity leads to disparate computation and storage capacities, communication efficiency, and resource availability across a vast range. To illustrate the major issues resulting from this dispersion of client systems, we consider the following situations(xu2021asynchronous):\n\nThe issue of stragglers is a common problem in FL settings. It arises in collaborative training as devices often suffer from slow network connectivity and constrained resource availability. Consequently, they may become offline unexpectedly due to unreliable connections. These conditions hamper their ability to be constantly active in the training process. The described phenomenon is referred to, as the ”stragglers issue”(mcmahan2017communication)or ”clients dropout”(aledhari2020federated)where the server is compelled to wait inefficiently for those unreliable clients to upload their local updates.\n\nWithout adopting an effective mechanism for client selection, faster clients who have completed their local training are held up by slower or unreliable clients who have fallen behind(wang2021field). Thus, the aggregation phase will witness significant delays leading to an undesirable impact on the convergence rate of the global model, or even worse, impeding it from convergence at all.\n\nA poor client selection strategy can also result in infrequently picking competent devices to join a communication round. It means that the exceptional computational abilities of some devices will not be thoroughly exploited through the classical FL protocol.\n\nWhilst federated learning assures the data privacy held separately on clients’ sites, the potential privacy threats exposed by sharing only model parameters have hindered certain business advancements from seeing the light(wahab2021federated). In fact, given the inherent heterogeneity of data and device resources in FL environments, the objective and motivation behind joining such collaborative training may differ across various parties, depending on their specific requirements(li2021survey). Model heterogeneity refers to the client’s willingness to design their separate local model independently from each other. However, the traditional averaging-based aggregation method lacks flexibility when each client trains its model in a black-box manner to the other clients. To offer a more comprehensive understanding of this type of heterogeneity, we organize it into three subclasses that often exhibit simultaneously in real-world scenarios.\n\nType-based model heterogeneity.\n\nVarious machine learning models can be appropriate for the same task at hand. The selection of the best-fitted model depends on the type of data features and characteristics of each client. Some may opt for aLinearmodel (e.g. Linear Regression, Ridge Regression), While others may choose to adopt aDeep Learningmodel such as a Neural Network (e.g. CNN, DNN), orTreemodel (e.g. Decision Tree, Random Forest)(zhang2021survey). Consider, for instance, two hospitals with different data types: one may hold a dataset of images such as CT scans and MRIs. At the same time, the other entity may possess medical records in tabular form. In such cases, regardless of sharing the same goal of prediction, the former may prefer to adopt a Convolutional Neural Network (CNN), while the latter may find a Decision Tree model more appropriate for their data type.\n\nSize-based model heterogeneity.\n\nDue to system heterogeneity, adjustments to the trained model size are desirable to match the available resource restrictions(gao2022survey). For example, we can build a human activity recognition model using data collected from smartphones and wearable devices. Although smartphones have powerful computation resources, wearable devices can capture more precise movement data with limited computational resources. Consequently, a larger model can be trained for smartphones, whereas a lightweight model is more appropriate for wearable devices.\n\nArchitecture-based model heterogeneity.\n\nWhen aiming for an FL solution, even if the participating entities have reached a consensus on the choice of model type and dedicated resources, they may still be unwilling to divulge the details of their model architecture. Instead, they may prefer to execute the FL process in a black box fashion without communicating any information about the neural network’s depth, the loss function, the optimizer, or any other pertinent properties.\n\nTo summarize, handling the diverse heterogeneity types in FL is a growing consideration. Nonetheless, implementing a tailored aggregation method that can uphold this diversity is still a significant hurdle to overcome(gao2022survey).\n\nEnhancing model performance and dealing with substandard data is not exclusive to federated learning, rather, these challenges are present in various machine learning techniques. Nevertheless, the peculiarity of federated learning’s distributed nature brings a unique challenge to communication efficiency(almanifi2023communication). Adopting a federated learning mechanism, as opposed to the traditional centralized ML settings, mandates scrutiny of the updates’ transmission efficiency. On the one hand, the federated learning architecture enables the synchronization of training models across multiple sites, resulting in reduced computation time. However, on the other hand, this can lead to an onerous increase in communication costs as the convergence rate slows down due to the large exchanged model size or the restricted qualification of the active devices(sun2021decentralized).\n\nOne communication round in federated learning consists of two types of transmission:upstream communicationanddownstream communication. Upstream communication describes the process wherein clients transmit the updated local model to the server. Conversely, downstream communication pertains to the procedure by which clients acquire the current global model from the server. These operations are reiterated until a powerful global model is achieved. Several survey papers have approached the optimization challenge of achieving efficient communication from various standpoints(shahid2021communication;jiang2022towards;zhao2023towards;almanifi2023communication). According to(almanifi2023communication), communication is deemed efficient by the ability to transmit data through a reliable channel while expending minimal energy. More technically, efficiency is attained by ensuring that data exchanges in both downstream and upstream channels incur no overhead and consume the minimum resources.\n\nThe present section will examine the impediments that stunt efficient communication between clients and servers. Fig.12depicts these obstacles in three distinct classes.\n\nAs stated in section3.1, the coexistence of various types of heterogeneity represents a formidable challenge to the successful implementation of federated learning. More specifically, it is well known that machine learning techniques are intrinsically power-intensive, and the concomitant presence of heterogeneous data, models, and device resources exacerbates the issue of attaining a desirable communication efficiency. For instance, in situations where millions of devices communicate with a remote server with no selection scheme, some devices may experience battery drain and drop out of training, while others may remain idle despite possessing superior competencies. This leads to a significant deterioration in communication efficiency.\n\nThe network conditions, including bandwidth, reliability, and connectivity, can be a source of disruption in the federated learning process(10183138). This is because some participating devices may suffer from insufficient bandwidth, which results in unreliable communication with the server. Additionally, differences in upload and download speeds, or disparities in the overall network reliability across selected clients, can give rise to potential bottlenecks that impede the learning process(shahid2021communication). Furthermore, the communication channels are often noisy and fading, which slows down the convergence rate and reduces the global model performance(zhao2023towards).\n\nTraditional federated learning, characterized by synchronized and centralized aggregation, presents significant communication hurdles. These challenges can manifest in several forms, such as the stragglers’ occurrence, inefficient energy utilization, fluctuating network conditions, and disparities in resource availability among devices, leading faster devices to remain idle for extended periods. Therefore, it becomes imperative to explore alternative aggregation mechanisms as viable solutions to facilitate efficient communication(xu2021asynchronous).\n\nDisseminating model parameters in a distributed environment introduces novel risks and vulnerabilities to the overall system’s security and privacy(bouacida2021vulnerabilities). Given that the federated learning paradigm is preferred when security and privacy concerns are of great importance, it is crucial to draw attention to these challenges and explore the available defenses and privacy-preserving techniques. Generally, the security and privacy attacks can be attributed to three possible adversaries: a malicious server, an insider adversary, or an outsider adversary.\n\nNumerous studies have classified the existing attacks and vulnerabilities in the FL environment from various perspectives(rodriguez2023survey), from general targeted and untargeted attacks(wahab2021federated)In our work, we account for the principal components of the FL pipeline as probable attack targets. We have thus organized the security and privacy attack surfaces into three primary classes (Client as a Target, Server as a Target, and Aggregation Process as a Target), with each class further divided into several subclasses. Fig.13illustrates this categorization. We believe this hierarchical classification facilitates a deep comprehension and expedites the knowledge identification for researchers interested in securing FL systems.\n\nIn decentralized learning, where the server is not aware of the reliability of the orchestrated clients, setting defensive countermeasures in case of client deviation becomes challenging. This limitation is known as theclient unreliabilityproblem, referring to the inability of the server to detect whether a client’s behavior is normal or deviated from the expected protocol(ma2021federated). This vulnerability opens the door for potential attacks exploiting various elements on the client side. To systematically categorize the threats in this class, we have classified them as follows:\n\nData-based Attacks.During data preprocessing, cleaning operations offer adversaries potential openings(ma2021federated). For instance, thedata poisoning attackis a common threat to the integrity of the training dataset in FL(hallaji2022federated). An attacker with access to the local data can harm the accuracy of the learned model by tampering with or adding malicious data to the training set, resulting in a biased or impaired global model. Two common types of data poisoning attacks are clean-label and dirty-label attacks(qammar2022federated). Clean-label attacks(shafahi2018poison)manipulate local input data without altering the labels. Conversely, dirty-label attacks(lim2020federated)modify data sample labels, often using label-flipping or toxic sample generation, making them difficult to mitigate as the adversary can change labels without altering data features. For example, in a handwritten digit prediction, a label-flipping attack could involve flipping all the digits 3s into 5s and vice versa, causing the model to predict incorrectly, as illustrated in Fig.14.\n\nBackdoorsare also data-based attacks(gu2017badnets), aiming to deteriorate the performance of a specific subtask while preserving the performance of the overall model task. By altering data characteristics, an adversary can induce the model to respond according to its intentions when the input contains the backdoor features(zhang2023survey). Furthermore, even without direct exchange of raw data, transferring model updates does not ensure complete privacy protection(yin2021comprehensive). Hence, there remains a risk ofinformation leakage, as demonstrated in prior studies(hitaj2017deep;melis2019exploiting).\n\nLocal Model-based Attacks.During training,model poisoningattacks, often more efficient than data poisoning attacks, target the integrity of the FL process. Malicious parties, whether participating clients or external adversaries, can alter local updates before submitting them to the server. In the FL environment, where ensuring the trustworthiness of all active devices is not always feasible, preventing such attacks becomes challenging(wang2022defense).\n\nTraining-based Attacks.Themanipulation of training rulesis a technique for compromising the computation and the global model’s availability in federated learning. If an attacker gains control over one client, they could adjust the training hyperparameters, such as learning rate, local epochs, and batch size, to delay the convergence rate or even halt the global model’s learning process(bouacida2021vulnerabilities).\nA different approach for disrupting the training is by usingGenerative Adversarial Networks(GANs). A GAN-trained model enables the attacker to reconstruct and control benign-like users’ data, resulting in sensitive information disclosure and compromising the global model by injecting poisoned updates(hitaj2017deep;zhang2019poisoning).\n\nIn federated learning, the server plays a crucial role by holding essential information about the model’s architecture and receiving the local user’s weight values in each round. Therefore, it becomes an attractive target for attacks. This section categorizes server-side attacks into three main categories as follows:\n\nFalsification.During the inference phase,evasion attacksaim to fool the target model by introducing subtle variations to the input data(mothukuri2021survey).\nOne widely-used technique for evading ML models involves adversarial samples, wherein an attacker alters test samples to closely resemble the original data. Yet, they are carefully determined according to the model’s sensitivity to yield a class change(wang2023potent). For example, an attacker might add a small amount of noise to an image of a panda, causing the model to identify it as a gibbon mistakenly(liu2022threats). See Fig.15.\nAdditionally, we bring into this category the problem ofverifiability(bouacida2021vulnerabilities), which concerns the user’s and server’s ability to ascertain that all participants are working honestly without implicitly conducting any curious behavior that may reveal private information or impair the federation utility.\n\nPerformance Degradation.In traditional FL, a malicious or compromised server can steal private information or easily manipulate the global model to exploit the shared computation in building malicious tasks. Besides, the QoS in FL applications mainly relies on the server robustness to prevent adversary intrusions. Specifically, an unstable server exposes the entire system to the vulnerability of theSingle Point of Failure attack(qammar2022securing). In other scenarios, a compromised participant may have an alternative goal beyond sabotaging the model. Instead, they may seek to disrupt the process by submitting fake updates until it crushes. Since the server is typically unaware of such conduct, this operation, commonly known as aDistributed Denial of Service(DDoS) attack, will persist and paralyze the entire federated learning system(qammar2022securing).Clients’ unavailabilityis another issue that can slow down the convergence of the global model(mothukuri2021survey). As outlined in Section3.1, clients may dropout of the training due to limited device resources or network connectivity issues, leaving the server in an unproductive waiting state.\n\nPrivacy Data Leaks.The privacy leakage issue has attracted significant attention(geiping2020inverting;yin2021comprehensive). Although the row data never leaves the client’s device, exchanging the gradients between the active devices and the server engenders a serious privacy leakage. Moreover, after publishing the final model, inner adversaries or outsiders may attempt to infer sensitive information regarding a subject or a dataset.Inference attacks(nasr2019comprehensive)are a common threat to privacy during training and model deployment. Two common types of inference attacks are membership inference and properties inference. A membership inference(hu2022membership)intends to determine whether a particular sample belongs to the training dataset. For instance, an attacker might try to identify if a patient’s medical record was included in a disease prediction model, this could reveal that the patient has that condition. A property inference(melis2019exploiting), on the other hand, attempts to infer characteristics of the training data. In particular, these properties might be unrelated to the primary learning task. For example, in anage predictionmodel, this could involve inferring ifglasses-wearerstend to be younger or older.\n\nThe aggregation process is a vital component of distributed learning, where convergence over this environment occurs after hundreds to thousands of communication rounds. However, an insecure communication channel increases vulnerability to privacy thefts and security menaces, particularly when subjected to external attacks. We discuss and categorize, in this section, prevalent attacks targeting the aggregation process.\n\nUnreliable Communication.Many types of potential attacks might come from external actors. For instance,Eavesdropperscan probe the intermediate training updates (e.g., weights or gradients) or the final model (e.g., weights or the query results provided by a published API) by intercepting the communication between FL actors(wang2019eavesdrop). By doing so, they can either gain access to confidential information or substitute the original updates with crafted ones(yin2021comprehensive).\nIn addition, if an outsider executes aman-in-the-middle attack, the updates may be stolen, adjusted, or deviated from their desired destination.\n\nRobustness.From the training phase standpoint, thefree-rider attack(lin2019free;fraboni2021free)poses a distinct threat to the FL aggregation. In this attack, a participant mimics benign client behavior to acquire the global model without contributing to learning. The attacker stays passive, submitting meaningless updates or not updating at all, conserving local resources and avoiding data sharing while benefiting from the improved model and shared computing power(qammar2022federated). Hence, various risks outlined above render anon-robust aggregationalgorithm ineffective in protecting FL systems from potential harm. Consequently, rather than bolstering participants with a robust model, the FL approach could yield an impaired model, leading to erroneous decision-making and severe privacy breaches. Therefore, a robust aggregation method is paramount for upholding the FL integrity(10062923).\n\n\n================================================================================\n3.1.Heterogeneity In Federated Learning Ecosystem\n================================================================================\nThe problem of heterogeneity in the FL settings has been extensively studied over the past few years(gao2022survey;xu2021asynchronous). It arises from the fact that the clients involved in the training process often have different systems and data characteristics, despite their shared goal of building a robust and powerful intelligent model.\nTo offer a broader perspective, we classify the encompassed types of heterogeneity in FL into three distinct categories:(i) statistical heterogeneity,(ii) system heterogeneity, and(iii) model heterogeneity. In the following, we will delve into the sources of heterogeneity as one of the most demanding challenges. The provided classification is summarized in Fig.11.\n\nStatistical heterogeneity refers to the non-independent and not identically distributed (non-IID) nature of data(li2020federated). The issue of non-IID data emerges as a consequence of the data generation paradigm in the context of FL systems. The traditional ML models assume the data to be in IID distribution, which stands in contrast to the real-life situation of collaborative training, where each device collects data differently depending on the user’s needs, preferences, location, and available resources(criado2022non). As a result, the assembled datasets will contain dissimilar data features, target class distributions, and even unbalanced sizes. Technically, it means that the data held locally in a single client can not be representative of the overall data distribution across all the active participants. Hence, the development of an effective federated learning framework will be compounded by an additional layer of complexity. The challenge is to propose a global model that can satisfy both a high level of generalization and an optimal personalization that accounts for the unique characteristics of each client(tan2022towards).\n\nTo dig deeper into the possible causes of statistical heterogeneity we divide the non-IID data distribution into two classes:violations of identicalnessandviolations of independence.\n\nAs mentioned in(kairouz2021advances), the non-Identical data can pertain to five distinct subclasses:\n\nFeature distribution skew.\nThis scenario occurs when the input feature space varies across clients even if their knowledge is the same.\n\nLabel distribution skew.\nIt arises due to regional differences, which can impact the label distribution.\n\nSame label, different features.\nFor the same label, disparate vectors of input features may be associated.\n\nSame features, different labels.\nSince users have personal preferences and geo-regions, one vector of input feature may lead to distinct labels.\n\nQuantity skew or unbalancedness.\nClients may have vastly varying amounts of collected data, depending on their device capabilities.\n\nBesides the effects of non-identical data distribution, there are common patterns of data deviation from being independently drawn from an overall distribution. For example, if the data is in an insufficiently-random order (e.g. ordered by time or/and by localization), it will cause a cycling situation in which a regime of data sample permutation is established.\n\nThe heterogeneity of the federated learning ecosystem may also stem from the varying nature of the device systems employed by each client. When a group of devices trains over different datasets, they often use varying hardware. The heterogeneity of device systems can be observed through differences in hardware capabilities (CPU, GPU, memory), network connectivity (4G, 5G, WiFi), and resource availability (battery power and lifespan)(jiang2022towards;fedlbs24iwcmc). This diversity leads to disparate computation and storage capacities, communication efficiency, and resource availability across a vast range. To illustrate the major issues resulting from this dispersion of client systems, we consider the following situations(xu2021asynchronous):\n\nThe issue of stragglers is a common problem in FL settings. It arises in collaborative training as devices often suffer from slow network connectivity and constrained resource availability. Consequently, they may become offline unexpectedly due to unreliable connections. These conditions hamper their ability to be constantly active in the training process. The described phenomenon is referred to, as the ”stragglers issue”(mcmahan2017communication)or ”clients dropout”(aledhari2020federated)where the server is compelled to wait inefficiently for those unreliable clients to upload their local updates.\n\nWithout adopting an effective mechanism for client selection, faster clients who have completed their local training are held up by slower or unreliable clients who have fallen behind(wang2021field). Thus, the aggregation phase will witness significant delays leading to an undesirable impact on the convergence rate of the global model, or even worse, impeding it from convergence at all.\n\nA poor client selection strategy can also result in infrequently picking competent devices to join a communication round. It means that the exceptional computational abilities of some devices will not be thoroughly exploited through the classical FL protocol.\n\nWhilst federated learning assures the data privacy held separately on clients’ sites, the potential privacy threats exposed by sharing only model parameters have hindered certain business advancements from seeing the light(wahab2021federated). In fact, given the inherent heterogeneity of data and device resources in FL environments, the objective and motivation behind joining such collaborative training may differ across various parties, depending on their specific requirements(li2021survey). Model heterogeneity refers to the client’s willingness to design their separate local model independently from each other. However, the traditional averaging-based aggregation method lacks flexibility when each client trains its model in a black-box manner to the other clients. To offer a more comprehensive understanding of this type of heterogeneity, we organize it into three subclasses that often exhibit simultaneously in real-world scenarios.\n\nType-based model heterogeneity.\n\nVarious machine learning models can be appropriate for the same task at hand. The selection of the best-fitted model depends on the type of data features and characteristics of each client. Some may opt for aLinearmodel (e.g. Linear Regression, Ridge Regression), While others may choose to adopt aDeep Learningmodel such as a Neural Network (e.g. CNN, DNN), orTreemodel (e.g. Decision Tree, Random Forest)(zhang2021survey). Consider, for instance, two hospitals with different data types: one may hold a dataset of images such as CT scans and MRIs. At the same time, the other entity may possess medical records in tabular form. In such cases, regardless of sharing the same goal of prediction, the former may prefer to adopt a Convolutional Neural Network (CNN), while the latter may find a Decision Tree model more appropriate for their data type.\n\nSize-based model heterogeneity.\n\nDue to system heterogeneity, adjustments to the trained model size are desirable to match the available resource restrictions(gao2022survey). For example, we can build a human activity recognition model using data collected from smartphones and wearable devices. Although smartphones have powerful computation resources, wearable devices can capture more precise movement data with limited computational resources. Consequently, a larger model can be trained for smartphones, whereas a lightweight model is more appropriate for wearable devices.\n\nArchitecture-based model heterogeneity.\n\nWhen aiming for an FL solution, even if the participating entities have reached a consensus on the choice of model type and dedicated resources, they may still be unwilling to divulge the details of their model architecture. Instead, they may prefer to execute the FL process in a black box fashion without communicating any information about the neural network’s depth, the loss function, the optimizer, or any other pertinent properties.\n\nTo summarize, handling the diverse heterogeneity types in FL is a growing consideration. Nonetheless, implementing a tailored aggregation method that can uphold this diversity is still a significant hurdle to overcome(gao2022survey).\n\n\n================================================================================\nViolations of Identicalness\n================================================================================\nAs mentioned in(kairouz2021advances), the non-Identical data can pertain to five distinct subclasses:\n\nFeature distribution skew.\nThis scenario occurs when the input feature space varies across clients even if their knowledge is the same.\n\nLabel distribution skew.\nIt arises due to regional differences, which can impact the label distribution.\n\nSame label, different features.\nFor the same label, disparate vectors of input features may be associated.\n\nSame features, different labels.\nSince users have personal preferences and geo-regions, one vector of input feature may lead to distinct labels.\n\nQuantity skew or unbalancedness.\nClients may have vastly varying amounts of collected data, depending on their device capabilities.\n\n\n================================================================================\nViolations of Independence\n================================================================================\nBesides the effects of non-identical data distribution, there are common patterns of data deviation from being independently drawn from an overall distribution. For example, if the data is in an insufficiently-random order (e.g. ordered by time or/and by localization), it will cause a cycling situation in which a regime of data sample permutation is established.\n\n\n================================================================================\nThe stragglers problem\n================================================================================\nThe issue of stragglers is a common problem in FL settings. It arises in collaborative training as devices often suffer from slow network connectivity and constrained resource availability. Consequently, they may become offline unexpectedly due to unreliable connections. These conditions hamper their ability to be constantly active in the training process. The described phenomenon is referred to, as the ”stragglers issue”(mcmahan2017communication)or ”clients dropout”(aledhari2020federated)where the server is compelled to wait inefficiently for those unreliable clients to upload their local updates.\n\n\n================================================================================\nLow round time efficiency\n================================================================================\nWithout adopting an effective mechanism for client selection, faster clients who have completed their local training are held up by slower or unreliable clients who have fallen behind(wang2021field). Thus, the aggregation phase will witness significant delays leading to an undesirable impact on the convergence rate of the global model, or even worse, impeding it from convergence at all.\n\n\n================================================================================\nLow resource utilization\n================================================================================\nA poor client selection strategy can also result in infrequently picking competent devices to join a communication round. It means that the exceptional computational abilities of some devices will not be thoroughly exploited through the classical FL protocol.\n\n\n================================================================================\n3.2.Communication Efficiency in Federated Learning Ecosystem\n================================================================================\nEnhancing model performance and dealing with substandard data is not exclusive to federated learning, rather, these challenges are present in various machine learning techniques. Nevertheless, the peculiarity of federated learning’s distributed nature brings a unique challenge to communication efficiency(almanifi2023communication). Adopting a federated learning mechanism, as opposed to the traditional centralized ML settings, mandates scrutiny of the updates’ transmission efficiency. On the one hand, the federated learning architecture enables the synchronization of training models across multiple sites, resulting in reduced computation time. However, on the other hand, this can lead to an onerous increase in communication costs as the convergence rate slows down due to the large exchanged model size or the restricted qualification of the active devices(sun2021decentralized).\n\nOne communication round in federated learning consists of two types of transmission:upstream communicationanddownstream communication. Upstream communication describes the process wherein clients transmit the updated local model to the server. Conversely, downstream communication pertains to the procedure by which clients acquire the current global model from the server. These operations are reiterated until a powerful global model is achieved. Several survey papers have approached the optimization challenge of achieving efficient communication from various standpoints(shahid2021communication;jiang2022towards;zhao2023towards;almanifi2023communication). According to(almanifi2023communication), communication is deemed efficient by the ability to transmit data through a reliable channel while expending minimal energy. More technically, efficiency is attained by ensuring that data exchanges in both downstream and upstream channels incur no overhead and consume the minimum resources.\n\nThe present section will examine the impediments that stunt efficient communication between clients and servers. Fig.12depicts these obstacles in three distinct classes.\n\nAs stated in section3.1, the coexistence of various types of heterogeneity represents a formidable challenge to the successful implementation of federated learning. More specifically, it is well known that machine learning techniques are intrinsically power-intensive, and the concomitant presence of heterogeneous data, models, and device resources exacerbates the issue of attaining a desirable communication efficiency. For instance, in situations where millions of devices communicate with a remote server with no selection scheme, some devices may experience battery drain and drop out of training, while others may remain idle despite possessing superior competencies. This leads to a significant deterioration in communication efficiency.\n\nThe network conditions, including bandwidth, reliability, and connectivity, can be a source of disruption in the federated learning process(10183138). This is because some participating devices may suffer from insufficient bandwidth, which results in unreliable communication with the server. Additionally, differences in upload and download speeds, or disparities in the overall network reliability across selected clients, can give rise to potential bottlenecks that impede the learning process(shahid2021communication). Furthermore, the communication channels are often noisy and fading, which slows down the convergence rate and reduces the global model performance(zhao2023towards).\n\nTraditional federated learning, characterized by synchronized and centralized aggregation, presents significant communication hurdles. These challenges can manifest in several forms, such as the stragglers’ occurrence, inefficient energy utilization, fluctuating network conditions, and disparities in resource availability among devices, leading faster devices to remain idle for extended periods. Therefore, it becomes imperative to explore alternative aggregation mechanisms as viable solutions to facilitate efficient communication(xu2021asynchronous).\n\n\n================================================================================\n3.3.Security and Privacy in Federated Learning Ecosystem\n================================================================================\nDisseminating model parameters in a distributed environment introduces novel risks and vulnerabilities to the overall system’s security and privacy(bouacida2021vulnerabilities). Given that the federated learning paradigm is preferred when security and privacy concerns are of great importance, it is crucial to draw attention to these challenges and explore the available defenses and privacy-preserving techniques. Generally, the security and privacy attacks can be attributed to three possible adversaries: a malicious server, an insider adversary, or an outsider adversary.\n\nNumerous studies have classified the existing attacks and vulnerabilities in the FL environment from various perspectives(rodriguez2023survey), from general targeted and untargeted attacks(wahab2021federated)In our work, we account for the principal components of the FL pipeline as probable attack targets. We have thus organized the security and privacy attack surfaces into three primary classes (Client as a Target, Server as a Target, and Aggregation Process as a Target), with each class further divided into several subclasses. Fig.13illustrates this categorization. We believe this hierarchical classification facilitates a deep comprehension and expedites the knowledge identification for researchers interested in securing FL systems.\n\nIn decentralized learning, where the server is not aware of the reliability of the orchestrated clients, setting defensive countermeasures in case of client deviation becomes challenging. This limitation is known as theclient unreliabilityproblem, referring to the inability of the server to detect whether a client’s behavior is normal or deviated from the expected protocol(ma2021federated). This vulnerability opens the door for potential attacks exploiting various elements on the client side. To systematically categorize the threats in this class, we have classified them as follows:\n\nData-based Attacks.During data preprocessing, cleaning operations offer adversaries potential openings(ma2021federated). For instance, thedata poisoning attackis a common threat to the integrity of the training dataset in FL(hallaji2022federated). An attacker with access to the local data can harm the accuracy of the learned model by tampering with or adding malicious data to the training set, resulting in a biased or impaired global model. Two common types of data poisoning attacks are clean-label and dirty-label attacks(qammar2022federated). Clean-label attacks(shafahi2018poison)manipulate local input data without altering the labels. Conversely, dirty-label attacks(lim2020federated)modify data sample labels, often using label-flipping or toxic sample generation, making them difficult to mitigate as the adversary can change labels without altering data features. For example, in a handwritten digit prediction, a label-flipping attack could involve flipping all the digits 3s into 5s and vice versa, causing the model to predict incorrectly, as illustrated in Fig.14.\n\nBackdoorsare also data-based attacks(gu2017badnets), aiming to deteriorate the performance of a specific subtask while preserving the performance of the overall model task. By altering data characteristics, an adversary can induce the model to respond according to its intentions when the input contains the backdoor features(zhang2023survey). Furthermore, even without direct exchange of raw data, transferring model updates does not ensure complete privacy protection(yin2021comprehensive). Hence, there remains a risk ofinformation leakage, as demonstrated in prior studies(hitaj2017deep;melis2019exploiting).\n\nLocal Model-based Attacks.During training,model poisoningattacks, often more efficient than data poisoning attacks, target the integrity of the FL process. Malicious parties, whether participating clients or external adversaries, can alter local updates before submitting them to the server. In the FL environment, where ensuring the trustworthiness of all active devices is not always feasible, preventing such attacks becomes challenging(wang2022defense).\n\nTraining-based Attacks.Themanipulation of training rulesis a technique for compromising the computation and the global model’s availability in federated learning. If an attacker gains control over one client, they could adjust the training hyperparameters, such as learning rate, local epochs, and batch size, to delay the convergence rate or even halt the global model’s learning process(bouacida2021vulnerabilities).\nA different approach for disrupting the training is by usingGenerative Adversarial Networks(GANs). A GAN-trained model enables the attacker to reconstruct and control benign-like users’ data, resulting in sensitive information disclosure and compromising the global model by injecting poisoned updates(hitaj2017deep;zhang2019poisoning).\n\nIn federated learning, the server plays a crucial role by holding essential information about the model’s architecture and receiving the local user’s weight values in each round. Therefore, it becomes an attractive target for attacks. This section categorizes server-side attacks into three main categories as follows:\n\nFalsification.During the inference phase,evasion attacksaim to fool the target model by introducing subtle variations to the input data(mothukuri2021survey).\nOne widely-used technique for evading ML models involves adversarial samples, wherein an attacker alters test samples to closely resemble the original data. Yet, they are carefully determined according to the model’s sensitivity to yield a class change(wang2023potent). For example, an attacker might add a small amount of noise to an image of a panda, causing the model to identify it as a gibbon mistakenly(liu2022threats). See Fig.15.\nAdditionally, we bring into this category the problem ofverifiability(bouacida2021vulnerabilities), which concerns the user’s and server’s ability to ascertain that all participants are working honestly without implicitly conducting any curious behavior that may reveal private information or impair the federation utility.\n\nPerformance Degradation.In traditional FL, a malicious or compromised server can steal private information or easily manipulate the global model to exploit the shared computation in building malicious tasks. Besides, the QoS in FL applications mainly relies on the server robustness to prevent adversary intrusions. Specifically, an unstable server exposes the entire system to the vulnerability of theSingle Point of Failure attack(qammar2022securing). In other scenarios, a compromised participant may have an alternative goal beyond sabotaging the model. Instead, they may seek to disrupt the process by submitting fake updates until it crushes. Since the server is typically unaware of such conduct, this operation, commonly known as aDistributed Denial of Service(DDoS) attack, will persist and paralyze the entire federated learning system(qammar2022securing).Clients’ unavailabilityis another issue that can slow down the convergence of the global model(mothukuri2021survey). As outlined in Section3.1, clients may dropout of the training due to limited device resources or network connectivity issues, leaving the server in an unproductive waiting state.\n\nPrivacy Data Leaks.The privacy leakage issue has attracted significant attention(geiping2020inverting;yin2021comprehensive). Although the row data never leaves the client’s device, exchanging the gradients between the active devices and the server engenders a serious privacy leakage. Moreover, after publishing the final model, inner adversaries or outsiders may attempt to infer sensitive information regarding a subject or a dataset.Inference attacks(nasr2019comprehensive)are a common threat to privacy during training and model deployment. Two common types of inference attacks are membership inference and properties inference. A membership inference(hu2022membership)intends to determine whether a particular sample belongs to the training dataset. For instance, an attacker might try to identify if a patient’s medical record was included in a disease prediction model, this could reveal that the patient has that condition. A property inference(melis2019exploiting), on the other hand, attempts to infer characteristics of the training data. In particular, these properties might be unrelated to the primary learning task. For example, in anage predictionmodel, this could involve inferring ifglasses-wearerstend to be younger or older.\n\nThe aggregation process is a vital component of distributed learning, where convergence over this environment occurs after hundreds to thousands of communication rounds. However, an insecure communication channel increases vulnerability to privacy thefts and security menaces, particularly when subjected to external attacks. We discuss and categorize, in this section, prevalent attacks targeting the aggregation process.\n\nUnreliable Communication.Many types of potential attacks might come from external actors. For instance,Eavesdropperscan probe the intermediate training updates (e.g., weights or gradients) or the final model (e.g., weights or the query results provided by a published API) by intercepting the communication between FL actors(wang2019eavesdrop). By doing so, they can either gain access to confidential information or substitute the original updates with crafted ones(yin2021comprehensive).\nIn addition, if an outsider executes aman-in-the-middle attack, the updates may be stolen, adjusted, or deviated from their desired destination.\n\nRobustness.From the training phase standpoint, thefree-rider attack(lin2019free;fraboni2021free)poses a distinct threat to the FL aggregation. In this attack, a participant mimics benign client behavior to acquire the global model without contributing to learning. The attacker stays passive, submitting meaningless updates or not updating at all, conserving local resources and avoiding data sharing while benefiting from the improved model and shared computing power(qammar2022federated). Hence, various risks outlined above render anon-robust aggregationalgorithm ineffective in protecting FL systems from potential harm. Consequently, rather than bolstering participants with a robust model, the FL approach could yield an impaired model, leading to erroneous decision-making and severe privacy breaches. Therefore, a robust aggregation method is paramount for upholding the FL integrity(10062923).\n\n\n================================================================================\n4.Federated Learning Recent Techniques and Aggregation Strategies\n================================================================================\nAs broadly discussed earlier, the issue of heterogeneity is often a stumbling block when attempting to apply successful federated learning in real-world scenarios. This section explores the crucial role of implementing an aggregation method that addresses different types of heterogeneity while ensuring the FL model learns informative patterns from all available resources.\nWe classified the recent strategies in the literature into three distinct classes, as depicted in Fig.16.\n\nModel-oriented strategies focus on improving personalization through the manipulation of the global and local model architecture. An important decision in this regard is whether to limit the collaborative training to only the upper/lower layers of the model, enable users to modify a shared global model, personalize the entire model locally, or train different parts of the final model separately on each device. Please refer to Table2for a thoughtfully curated collection of scholarly publications that have made significant contributions to this area of research.\n\nParameter Decoupling\n\nThis paradigm aims to achieve personalized models and assuage the heterogeneity impact. It involves dividing the model parameters into two or more sets and optimizing each set separately.\nOne configuration of parameter decoupling entails alayer-based splitof the neural network model(arivazhagan2019federated), wherein the layers are segmented into two sets: base layers and personalized layers. This structure helps ensure the privacy of the personalized layers and results in a high degree of personalization.\n\nFor example, EPSL(lin2023efficient)and ModFL(liang2022modular)target personalization in resource-constrained environments. Alternatively, propose an optimal layer selection strategy for energy, time, and privacy trade-offs. Leveraging pre-trained BERT encoders for NLP, FedSplitBERT(lit2022federated)tackles both heterogeneity and communication challenges.Feature representationis another decoupling approach. For instance, the authors in(bui2019federated)have proposed the FURL method, which enables existing personalization techniques within FL by splitting model parameters. User-specific features remain private, while shared features are learned collaboratively. Another study in(rakotomamonjy2023personalisedx)has addressed the issue of heterogeneous raw data representation among FL clients. Their framework called FLIC employs local embedding functions to map the data into a common space. Similar approaches utilize feature anchor vectors(zhou2022fedfa), low-dimensional classifier(collins2021exploiting), and more(sun2021partialfed).\nIn essence, according to(li2021aggregate), parameter decoupling for privacy and personalization can be categorized into single-branch and multi-branch approaches. The former directly privatizes specific layers while aggregating the remaining ones via the server. The latter keeps the entire model shared but privatizes certain components.\n\nGlobal-Local Models Combination\n\nA slightly different approach involvescombining global and local models(criado2022non;hanzely2020federated). This technique is used to personalize the final model employed by each client instead of adopting one globally deployed model for all clients. Unlike standard FL, each client has two models: a global model trained collaboratively and a private local model for fine-tuning the FL outcome. This benefits scenarios with low correlation between local and global data distribution. The authors in(deng2020adaptive)advocate an APFL method that combines global and local models using an adaptively learned weight for improved personalization and generalization. Similarly, the framework in(zec2020specialized)leverages federated averaging and mixtures of experts to achieve personalized models viamodel interpolation.\n\nModel Split\n\nTo improve communication efficiency and tackle device heterogeneity, model split is a promising technique. This approach divides the model, often a neural network, into sub-models or branches. Each device then trains a specific portion, reducing the communication burden and computational cost per device.\nWithin this particular branch, the researchers in(dun2023efficient)offered AsyncDrop, as a new asynchronous solution to handle device heterogeneity in large-scale FL. This approach leverages dropout regularization, randomly masking a subset of neurons in each layer during training. This effectively creates sub-models where all layers are present but only a portion of neurons are active. Devices are then assigned sub-models for training based on their computational capabilities. In(cui2022fedbranch), the suggested FedBranch framwork adopts the strategy of model-splitting into a multi-branch neural network. Moreover, FedBranch employs a layer-wise aggregation to combine branch outputs and integrates a task offloading algorithm for efficient distribution of training tasks across branches. Building on the same foundation laid by(dun2023efficient), FedBranch approach assigns a suitable branch model to each participating client based on their computational resources. Finally, In(mori2022personalized), the authors have investigated another personalized approach using multi-branch architecture to establish pFedMB, enabling similar clients to automatically share knowledge without directly calculating the similarities, as with FedAMP(huang2021personalized)and FedFomo(zhang2020personalized).\n\nSynch: Synchronization mode {Synchronous, Asynchronous}.Users: Maximum active users used in experiments.Archi: Architecture {Centralized, Decentralized(P2P), Hierarchical}.Cm. E.: Communication Efficiency.Cp. E.: Computation Efficiency.Conv: Convergence Analysis.Pers: Personalization.Gen: Generalization.Fair: Fairness.Heter: Heterogeneity.Sec: Security.Priv: Privacy.Scal: Scalability.\n\nAggregation-oriented strategies involve optimizing various aspects of the aggregation process, including training hyperparameters, loss functions, gradient variances, convergence rates, and learning direction. The primary objective is to identify and implement the optimal aggregation environment that accelerates FL convergence while accommodating the unique characteristics of individual users. Table2delineates the sub-categories and furnishes instances of literature papers that pertain to this particular research area.\n\nServer Optimization\n\nApart from the architectural decision choice, another solution is to modify the server-side optimizers.Adaptive gradientmethods are extensively employed in traditional ML. Unlike fixed learning rates in vanilla gradient descent, which rely on either a constant rate or a preset schedule, adaptive methods adjust the rate on the fly based on the gradient magnitude. This flexibility has shown theoretical and practical advantages in FL(reddi2020adaptive), unlocking superior generalization performance ober non-adaptive methods including Adagrad(duchi2011adaptive), Adam(kingma2014adam), and Yogi(zaheer2018adaptive).\nMeanwhile, the authors in(li2023fedda)argue that server-side adaptive gradients alone do not fully leverage adaptive information. To address this, they propose FedDA a framework enabling each client to adjust its learning rate based on local gradients and past updates.\nAnother server-side optimization technique ismomentum. In federated learning, SGD with momentum averages gradients from clients while considering past updates, guiding the global model toward the right learning direction. In other words, it bolsters faster convergence and escapes from poor local minima.\nFor instance, the STEM algorithm(khanduri2021stem)utilizes momentum for both client and server updates, achieving an optimal balance between updates’ frequency and minibatch sizes. Similarly, FedGLOMO(das2022faster)leverages global and local momentum terms to reduce variance and accelerate convergence. These approaches, along with FedMom and FedNAG(huo2020faster;yang2022federated)(variants integrating Nesterov’s Accelerated Gradient), showcase the effectiveness of momentum in heterogeneous FL scenarios.\n\nRegularization\n\nRegularization, a technique to prevent overfitting in ML, can also combat client drift in FL settings. Client drift occurs when local models diverge from the global optimum due to heterogeneous data (Figure17). Regularization adds a penalty term to the loss function to penalize models that deviate too far, encouraging them to stay closer to the global model.\nRecent work incorporates dynamic regularization(acar2021federated), triplet term regularization(li2023fedtrip), but also integrates it with other techniques, such as knowledge distillation(luo2023improving)and stratified sampling(lu2023federated).\n\nHyper-Parameters Optimization (HPO)\n\nFLhyperparameter tuningprioritizes communication and computation efficiency over accuracy, in construct ML HPO focused on accuracy. This optimization accelerates convergence by adjusting factors like client selection, local training steps, and aggregation frequency – all crucial for balancing performance and efficiency(hefel24iwcmc).\n\nIn fact, FL grapples with a distinct challenge: optimizing hyperparameters for a distributed system. Here, two main approaches emerge:theoretic-based(luo2021cost;wu2021fast;shi2020device)andReinforcement Learning (RL)-basedmethods(guo2022auto;zhang2021deep;lu2020blockchain). Theoretical methods offer efficient solutions by simplifying the problem with environmental assumptions, which may not hold true in the face of data’s dynamism and lack of clear patterns. This is where RL-based methods shine. They treat the tuning task as a dynamic decision-making process, offering greater adaptability. A prime example is Dap-FL(chen2023dap). It implements a Deep Deterministic Policy Gradient (DDPG) algorithm to adjust clients’ learning rates and training epochs based on their progress and the global model. Auto-FedRL(guo2022auto)pushes the HPO boundaries even further. It doesn’t stop at a limited set of hyperparameters. Instead, it employs an online RL agent to dynamically adjust a larger spectrum of hyperparameters for both clients and the server.\n\nSynch: Synchronization mode {Synchronous, Asynchronous}.Users: Maximum active users used in experiments.Archi: Architecture {Centralized, Decentralized(P2P), Hierarchical}.Cm. E.: Communication Efficiency.Cp. E.: Computation Efficiency.Conv: Convergence Analysis.Pers: Personalization.Gen: Generalization.Fair: Fairness.Heter: Heterogeneity.Sec: Security.Priv: Privacy.Scal: Scalability.\n\nClient-oriented strategies aim to increase the involvement of the most reliable nodes with high-quality data and favorable learning capabilities. The main idea is to mitigate the negative impact of struggling nodes on the overall aggregation performance by carefully choosing the participating clients, evaluating the quality of their updates, or organizing them hierarchically to improve the averaging process. see Table2for a summary.\n\nWeighted Aggregation\n\nThe classical aggregation methods (e.g., FedAvg), struggle with real-world non-IID data, leading to suboptimal convergence and utility(khaled2020tighter;hsu2019measuring). To navigate this drawback,weighted aggregationinvolves assigning weights to local models to discriminate the importance of contributing users. This strategy acknowledges that updates from users with high-quality, relevant data are more valuable for the global model. To tackle this, the FAIR framework rests on three-component solution: 1) estimate each device’s contribution quality using historical records, 2) reward high-quality participation through a quality-aware incentive mechanism, and 3) automatically weight local models, ensuring best contributors have a stronger impact on the final model. Other weighting techniques include measuring loss variation(talukder2022computationally)and adopting a hierarchical multi-parameter weighting scheme(herabad2023communication).\n\nClient Selection\n\nThe objective of carefully choosing a subset of active clients to participate in a communication round is to optimize the performance of federated learning while considering the diverse nature of nodes. Theclient selectionmethods aim to make the most optimal use of the limited and heterogeneous clients’ resources, including data and computing capabilities. Various techniques beyond random selection have been proposed to accelerate the global convergence(fu2022client). These strategies involve sophisticated perspectives such as employing a scoring system based on past performance(cho2022flame)and prioritizing nodes with superior computing power and accuracy(lu2023towards).\n\nClient Clusturing.\n\nClient clustering avenue is inspired by the unsupervised clustering ML paradigm. Indeed, it groups clients with similar data distributions, addressing the challenge of data non-IIDness. As an alternative perspective deviating from adopting a single global model in traditional FL, client clustering allows for hierarchical knowledge transfer. Specifically, this involves training task-specific models for each cluster. Subsequently, the server aggregates the models from various clusters to enable high-level knowledge sharing.\nIn edge computing environments, both studies(wolfrath2022haccs)and(lu2023auction)leverage clustering to group edge devices based on their similar data distributions. The former work relies on update metadata (e.g., mean, variance), while the later directly analyzes local gradients for more accurate information. In recommendation systems,(imran2023refrs)leverages neural-based clustering to capture user preferences and group semantically similar user models. Another secure solution can be found in in(firdaus2023personalized).\n\nSynch: Synchronization mode {Synchronous, Asynchronous}.Users: Maximum active users used in experiments.Archi: Architecture {Centralized, Decentralized(P2P), Hierarchical}.Cm. E.: Communication Efficiency.Cp. E.: Computation Efficiency.Conv: Convergence Analysis.Pers: Personalization.Gen: Generalization.Fair: Fairness.Heter: Heterogeneity.Sec: Security.Priv: Privacy.Scal: Scalability.\n\nCommunication efficiency is one essential aspect of FL, yet it often poses a critical bottleneck. As outlined in Section3.2, factors like limited bandwidth, latency, and large models hinder efficient communication. Various optimization strategies have emerged in the literature, aiming to surmount these hurdles and expedite convergence. Fig.18provides a visual taxonomy of these practices, which we will delve into in this section.\n\nTypically, communication overhead arises when multiple transmitters attempt to send a significant amount of data to a central hub, as is the case with the client-server model exchange in federated training. This overhead is further exacerbated due to the limited resources and network bandwidth. To position the available solutions, we categorize them into two main approaches:reducing training latencyandadapting the network topology.\nTable2enumerates a selection of recent endeavors falling within the purview of these two methodologies.\n\nTraining Latency Reduction.\n\nOn the client side, the training latency is controlled by the local capabilities and workload. Despite the immutability of the former, the latter leaves room for incorporating inventive adjustments. We introduce in this category the subsequent solutions, including load balancing, Over-The-Air (OTA)-FL, and asynchronous aggregation.\n\nLoad Balancing.In order to mitigate the severe effect of FL clients’ disparities, many researchers suggest balancing the amount of data retained by each client. One such approach consists of turning RL techniques to determine the optimal amount of data that must be used in a training round for each client(shin2023federated). For instance, in(tu2020network), researchers have derived a convex optimization accounting for local resources and model accuracy to determine the most suitable clients for processing specific data points. In another investigation, the CATA-Fed system(jeong2022cluster)considers data diversity and data load when selecting clients. The goal of this scheduling algorithm is twofold: global bias alleviation with fair workload distribution. More strategies can be found in(trindade2022resource;morell2022optimising).\n\nOver-The-Air Computation.Over-the-air computation is a powerful strategy that strikes a balance between data privacy and effective knowledge sharing. Technically speaking, over-the-air computation stands for computing a nomographic function (e.g., mean) of distributed data from multiple transmitters. In contrast to the traditional computation-communication separation methods in FL, this design carries out parts of the aggregation processover-the-airby local devices to reduce the required bandwidth, thereby, speeding up the federated training process. In other words, the summation of the models’ gradient is carried out over the air in a distributed manner, and only the sums (not all the gradients) are transmitted to the aggregator to finally compute the sums’ average.\nAmidst numerous research endeavors(guo2021over;sifaou2022over), the researchers in(yang2022over)have explored the impact of noisy communication channels on OTA-FL. The developed ACPC-OTA-FL algorithm allows each client to flexibly ascertain its transmission power level and the number of local update steps, maximizing the utilization of available resources. In contrast, the CHARLES framework(mao2022charles)leverages the estimation of Channel State Information (CSI) to assess the effects of fading wireless channels within heterogeneous OTA-FL scenarios.\n\nAsynchronous aggregation.Observing the numerous limitations caused by the synchronicity assumption of the standard FL ecosystem, the research intention has been directed to release the federated learning environments from this strict requirement by leveraging the asynchronous aggregation scheme(yang2022efficient;taha2022unbounded).\n\nNetwork Topology Adjustment.\n\nNetwork topology refers to an architectural design that dedicates the connection and devices within a network. However, the conventional star topology commonly used in FL may not always be an efficient choice. Therefore, some researchers advise modifying the network design to enhance system efficiency. Intuitively, different topologies inherently incur varying communication costs, and then hopefully, selecting an optimized network topology will help achieve the desired efficiency level. To present the existing solutions in this regard, we bring two extensively adopted FL structures:hierarchical aggregationandadaptive network topology.\n\nHierarchical Aggregation.The hierarchical FL embraces a tree-like structure, allowing for partial aggregation(su2021secure). Proximate devices upload their updates to a small base station (SBS) for initial aggregation. Subsequently, a macro base station (MBS) conducts the final aggregation(10062841). In this setup, leveraging edge devices as SBSs within the modern FL systems has shown great potential in reducing communication bottlenecks(yi2022hfedmtl;singh2022dew).\n\nAdaptive Network Topology.The interplay of communication topology and training duration dilemma has attracted significant focus. From one side, a highly connected topology expedites the FL convergence. On the flip side, a more connected topology can also prolong the duration of a communication round. One contribution in this domain(marfoq2020throughput)relies on the max-plus algebra and leverages quantifiable network characteristics, including computation times, link latency, and transmission times to optimize system throughput, measured by the number of completed rounds per time unit. A different study(zhou2022communication)proposed a novel client-server interaction design. This approach empowers each client to decide whether or not to share its model updates based on two thresholds: a probability threshold that limits update frequency to prevent server overload and an informative model determination threshold that ensures only informative updates are transmitted.\n\nSynch: Synchronization mode {Synchronous, Asynchronous}.Users: Maximum active users used in experiments.Archi: Architecture {Centralized, Decentralized(P2P), Hierarchical}.Cm. E.: Communication Efficiency.Cp. E.: Computation Efficiency.Conv: Convergence Analysis.Pers: Personalization.Gen: Generalization.Fair: Fairness.Heter: Heterogeneity.Sec: Security.Priv: Privacy.Scal: Scalability.ANT: Adaptive Network Topology.\n\nAn additional avenue of focus in the efficiency field pertains to reducing data transmission costs. Several factors amplify the increased expenses associated with FL communication. Although many environmental factors remain beyond one’s control, other flexible elements related to the aggregation process offer opportunities for valuable contributions. For instance, the model size and the aggregation frequency present compelling areas for investigation. In Table2, we offer a compilation of the surveyed papers that converge with this specific domain.\n\nModel Size Reduction\n\nAnother captivating strategy to reduce communication overhead, deeply explored in Section4.3, is reducing the number of model parameters transmitted. Researchers argue that it is neither necessary nor efficient that each client must download and upload the complete in the federation process. Instead, they propose alternatives where only a relevant fraction of the global model is assigned to each client to be updated locally. One such configuration relies onmodel division, whether it is layer-based or parameter-representation-based. The second configuration ofupdate droppingtrims less significant neurons from the global model. Beyond model architecture changes, thecompressionstrategy has gained significant interest from the academic communities aiming to reduce energy consumption. Generally described, compression is the process by which the information is encoded using a smaller number of bits than that of the original representation, making it suitable for bandwidth-limited channels and lower energy requirements. Prior arts in this specific field fall into three lines as follows:\n\nQuantization.Quantization involves representing the neural network’s weights and activations with lower precision (i.e., fewer bits). For instance, by reducing the number of colors in a digital image, the file becomes smaller and takes less space. Similarly, quantization maps the full-precision floating point to a smaller set, making the model lighter for transmission.\nIn the pursuit of communication efficiency, QD-Compressor(jin2023design)is a dedicated proposal to large-scale DNN snapshots, precisely for failure-prone clusters in FL. Due to variations in parameter value ranges across layers, the Local-Sensitive Quantization module employs a layer-specific quantization strategy to dynamically adjust quantizers and the number of quantization bits among layers. Moreover, the Error Feedback Mechanism helps maintain high-quality restored models by averting quantization errors. In the same trajectory, the JoPEQ framework introduced in(lang2023joint)jointly integrates lossy compression and privacy augmentation strategies. The core idea lies in employing vector quantization to exploit the incurred distortion in injecting noises into model updates, fortifying the FL system against privacy breaches.\n\nSketching.The previous quantization mechanisms support only uniformly distributed data, which is not always the case for FL updates. The sketch algorithm is a probabilistic alternative that can retain key statistical properties and enable meaningful analysis. The sketching is a memory-saving solution that is used to estimate the model updates distribution in a single processing pass over the updates values. For instance, FetchSGD(rothchild2020fetchsgd)incorporates Count Sketch with momentum and error accumulation, enabling efficient communication with good recovery guarantees.\nWhile the proposal in(kollias2023sketch)leverages Locality Sensitive Hashing (LSH) sketching. This technique relies on the predicate that if two distant models are approximately “close,” there is no need to share them.\n\nSparsification.Intuitively, sparsification is the process by which a matrix becomes more sparse. A sparse matrix is a matrix whose zero elements are higher than those non-zero elements. The main advantage of having a sparse matrix is to save space by storing only the non-zero elements. Sparsification techniques are employed in federated learning to filter out and preserve only the most important parts of the locally trained models.\nStandard sparsification in FL can enhance communication efficiency but it may expose sensitive model parameters during aggregation. The work in(ergun2021sparsified)tackles this concern with SparseSecAggn, an approach for secure sparsification in FL using pairwise sparsification. Shared random masks between devices ensure their aggregated masked models nullify each other. For model compression in analog FL, the authors in(ahn2022model)suggested a novel lossless compression technique called Pattern-Shared Sparsification (PSS). Unlike prior methods where devices sparsify gradients independently (i.e., local top-k sparsification), PSS utilizes a collective sparsification pattern across all devices.\nOther scholars have demonstrated that the hybridization of the aforementioned compression mechanisms offers a potent resolution, as exemplified in(malekijoo2021fedzip).\n\nTo summarize, a perfect compression method does not exist. It either compromises information loss or costs higher computation. From this computation-information trade-off lens, two primary approaches exist lossy and lossless compression.Lossy compressionmethods prioritize efficiency by sacrificing some information fidelity(liu2021hierarchical). Conversely,lossless compressionassures no information loss but comes at the cost of higher computational requirements(zhao2022cork).\n\nAggregation Frequency Reduction.\n\nIn a notable finding from the work in(lin2017deep), it was demonstrated that a remarkable 99% of the gradients exchanged during the FL communication process are redundant. Furthermore, transmitting voluminous model parameters strains network resources and elongates the required time for convergence. To combat this, it proves advantageous to diminish the frequency at which clients forward their updates to the aggregator. In this regard, we bring two approaches, as found in the existing literature:periodic aggregationandfixed communication rounds.\n\nPeriodic Aggregation.As you may guess, this enables the client to perform more than one training iteration prior to sending their updates to the aggregator server. Therefore, the need for client-server communication will be lessened. Interestingly, the research in(mohammadi2021differential)concurrently examined three mechanisms to enhance communication efficiency while maintaining privacy in FL. These mechanisms encompass period aggregation, model compression, and client participation scheduling. In a similar vein, the TAMUNA framework(condat2023tamuna)employs infrequent communication on top of transmitting compressed models to alleviate the communication burden.\n\nFixed Communication Round.It refers to a known approach of reducing aggregation frequency, in which the practice of collecting and aggregating model updates from active clients is only performed at regular intervals, generally defined by a fixed number of local iterations. For example, the efforts in(mhaisen2021optimal)and(li2023hfml)have emphasized this concept in the context of hierarchical FL. While the paper in(hu2023scheduling)considered asynchronous FL setup.\n\nSynch: Synchronization mode {Synchronous, Asynchronous}.Users: Maximum active users used in experiments.Archi: Architecture {Centralized, Decentralized(P2P), Hierarchical}.Cm. E.: Communication Efficiency.Cp. E.: Computation Efficiency.Conv: Convergence Analysis.Pers: Personalization.Gen: Generalization.Fair: Fairness.Heter: Heterogeneity.Sec: Security.Priv: Privacy.Scal: Scalability.P.A.: Periodic Aggregation.\n\nThe objective of thoughtful client selection is to effectively make decisions on the aggregation level, enabling meaningful knowledge extraction from the selected clients. The challenges here stem from the significant difference in the data quality and quantity held by each device as well as their calculation powers. Besides, the present problem is aggravated by the size of the current deep neural networks, which can be in the range of millions of parameters, resulting in tremendous bandwidth consumption. This underscores the importance of designing a sophisticated client participation scheme that takes into consideration all of these factors to conduct more efficient and optimized federated aggregation protocols. In this section, we discuss three main state-of-the-art classes: reliability-based client selection, utility-based client selection, and client maximization. We summarize these insights in Table2.\n\nClient Selection\n\nReliability-based Client Selection.Reliability-based client selection focuses on selecting clients based on their reliability or trustworthiness. It considers their past performance, such as their consistency in joining the collaborative training, their ability to complete training tasks, and providing accurate updates. The goal is to prioritize clients that have proven reliable for not stumbling the smoothness of communications (e.g., that do not drop out from the training, surprisingly), ensuring FL system stability.\nTo illustrate, we consider the approach in(rjoub2022trust). This strategy harnesses a trust-based Deep-RL mechanism tailored to select adequate clients in a resource-efficient and time-conscious manner. In a similar wavelength, the scoring-aided FL framework in(zhang2023scoring)chooses FL mobile clients based on their distinctive patterns, focusing on precision and efficiency.\n\nUtility-based Client Selection.In contrast, utility-based client selection emphasizes selecting clients based on their utility or usefulness for the specific learning task. It evaluates factors such as the potential impact of the client’s data and updates on improving the model’s generalization performance(egtgsv24iwcmc). By strategically selecting clients with the most valuable contributions, this approach accelerates long-term convergence, requiring fewer communication rounds to achieve the target performance.\nTo exemplify, the paper in(shi2023efficient)enables the quantification of individual client contributions to the broader global model. The authors explore the Combinatorial Multi-Arm Bandit(MAB) strategies to propose the CU-CS scheme that intelligently allocates resources based on clients’ impact. On a related reference(huang2023active), the ACFL method pinpoints highly informative clients within each cluster through Active Learning (AL) metrics, to enhance cluster-specific models.\n\nClient Number Maximization.\n\nIntuitively, increasing the number of participating clients should decrease the time required to achieve convergence. This ”time-to-converge” is essentially determined by the number of communication rounds needed in order to reach the desired FL performance. Although this might seem promising, it is worth noting that simply maximizing the number of clients will not necessarily achieve excellent FL system efficiency without undesirable costs (e.g., the impact on the overall non-IIDness and the model uploading waiting delays).\nDue to the conflicting-objective nature of this problem, its proper formulation necessitatesmulti-objective optimizationfunctions.\nThe authors in(ji2022client)formulate a mixed-integer optimization for wireless FL, focusing on client selection and bandwidth allocation. The resulting Perround Energy Drift Plus Cost (PEDPC) algorithm translates the original offline problem into an online perspective for minimizing latency and accuracy degradation in the long run. In a related context, a recent study(wu2023fedab)proposes FedAB, an incentive mechanism for FL that promotes user engagement, effectiveness, fairness, and reciprocity. It leverages a combination of multi-attribute reverse auction and combinatorial MAB strategies. Notably, FedAB incorporates Upper Confidence Bound (UCB)-based client selection, balancing the exploitation of past reliable clients with the exploration of promising new clients.\n\nSynch: Synchronization mode {Synchronous, Asynchronous}.Users: Maximum active users used in experiments.Archi: Architecture {Centralized, Decentralized(P2P), Hierarchical}.Cm. E.: Communication Efficiency.Cp. E.: Computation Efficiency.Conv: Convergence Analysis.Pers: Personalization.Gen: Generalization.Fair: Fairness.Heter: Heterogeneity.Sec: Security.Priv: Privacy.Scal: Scalability.\n\nGiven the significant risks associated with FL security and privacy attack surfaces, as discussed in Section3.3, it is crucial to survey the defense mechanisms to attract attention to this line of interest and inspire further research. In this section, we will furnish an exhaustive breakdown of various detection and defense measures, particularly emphasizing those that directly impact FL aggregation. Although attack detection and defense are two different phases, we treat them as the same in this survey since they usually work together to protect FL. Our proposed taxonomy for FL security and privacy mechanisms synthesizes multiple perspectives for a comprehensive view, as illustrated in Fig.19.\n\nA straightforward and intuitive solution to defend against aggregation attacks is to analyze the components involved in FL aggregation, such as the clients’ local updates and training rules. The central idea behind this class of solutions is that, even without direct access to the client’s data or complete control over their behaviors, for privacy reasons, the central aggregator in an FL system can identify abnormalities and mitigate them by implementing appropriate evaluation mechanisms for reliability verification. Table2outlines the proposed taxonomy of security and privacy solutions in FL, highlighting relevant contemporary research.\n\nAnomaly Detection.\n\nAnomaly detection mechanisms play an active role in identifying and mitigating the impact of suspicious behavior from individual users, thereby safeguarding the FL aggregation process. The main perspectives of anomaly detection are twofold. First, it involves detecting outliers that significantly deviate from expected behavior or exhibit patterns indicative of potential attacks or data anomalies. Second, it considers monitoring the communication and network activities of clients. For example, unusual communication patterns, excessive data transfer, or suspicious network behavior can serve as signals for detecting malicious activity or unauthorized access attempts. For a comprehensive overview, we categorize proactive anomaly detectors in to two families:\n\nSupervised Anomaly Detection.Supervised anomaly detection techniques require labeled data during the classifier training. These methods utilize historical data that encompasses both normal and deviant instances, enabling the classifier to learn and differentiate between them.Spectral-based methodsare widely employed in anomaly detection tasks. These techniques embed both benign and malicious data into a lower-dimensional space using spectral analysis. For instance, both studies in(gu2022fedcut)and(zeng2022never)leverage spectral analysis as a means to detect and alleviate Byzantine misbehavior and backdoors.\nLikewise, theentropy-based methodsoffer insights into the unusual patterns within the data. However, it relies on entropy, a measure of uncertainty or randomness in the data. By calculating the entropy of different features or data distributions, these methods can detect instances with abnormally high or low entropy values. The Sageflow(park2021sageflow)and ELITE(wang2021elite)frameworks compare the entropy of clients’ local updates to a threshold value, excluding potential outliers from aggregation. This process prevents harmful updates from impacting the final global model.\n\nUnsupervised Anomaly Detection.In contrast to the previous detectors, unsupervised anomaly detection techniques perform independently of labeled data. They aim to identify anomalies by learning the underlying structure or patterns in the data that deviate significantly from expected behavior. These methods assume that anomalous data are infrequent and distinct from benign ones.\nFor instance, DL-based anomaly detection often operates usingautoencoders, a specialized type of neural network architecture. An autoencoder comprises two main components: an encoder and a decoder. In the encoding phase, the encoder compresses input data into a lower-dimensional representation, aiming to capture essential features of the data. Subsequently, the decoder reconstructs the original input from this compressed format, striving for minimal error in the reconstruction process. This process facilitates anomaly identification by discerning variations between the reconstructed data and the original data. The data instance is then classified as an anomaly if the computed error surpasses a predetermined threshold. Notably, autoencoders have proven their superiority over traditional linear algebra-based methods like Principal Component Analysis (PCA) when handling intricate and nonlinear data problems.\nExtensive research has been conducted in this area(liu2022privacy;vucovich2022anomaly). For instance, the work in(liu2022privacy), introduces an autoencoder to estimate the anomaly score before each aggregation round.\nAnother commonly employed strategy in this class involves the use ofDNN-based detectors(wang2023federated). The binary implementation of this technique operates in two steps. First, the DNN is trained on normal training data to recognize the patterns associated with expected behavior. Then, during the testing phase, each new instance is fed into the trained DNN. If the DNN accepts the input, it is considered non-anomalous, whereas if the DNN network rejects the instance, it is identified as an anomaly. The proposal in(ma2021federated)exemplifies this approach. Similarly, Through DNN utilization in privacy-preserving recommender systems(wang2022fast), the proposed PrivRec and DP-PrivRec models attain intricate user and item representations, facilitating swift adaptation to new users while safeguarding privacy.\n\nVerification.\n\nZero-knowledge Proofs.ZKPs offer a powerful tool for verifiability on private data. In essence, they enable a ”prover” to demonstrate knowledge of specific information without disclosing the underlying details to a ”verifier.” In federated learning, probabilistic ZKP assessments enable participants to prove that their submitted model updates adhere to predefined criteria, such as specified ranges and authentic features. This validation ensures the accuracy and correctness of their computations while yielding their sensitive data preserved(yang2023fedzkp;xing2023zero).\n\nSniper.To address the problem of distributed poisoning attacks, where multiple attackers collude to inject malicious samples into the training data, potentially causing significant harm to FL, the work in(cao2019understanding)presents the Sniper paradigm. The Sniper scheme uses a two-phase verification approach based on a validation dataset to detect and eliminate potentially poisoned models. The authors advocate that their proposal dramatically decreases the success rate of poisoning attacks even when more than one attacker is involved.\n\nEnhanced Model Training.\n\nThe defense paradigms that fall into this class strive to improve the training of FL models using innovative methods that surpass conventional methodologies and surmount unresolved limitations. Researchers have actively sought solutions from diverse disciplines, adapting them to the unique challenges of FL.\n\nPruning.The pruning technique reduces the size of neural networks by eliminating unnecessary connections or parameters without sacrificing performance. Parameters are evaluated based on their impact on the network’s accuracy, and those deemed less crucial or present negligible contributions are pruned. This results in a more lightweight and efficient learned model. Pruning is a suitable technique in FL, where users often have limited resources incapable of training large neural networks. To offer a global overview of this method, the authors in(wei2023securing)describe two simple pruning approaches:Threshold-Based PruningandRandom Pruning. For enhanced model training, the authors in(wei2023securing)describe two simple pruning approaches:Threshold-Based PruningandRandom Pruning. In a similar vein, the Large Gradient Pruning (LGP) method(zhang2023preserving)involves setting a threshold for gradient magnitudes and removing gradients below this\nthreshold. By doing so, the LGP framework retains informative updates while reducing the risk of privacy breaches through gradient inversion attacks. Similar work can be found in(zhao2022cork)(stripelis2022towards)to defend against both security and privacy breaches.\n\nAdversarial Training (AT).Adversarial training incorporates specially manipulated adversarial examples alongside the regular data during the model training process. The goal is to expose the model to various attacks during training, teaching it to be more cautious and resilient when dealing with such attacks in real-world scenarios. For example, in(hallaji2023label), this training policy is applied to strengthen the robustness of neural network models against label poisoning attacks. Similarly,(zhang2023secure)presents a novel vertical federated learning approach explicitly designed to thwart label inference attacks as one of the significant privacy threats in vertical FL systems.\n\nFederated Distillation (FD).As opposed to standard FL exchanges of model parameters, Federated Distillation (FD)(seo202216)only requires the transmission of model outputs, which are significantly smaller in size. The concept of FD draws inspiration from Knowledge Distillation (KD), which focuses on transferring knowledge from a fully trained, large, and complex model (teacher) to a smaller and simpler model (student). In communication resource-constrained settings, federated distillation emerges as a highly appealing solution for sharing knowledge among participants.\nPrevious proposals in this regard are presented in FedMD(li2019fedmd), FedKD(seo202216), and FedGEN(zhu2021data). However, recent investigations have revealed that solely relying on gradient hiding leaves the FL system prone to threats like single-point-of-failure and membership information leakage(yang2023fd). In light of this, researchers have sought to combine knowledge distillation with emerging solutions like blockchain(li2023hbmd)and edge computing(yang2023edge). One notable work(shao2023selective)takes FD to the next level through a selective knowledge-sharing mechanism that is able to handle heterogeneous data. Selective-FD employs client-side and server-side selectors to identify and filter misleading or unreliable contributions during knowledge sharing.\n\nFederated Multi-Task Learning (FMTL).In multi-task learning (MTL), the objective is to train a single model that can effectively handle multiple related tasks simultaneously, rather than building separate models for each task. Federated multi-task learning combines the benefits of MLT with the advantages of FL to address the challenges of learning models for numerous related activities on non-iid data. For instance, the authors in(yi2022hfedmtl)designed HFedMTL, an FMTL system using a primal-dual method for task reduction, enhancing MTL flexibility on massive terminals. Another FMTL scheduling mechanism is developed in(liu2023federated)harnesses a trusted computing sandbox within the blockchain framework.\n\nSynch: Synchronization mode {Synchronous, Asynchronous}.Users: Maximum active users used in experiments.Archi: Architecture {Centralized, Decentralized(P2P), Hierarchical}.Cm. E.: Communication Efficiency.Cp. E.: Computation Efficiency.Conv: Convergence Analysis.Pers: Personalization.Gen: Generalization.Fair: Fairness.Heter: Heterogeneity.Sec: Security.Priv: Privacy.Scal: Scalability.AT: Adversarial Training.FD: Federated Distillation.FMTL: Federated Multi-Task Learning\n\nSecuring the FL aggregation procedure is of utmost importance. The proposals in this category aim for a resilient pipeline against communication issues, client dropouts, and malicious actors. Upon our literature review, we have organized these efforts into three primary categories: robust and secure aggregation, a modified version of the standard aggregation process, and a well-protected execution environment. These categories as well as their sub-categories are summarized in Table2to form a selection of relevant work in the literature.\n\nRobust Aggregation.\n\nRobust aggregation remediates the FL system against security and privacy attacks by detecting and mitigating malicious or inaccurate client models. These practices operate under the assumption that poisoned and benign models exhibit distinguishable features. Their objective is to accomplish this task without jeopardizing performance or introducing communication bottlenecks. The literature explores two main approaches:\n\nMetrics-based Aggregation Methods.The term ”metrics” here refers to specific criteria used to evaluate the quality of local updates, such as trust, reliability, and similarity. The FL server scrutinizes individual models provided by each clientccand compare their performance metrics to a validation dataset using the aggregated model derived from all updates except for that of clientcc. Consequently, the FL server can flag anomalous updates that diminish the model’s utility based on predefined rules or thresholds and potentially discard them. It is worth noting that here, the FL server requires access to a validation dataset, which may not always be feasible in FL. For instance, the FLTrust(cao2020fltrust)exemplifies a trust-based mechanism. It treats client updates as vectors and employs ReLU cosine similarity to assess their alignment with the server model, potentially flagging dissimilar updates. Unlike prior cosine-based methods(ma2022shieldfl), the CosDefense algorithm(yaldiz2023secure)utilizes cosine similarity scores and requires only the updates themselves without requiring additional information. However, the authors in(mao2021romoa)argue that simply calculating distance or similarity is not suﬃcient, proposing hybrid similarity measures with a look-ahead strategy. A similar voting-based strategy is presented in(yue2022federated).\n\nStatistic-based Aggregation Methods.An alternative (or a supplementary) approach to metrics-based verification methods consists of evaluating the statistical properties of update magnitudes such as geometric median(pillutla2022robust), trimmed mean(yin2018byzantine), Krum/multi-Krum(blanchard2017machine), Bulyan(guerraoui2018hidden), and FoolsGold(fung2020limitations). Such indicators filter only valid updates. Nonetheless, it’s important to highlight that these straightforward statistical techniques have demonstrated their vulnerabilities(zizzo2020fat). Consequently, this has led researchers to explore sophisticated methodologies, such as blockchain(liu2022federated), clustering(li2022enhancing), and fair detection(singh2023fair)to boost the FL security.\n\nProcess Modification\n\nMoving Target.Moving Target Defense (MTD) mechanisms orchestrate perturbal adjustments continuously to the system components and parameters, making it more challenging and costly for potential attackers. These proactive measures offer robust protection against intrusions at the server, the network, and the application levels, effectively bolstering the system’s resilience. Inspired by MTD(zhou2021augmented), researchers in(zhou2021augmented)proposed ADS-MTD to achieve CIA security (confidentiality, integrity, and availability) in FL. ADS-MTD uses hierarchical dual shuffling: primary model shuffling and augmented client shuffling. The former anonymizes client contributions, making it difficult for attackers to identify which client contributed to which part of the final global model. While the lateraugmented shufflingdynamically removes malicious clients to ensure model integrity and availability.\n\nPeer-To-Peer Aggregation.Other research has emphasized the advantages of an alternative decentralized solution in federated learning, as it eliminates vulnerabilities to attacks targeting the central hub of the FL system. Therefore, there has been a growing interest in exploring peer-to-peer (or decentralized) aggregation. Nevertheless, it is crucial to consider the implications of such a decentralized aggregation scheme. As such, delegating the monitoring responsibility to individual clients leads to limiting global monitoring capabilities.\nCasting light on traditional FL limitations in mobile robotics, a recent paper(zhou2023decentralized)offers PPAFL, a P2P FL approach in 5G and beyond networks. This secure solution incorporates a Secret Sharing-based communication, a Secure Stochastic Gradient Descent scheme integrated with an Autoencoder, and a Gaussian mechanism to address data leakage. In the same spirit, the study(lu2022privacy)presents a privacy-preserving consensus-based algorithm for decentralized FL, in which learners share their local models exclusively with their one-hub peers. This area of research was extensively explored due to its potential for strengthening FL security and efficiency(wang2023sparsfa;piotrowski2023towards;chen2022cfl).\n\nBlockchain.As defined by(javed2022integration), blockchain technology functions as a distributed and accessible database that acts as a verifiable and tamper-proof ledger. Its application in securing the aggregation process in federated learning yields numerous advantages. Firstly, it cultivates trust among clients and incentivizes the best contributors by rewarding their valuable involvement. Secondly, it reinforces the resilience of the aggregation process, minimizing the risk of vulnerabilities and potential failures, thanks to its remarkable properties of verifiability, traceability, and privacy preservation. Fig.20showcases a seamless integration of blockchain technology within an edge-based FL system(mao2023security). For example, The VFChain proposal(peng2021vfchain)engages blockchain for enhanced security through verifiability and auditability. VFChain replaces central servers with a blockchain-selected verifier committee for aggregation. Also, it introduces an authenticated data structure for efficient verification and secure committee rotation.\nSeveral recent studies have capitalized on this promising approach for various objectives and domains, including healthcare services(samuel2022iomt), Industrial Internet of Things (IIoT) networks(yazdinejad2022block).\n\nTrusted Execution Environment (TEE).\n\nTEEs refer to trusted and secure FL ecosystems that allow only authorized parties to perform attested operations and protect their communications. More specifically, TEE provides a cryptographic and isolated environment where authenticated code can run safely. Additionally, the TEE service is in charge of checking the authenticity and managing the access rights of the participant clients. Thus, the TEE ensures the learning process’s integrity and confidentiality, preventing any tampering or manipulation. For instance, in(mo2021ppfl), the TEEs strategy plays a vital role at both the client and server levels. On the client side, the authors employ a robust greedy layer-wise training approach to keep sensitive information hidden from adversaries. Meanwhile, on the server side, TEEs enable secure aggregation using a cryptographic protocol.\nThe paper presented in(chen2020training)also leverages the isolated enclave of TEEs to ensure the learning process integrity on both the client and server sides. In contrast, the work described in(rieger2022close)focuses, specifically, on the client side and introduces CrowdGuard to combat targeted attacks.\n\nSynch: Synchronization mode {Synchronous, Asynchronous}.Users: Maximum active users used in experiments.Archi: Architecture {Centralized, Decentralized(P2P), Hierarchical}.Cm. E.: Communication Efficiency.Cp. E.: Computation Efficiency.Conv: Convergence Analysis.Pers: Personalization.Gen: Generalization.Fair: Fairness.Heter: Heterogeneity.Sec: Security.Priv: Privacy.Scal: Scalability.\n\nAmidst the conflict between the privacy-by-design aspect of FL and the inherent privacy hurdles associated with its distributed nature, a pressing demand arises: extracting insights while upholding the privacy of data holders. Existing research centers on securing users’ private data, local model updates, and the final deployed model to guarantee that no sensitive information has been revealed. These solutions foster trust among the diverse actors within the federated network, carefully addressing the crucial challenge of harmonizing privacy preservation with knowledge sharing. We summarize in Table2a comprehensive array of strategies and scholarly papers published in this regard.\n\nPerturbations.\n\nThe perturbation mechanisms in FL strategically inject controlled noise to the data or the local model before sharing it with other participants at the expense of a slight degradation in model accuracy. The goal is to protect data privacy and prevent unauthorized access or disclosure of sensitive information.Differential Privacy (DP)stands as one of the most prominent perturbation methods in this domain. Its rigorous mathematical-based proof and flexible privacy-utility trade-offs made it relevant to many privacy-preserving applications in FL. According to(zhang2023systematic), the DP techniques in FL can be divided into three categories: (i) FL with central differential privacy: a trusted central server injects noise into the global parameters. (ii) FL with local differential privacy: each client incorporates noise into their local parameters. (iii) federated learning with distributed differential privacy: address the shortcomings of the two classes above by introducing only a small amount of noise locally and using a secure aggregation technique. From another perspective(zhang2023systematic), the field of DP research can be classified into two distinct categories: DP analysis(zhang2022understanding)and DP proposals(ho2022fedsgdcovid;zhang2023two). Building on DP, the Poisson Binomial Mechanism (BPM) algorithm(chen2022poisson)adds calibrated noise to FL updates, shielding device data from even in the presence of an untrusted aggregator. In particular, the injected noise is meticulously fine-tuned using quantified parameters for privacy (privacy epsilon, privacy budget), resulting in an unbiased yet optimal privacy-accuracy framework. Similarly,(zhang2023two)leverages this strategy within an end-edge-cloud system. Researchers established a flexible two-stage DP policy that can be applied individually or synergistically. Initially, a randomized response algorithm perturbs the feature data. Then, edge servers infuse noise into the model, bolstering security.\n\nHomomorphic Encryption.\n\nHomomorphic Encryption (HE) is an advanced cryptographic technique that facilitates computation on encrypted data without prior decryption. Within the context of FL, HE permits active devices to encrypt their local models, building a formidable barrier against sensitive information breaches. Hence, the aggregator can confidently execute arithmetic operations directly on the encrypted data in a seamlessly emulated fashion as if they were performed on plaintext data, preserving the privacy of individual contributors. Moreover, homomorphic encryption unfolds into three distinctive classes depending on the type and number of ciphertext operations configured: (i)Partially Homomorphic Encryption (PHE)supports one single operation, either addition or multiplication, for infinite times. (ii)Somewhat Homomorphic Encryption (SHE)enables both addition and multiplication, albeit with limitations on the number of computations. (iii)Fully Homomorphic Encryption (FHE)can perform any number of operations in the ciphertext space but requires advanced techniques and it is known to be computationally intensive. Numerous studies in the existing literature have utilized this intricate encryption method to establish robust federated learning frameworks, as shown in(zhang2022homomorphic), ShieldFL(ma2022shieldfl), and FedML-HE(jin2023fedml).\n\nSecure Aggregation.\n\nSecure aggregation plays a pivotal role in upholding the privacy of FL users, guaranteeing that no party discloses its model update in the clear, even to the aggregator. The concern of secure aggregation has been extensively researched, with scholars employing diverse strategies to protect the aggregation process through the lens of privacy, including data perturbations, encryption, secure multi-party aggregation, and blockchain solutions.\n\nSecure Multi-Party Computation (SMPC).SMPC is a sub-field of cryptography wherein a consortium of data owners who do not mutually trust each other jointly perform computations for a specific task. This collaborative effort is underpinned by the strict condition that the confidentiality of the entities’ data remains unbreached throughout the process. The main relevant techniques for implementing the SMPC include Secret Sharing (SS), Garbled Circuit (CC), and Oblivious Transfer (OT). To showcase this potent tool, we reference(tian2022flvoogd), which introduced FLVoogd to enhance efficiency and reduce resource-intensive operations. FLVoogd effectively rejects malicious uploads while protecting sensitive data, utilizing SMPC coupled with DP and Density-based Spatial Clustering of Applications with Noise (DBSCAN). Refer also to(piotrowski2023towards)for a similar study.\n\nSynch: Synchronization mode {Synchronous, Asynchronous}.Users: Maximum active users used in experiments.Archi: Architecture {Centralized, Decentralized(P2P), Hierarchical}.Cm. E.: Communication Efficiency.Cp. E.: Computation Efficiency.Conv: Convergence Analysis.Pers: Personalization.Gen: Generalization.Fair: Fairness.Heter: Heterogeneity.Sec: Security.Priv: Privacy.Scal: Scalability.\n\nTo summarize, we provide in Table2, a summary of the common FL attacks along with their corresponding defense mechanisms, emphasizing the key findings of this section.\n\nAD: Anomaly Detection.ZKPs: Zero Knowledge Proofs.AT: Adversarial Training.FD: Federated Distillation.FMTL: Federated Multi-Task Learning.RA: Robust Aggregation.MT: Moving Target.P2PPeer-to-Peer Aggregation.BC: Blockchain.TEE: Trusted Execution Environment.DP: Differential Privacy.HE: Homomorphic Encryption.SMPC: Secure Multi-Party Computation.\n\n\n================================================================================\n4.1.Strategies for Heterogeneity and Personalization Concerns\n================================================================================\nAs broadly discussed earlier, the issue of heterogeneity is often a stumbling block when attempting to apply successful federated learning in real-world scenarios. This section explores the crucial role of implementing an aggregation method that addresses different types of heterogeneity while ensuring the FL model learns informative patterns from all available resources.\nWe classified the recent strategies in the literature into three distinct classes, as depicted in Fig.16.\n\nModel-oriented strategies focus on improving personalization through the manipulation of the global and local model architecture. An important decision in this regard is whether to limit the collaborative training to only the upper/lower layers of the model, enable users to modify a shared global model, personalize the entire model locally, or train different parts of the final model separately on each device. Please refer to Table2for a thoughtfully curated collection of scholarly publications that have made significant contributions to this area of research.\n\nParameter Decoupling\n\nThis paradigm aims to achieve personalized models and assuage the heterogeneity impact. It involves dividing the model parameters into two or more sets and optimizing each set separately.\nOne configuration of parameter decoupling entails alayer-based splitof the neural network model(arivazhagan2019federated), wherein the layers are segmented into two sets: base layers and personalized layers. This structure helps ensure the privacy of the personalized layers and results in a high degree of personalization.\n\nFor example, EPSL(lin2023efficient)and ModFL(liang2022modular)target personalization in resource-constrained environments. Alternatively, propose an optimal layer selection strategy for energy, time, and privacy trade-offs. Leveraging pre-trained BERT encoders for NLP, FedSplitBERT(lit2022federated)tackles both heterogeneity and communication challenges.Feature representationis another decoupling approach. For instance, the authors in(bui2019federated)have proposed the FURL method, which enables existing personalization techniques within FL by splitting model parameters. User-specific features remain private, while shared features are learned collaboratively. Another study in(rakotomamonjy2023personalisedx)has addressed the issue of heterogeneous raw data representation among FL clients. Their framework called FLIC employs local embedding functions to map the data into a common space. Similar approaches utilize feature anchor vectors(zhou2022fedfa), low-dimensional classifier(collins2021exploiting), and more(sun2021partialfed).\nIn essence, according to(li2021aggregate), parameter decoupling for privacy and personalization can be categorized into single-branch and multi-branch approaches. The former directly privatizes specific layers while aggregating the remaining ones via the server. The latter keeps the entire model shared but privatizes certain components.\n\nGlobal-Local Models Combination\n\nA slightly different approach involvescombining global and local models(criado2022non;hanzely2020federated). This technique is used to personalize the final model employed by each client instead of adopting one globally deployed model for all clients. Unlike standard FL, each client has two models: a global model trained collaboratively and a private local model for fine-tuning the FL outcome. This benefits scenarios with low correlation between local and global data distribution. The authors in(deng2020adaptive)advocate an APFL method that combines global and local models using an adaptively learned weight for improved personalization and generalization. Similarly, the framework in(zec2020specialized)leverages federated averaging and mixtures of experts to achieve personalized models viamodel interpolation.\n\nModel Split\n\nTo improve communication efficiency and tackle device heterogeneity, model split is a promising technique. This approach divides the model, often a neural network, into sub-models or branches. Each device then trains a specific portion, reducing the communication burden and computational cost per device.\nWithin this particular branch, the researchers in(dun2023efficient)offered AsyncDrop, as a new asynchronous solution to handle device heterogeneity in large-scale FL. This approach leverages dropout regularization, randomly masking a subset of neurons in each layer during training. This effectively creates sub-models where all layers are present but only a portion of neurons are active. Devices are then assigned sub-models for training based on their computational capabilities. In(cui2022fedbranch), the suggested FedBranch framwork adopts the strategy of model-splitting into a multi-branch neural network. Moreover, FedBranch employs a layer-wise aggregation to combine branch outputs and integrates a task offloading algorithm for efficient distribution of training tasks across branches. Building on the same foundation laid by(dun2023efficient), FedBranch approach assigns a suitable branch model to each participating client based on their computational resources. Finally, In(mori2022personalized), the authors have investigated another personalized approach using multi-branch architecture to establish pFedMB, enabling similar clients to automatically share knowledge without directly calculating the similarities, as with FedAMP(huang2021personalized)and FedFomo(zhang2020personalized).\n\nSynch: Synchronization mode {Synchronous, Asynchronous}.Users: Maximum active users used in experiments.Archi: Architecture {Centralized, Decentralized(P2P), Hierarchical}.Cm. E.: Communication Efficiency.Cp. E.: Computation Efficiency.Conv: Convergence Analysis.Pers: Personalization.Gen: Generalization.Fair: Fairness.Heter: Heterogeneity.Sec: Security.Priv: Privacy.Scal: Scalability.\n\nAggregation-oriented strategies involve optimizing various aspects of the aggregation process, including training hyperparameters, loss functions, gradient variances, convergence rates, and learning direction. The primary objective is to identify and implement the optimal aggregation environment that accelerates FL convergence while accommodating the unique characteristics of individual users. Table2delineates the sub-categories and furnishes instances of literature papers that pertain to this particular research area.\n\nServer Optimization\n\nApart from the architectural decision choice, another solution is to modify the server-side optimizers.Adaptive gradientmethods are extensively employed in traditional ML. Unlike fixed learning rates in vanilla gradient descent, which rely on either a constant rate or a preset schedule, adaptive methods adjust the rate on the fly based on the gradient magnitude. This flexibility has shown theoretical and practical advantages in FL(reddi2020adaptive), unlocking superior generalization performance ober non-adaptive methods including Adagrad(duchi2011adaptive), Adam(kingma2014adam), and Yogi(zaheer2018adaptive).\nMeanwhile, the authors in(li2023fedda)argue that server-side adaptive gradients alone do not fully leverage adaptive information. To address this, they propose FedDA a framework enabling each client to adjust its learning rate based on local gradients and past updates.\nAnother server-side optimization technique ismomentum. In federated learning, SGD with momentum averages gradients from clients while considering past updates, guiding the global model toward the right learning direction. In other words, it bolsters faster convergence and escapes from poor local minima.\nFor instance, the STEM algorithm(khanduri2021stem)utilizes momentum for both client and server updates, achieving an optimal balance between updates’ frequency and minibatch sizes. Similarly, FedGLOMO(das2022faster)leverages global and local momentum terms to reduce variance and accelerate convergence. These approaches, along with FedMom and FedNAG(huo2020faster;yang2022federated)(variants integrating Nesterov’s Accelerated Gradient), showcase the effectiveness of momentum in heterogeneous FL scenarios.\n\nRegularization\n\nRegularization, a technique to prevent overfitting in ML, can also combat client drift in FL settings. Client drift occurs when local models diverge from the global optimum due to heterogeneous data (Figure17). Regularization adds a penalty term to the loss function to penalize models that deviate too far, encouraging them to stay closer to the global model.\nRecent work incorporates dynamic regularization(acar2021federated), triplet term regularization(li2023fedtrip), but also integrates it with other techniques, such as knowledge distillation(luo2023improving)and stratified sampling(lu2023federated).\n\nHyper-Parameters Optimization (HPO)\n\nFLhyperparameter tuningprioritizes communication and computation efficiency over accuracy, in construct ML HPO focused on accuracy. This optimization accelerates convergence by adjusting factors like client selection, local training steps, and aggregation frequency – all crucial for balancing performance and efficiency(hefel24iwcmc).\n\nIn fact, FL grapples with a distinct challenge: optimizing hyperparameters for a distributed system. Here, two main approaches emerge:theoretic-based(luo2021cost;wu2021fast;shi2020device)andReinforcement Learning (RL)-basedmethods(guo2022auto;zhang2021deep;lu2020blockchain). Theoretical methods offer efficient solutions by simplifying the problem with environmental assumptions, which may not hold true in the face of data’s dynamism and lack of clear patterns. This is where RL-based methods shine. They treat the tuning task as a dynamic decision-making process, offering greater adaptability. A prime example is Dap-FL(chen2023dap). It implements a Deep Deterministic Policy Gradient (DDPG) algorithm to adjust clients’ learning rates and training epochs based on their progress and the global model. Auto-FedRL(guo2022auto)pushes the HPO boundaries even further. It doesn’t stop at a limited set of hyperparameters. Instead, it employs an online RL agent to dynamically adjust a larger spectrum of hyperparameters for both clients and the server.\n\nSynch: Synchronization mode {Synchronous, Asynchronous}.Users: Maximum active users used in experiments.Archi: Architecture {Centralized, Decentralized(P2P), Hierarchical}.Cm. E.: Communication Efficiency.Cp. E.: Computation Efficiency.Conv: Convergence Analysis.Pers: Personalization.Gen: Generalization.Fair: Fairness.Heter: Heterogeneity.Sec: Security.Priv: Privacy.Scal: Scalability.\n\nClient-oriented strategies aim to increase the involvement of the most reliable nodes with high-quality data and favorable learning capabilities. The main idea is to mitigate the negative impact of struggling nodes on the overall aggregation performance by carefully choosing the participating clients, evaluating the quality of their updates, or organizing them hierarchically to improve the averaging process. see Table2for a summary.\n\nWeighted Aggregation\n\nThe classical aggregation methods (e.g., FedAvg), struggle with real-world non-IID data, leading to suboptimal convergence and utility(khaled2020tighter;hsu2019measuring). To navigate this drawback,weighted aggregationinvolves assigning weights to local models to discriminate the importance of contributing users. This strategy acknowledges that updates from users with high-quality, relevant data are more valuable for the global model. To tackle this, the FAIR framework rests on three-component solution: 1) estimate each device’s contribution quality using historical records, 2) reward high-quality participation through a quality-aware incentive mechanism, and 3) automatically weight local models, ensuring best contributors have a stronger impact on the final model. Other weighting techniques include measuring loss variation(talukder2022computationally)and adopting a hierarchical multi-parameter weighting scheme(herabad2023communication).\n\nClient Selection\n\nThe objective of carefully choosing a subset of active clients to participate in a communication round is to optimize the performance of federated learning while considering the diverse nature of nodes. Theclient selectionmethods aim to make the most optimal use of the limited and heterogeneous clients’ resources, including data and computing capabilities. Various techniques beyond random selection have been proposed to accelerate the global convergence(fu2022client). These strategies involve sophisticated perspectives such as employing a scoring system based on past performance(cho2022flame)and prioritizing nodes with superior computing power and accuracy(lu2023towards).\n\nClient Clusturing.\n\nClient clustering avenue is inspired by the unsupervised clustering ML paradigm. Indeed, it groups clients with similar data distributions, addressing the challenge of data non-IIDness. As an alternative perspective deviating from adopting a single global model in traditional FL, client clustering allows for hierarchical knowledge transfer. Specifically, this involves training task-specific models for each cluster. Subsequently, the server aggregates the models from various clusters to enable high-level knowledge sharing.\nIn edge computing environments, both studies(wolfrath2022haccs)and(lu2023auction)leverage clustering to group edge devices based on their similar data distributions. The former work relies on update metadata (e.g., mean, variance), while the later directly analyzes local gradients for more accurate information. In recommendation systems,(imran2023refrs)leverages neural-based clustering to capture user preferences and group semantically similar user models. Another secure solution can be found in in(firdaus2023personalized).\n\nSynch: Synchronization mode {Synchronous, Asynchronous}.Users: Maximum active users used in experiments.Archi: Architecture {Centralized, Decentralized(P2P), Hierarchical}.Cm. E.: Communication Efficiency.Cp. E.: Computation Efficiency.Conv: Convergence Analysis.Pers: Personalization.Gen: Generalization.Fair: Fairness.Heter: Heterogeneity.Sec: Security.Priv: Privacy.Scal: Scalability.\n\n\n================================================================================\n4.2.Strategies for Communication Efficiency and Optimization\n================================================================================\nCommunication efficiency is one essential aspect of FL, yet it often poses a critical bottleneck. As outlined in Section3.2, factors like limited bandwidth, latency, and large models hinder efficient communication. Various optimization strategies have emerged in the literature, aiming to surmount these hurdles and expedite convergence. Fig.18provides a visual taxonomy of these practices, which we will delve into in this section.\n\nTypically, communication overhead arises when multiple transmitters attempt to send a significant amount of data to a central hub, as is the case with the client-server model exchange in federated training. This overhead is further exacerbated due to the limited resources and network bandwidth. To position the available solutions, we categorize them into two main approaches:reducing training latencyandadapting the network topology.\nTable2enumerates a selection of recent endeavors falling within the purview of these two methodologies.\n\nTraining Latency Reduction.\n\nOn the client side, the training latency is controlled by the local capabilities and workload. Despite the immutability of the former, the latter leaves room for incorporating inventive adjustments. We introduce in this category the subsequent solutions, including load balancing, Over-The-Air (OTA)-FL, and asynchronous aggregation.\n\nLoad Balancing.In order to mitigate the severe effect of FL clients’ disparities, many researchers suggest balancing the amount of data retained by each client. One such approach consists of turning RL techniques to determine the optimal amount of data that must be used in a training round for each client(shin2023federated). For instance, in(tu2020network), researchers have derived a convex optimization accounting for local resources and model accuracy to determine the most suitable clients for processing specific data points. In another investigation, the CATA-Fed system(jeong2022cluster)considers data diversity and data load when selecting clients. The goal of this scheduling algorithm is twofold: global bias alleviation with fair workload distribution. More strategies can be found in(trindade2022resource;morell2022optimising).\n\nOver-The-Air Computation.Over-the-air computation is a powerful strategy that strikes a balance between data privacy and effective knowledge sharing. Technically speaking, over-the-air computation stands for computing a nomographic function (e.g., mean) of distributed data from multiple transmitters. In contrast to the traditional computation-communication separation methods in FL, this design carries out parts of the aggregation processover-the-airby local devices to reduce the required bandwidth, thereby, speeding up the federated training process. In other words, the summation of the models’ gradient is carried out over the air in a distributed manner, and only the sums (not all the gradients) are transmitted to the aggregator to finally compute the sums’ average.\nAmidst numerous research endeavors(guo2021over;sifaou2022over), the researchers in(yang2022over)have explored the impact of noisy communication channels on OTA-FL. The developed ACPC-OTA-FL algorithm allows each client to flexibly ascertain its transmission power level and the number of local update steps, maximizing the utilization of available resources. In contrast, the CHARLES framework(mao2022charles)leverages the estimation of Channel State Information (CSI) to assess the effects of fading wireless channels within heterogeneous OTA-FL scenarios.\n\nAsynchronous aggregation.Observing the numerous limitations caused by the synchronicity assumption of the standard FL ecosystem, the research intention has been directed to release the federated learning environments from this strict requirement by leveraging the asynchronous aggregation scheme(yang2022efficient;taha2022unbounded).\n\nNetwork Topology Adjustment.\n\nNetwork topology refers to an architectural design that dedicates the connection and devices within a network. However, the conventional star topology commonly used in FL may not always be an efficient choice. Therefore, some researchers advise modifying the network design to enhance system efficiency. Intuitively, different topologies inherently incur varying communication costs, and then hopefully, selecting an optimized network topology will help achieve the desired efficiency level. To present the existing solutions in this regard, we bring two extensively adopted FL structures:hierarchical aggregationandadaptive network topology.\n\nHierarchical Aggregation.The hierarchical FL embraces a tree-like structure, allowing for partial aggregation(su2021secure). Proximate devices upload their updates to a small base station (SBS) for initial aggregation. Subsequently, a macro base station (MBS) conducts the final aggregation(10062841). In this setup, leveraging edge devices as SBSs within the modern FL systems has shown great potential in reducing communication bottlenecks(yi2022hfedmtl;singh2022dew).\n\nAdaptive Network Topology.The interplay of communication topology and training duration dilemma has attracted significant focus. From one side, a highly connected topology expedites the FL convergence. On the flip side, a more connected topology can also prolong the duration of a communication round. One contribution in this domain(marfoq2020throughput)relies on the max-plus algebra and leverages quantifiable network characteristics, including computation times, link latency, and transmission times to optimize system throughput, measured by the number of completed rounds per time unit. A different study(zhou2022communication)proposed a novel client-server interaction design. This approach empowers each client to decide whether or not to share its model updates based on two thresholds: a probability threshold that limits update frequency to prevent server overload and an informative model determination threshold that ensures only informative updates are transmitted.\n\nSynch: Synchronization mode {Synchronous, Asynchronous}.Users: Maximum active users used in experiments.Archi: Architecture {Centralized, Decentralized(P2P), Hierarchical}.Cm. E.: Communication Efficiency.Cp. E.: Computation Efficiency.Conv: Convergence Analysis.Pers: Personalization.Gen: Generalization.Fair: Fairness.Heter: Heterogeneity.Sec: Security.Priv: Privacy.Scal: Scalability.ANT: Adaptive Network Topology.\n\nAn additional avenue of focus in the efficiency field pertains to reducing data transmission costs. Several factors amplify the increased expenses associated with FL communication. Although many environmental factors remain beyond one’s control, other flexible elements related to the aggregation process offer opportunities for valuable contributions. For instance, the model size and the aggregation frequency present compelling areas for investigation. In Table2, we offer a compilation of the surveyed papers that converge with this specific domain.\n\nModel Size Reduction\n\nAnother captivating strategy to reduce communication overhead, deeply explored in Section4.3, is reducing the number of model parameters transmitted. Researchers argue that it is neither necessary nor efficient that each client must download and upload the complete in the federation process. Instead, they propose alternatives where only a relevant fraction of the global model is assigned to each client to be updated locally. One such configuration relies onmodel division, whether it is layer-based or parameter-representation-based. The second configuration ofupdate droppingtrims less significant neurons from the global model. Beyond model architecture changes, thecompressionstrategy has gained significant interest from the academic communities aiming to reduce energy consumption. Generally described, compression is the process by which the information is encoded using a smaller number of bits than that of the original representation, making it suitable for bandwidth-limited channels and lower energy requirements. Prior arts in this specific field fall into three lines as follows:\n\nQuantization.Quantization involves representing the neural network’s weights and activations with lower precision (i.e., fewer bits). For instance, by reducing the number of colors in a digital image, the file becomes smaller and takes less space. Similarly, quantization maps the full-precision floating point to a smaller set, making the model lighter for transmission.\nIn the pursuit of communication efficiency, QD-Compressor(jin2023design)is a dedicated proposal to large-scale DNN snapshots, precisely for failure-prone clusters in FL. Due to variations in parameter value ranges across layers, the Local-Sensitive Quantization module employs a layer-specific quantization strategy to dynamically adjust quantizers and the number of quantization bits among layers. Moreover, the Error Feedback Mechanism helps maintain high-quality restored models by averting quantization errors. In the same trajectory, the JoPEQ framework introduced in(lang2023joint)jointly integrates lossy compression and privacy augmentation strategies. The core idea lies in employing vector quantization to exploit the incurred distortion in injecting noises into model updates, fortifying the FL system against privacy breaches.\n\nSketching.The previous quantization mechanisms support only uniformly distributed data, which is not always the case for FL updates. The sketch algorithm is a probabilistic alternative that can retain key statistical properties and enable meaningful analysis. The sketching is a memory-saving solution that is used to estimate the model updates distribution in a single processing pass over the updates values. For instance, FetchSGD(rothchild2020fetchsgd)incorporates Count Sketch with momentum and error accumulation, enabling efficient communication with good recovery guarantees.\nWhile the proposal in(kollias2023sketch)leverages Locality Sensitive Hashing (LSH) sketching. This technique relies on the predicate that if two distant models are approximately “close,” there is no need to share them.\n\nSparsification.Intuitively, sparsification is the process by which a matrix becomes more sparse. A sparse matrix is a matrix whose zero elements are higher than those non-zero elements. The main advantage of having a sparse matrix is to save space by storing only the non-zero elements. Sparsification techniques are employed in federated learning to filter out and preserve only the most important parts of the locally trained models.\nStandard sparsification in FL can enhance communication efficiency but it may expose sensitive model parameters during aggregation. The work in(ergun2021sparsified)tackles this concern with SparseSecAggn, an approach for secure sparsification in FL using pairwise sparsification. Shared random masks between devices ensure their aggregated masked models nullify each other. For model compression in analog FL, the authors in(ahn2022model)suggested a novel lossless compression technique called Pattern-Shared Sparsification (PSS). Unlike prior methods where devices sparsify gradients independently (i.e., local top-k sparsification), PSS utilizes a collective sparsification pattern across all devices.\nOther scholars have demonstrated that the hybridization of the aforementioned compression mechanisms offers a potent resolution, as exemplified in(malekijoo2021fedzip).\n\nTo summarize, a perfect compression method does not exist. It either compromises information loss or costs higher computation. From this computation-information trade-off lens, two primary approaches exist lossy and lossless compression.Lossy compressionmethods prioritize efficiency by sacrificing some information fidelity(liu2021hierarchical). Conversely,lossless compressionassures no information loss but comes at the cost of higher computational requirements(zhao2022cork).\n\nAggregation Frequency Reduction.\n\nIn a notable finding from the work in(lin2017deep), it was demonstrated that a remarkable 99% of the gradients exchanged during the FL communication process are redundant. Furthermore, transmitting voluminous model parameters strains network resources and elongates the required time for convergence. To combat this, it proves advantageous to diminish the frequency at which clients forward their updates to the aggregator. In this regard, we bring two approaches, as found in the existing literature:periodic aggregationandfixed communication rounds.\n\nPeriodic Aggregation.As you may guess, this enables the client to perform more than one training iteration prior to sending their updates to the aggregator server. Therefore, the need for client-server communication will be lessened. Interestingly, the research in(mohammadi2021differential)concurrently examined three mechanisms to enhance communication efficiency while maintaining privacy in FL. These mechanisms encompass period aggregation, model compression, and client participation scheduling. In a similar vein, the TAMUNA framework(condat2023tamuna)employs infrequent communication on top of transmitting compressed models to alleviate the communication burden.\n\nFixed Communication Round.It refers to a known approach of reducing aggregation frequency, in which the practice of collecting and aggregating model updates from active clients is only performed at regular intervals, generally defined by a fixed number of local iterations. For example, the efforts in(mhaisen2021optimal)and(li2023hfml)have emphasized this concept in the context of hierarchical FL. While the paper in(hu2023scheduling)considered asynchronous FL setup.\n\nSynch: Synchronization mode {Synchronous, Asynchronous}.Users: Maximum active users used in experiments.Archi: Architecture {Centralized, Decentralized(P2P), Hierarchical}.Cm. E.: Communication Efficiency.Cp. E.: Computation Efficiency.Conv: Convergence Analysis.Pers: Personalization.Gen: Generalization.Fair: Fairness.Heter: Heterogeneity.Sec: Security.Priv: Privacy.Scal: Scalability.P.A.: Periodic Aggregation.\n\nThe objective of thoughtful client selection is to effectively make decisions on the aggregation level, enabling meaningful knowledge extraction from the selected clients. The challenges here stem from the significant difference in the data quality and quantity held by each device as well as their calculation powers. Besides, the present problem is aggravated by the size of the current deep neural networks, which can be in the range of millions of parameters, resulting in tremendous bandwidth consumption. This underscores the importance of designing a sophisticated client participation scheme that takes into consideration all of these factors to conduct more efficient and optimized federated aggregation protocols. In this section, we discuss three main state-of-the-art classes: reliability-based client selection, utility-based client selection, and client maximization. We summarize these insights in Table2.\n\nClient Selection\n\nReliability-based Client Selection.Reliability-based client selection focuses on selecting clients based on their reliability or trustworthiness. It considers their past performance, such as their consistency in joining the collaborative training, their ability to complete training tasks, and providing accurate updates. The goal is to prioritize clients that have proven reliable for not stumbling the smoothness of communications (e.g., that do not drop out from the training, surprisingly), ensuring FL system stability.\nTo illustrate, we consider the approach in(rjoub2022trust). This strategy harnesses a trust-based Deep-RL mechanism tailored to select adequate clients in a resource-efficient and time-conscious manner. In a similar wavelength, the scoring-aided FL framework in(zhang2023scoring)chooses FL mobile clients based on their distinctive patterns, focusing on precision and efficiency.\n\nUtility-based Client Selection.In contrast, utility-based client selection emphasizes selecting clients based on their utility or usefulness for the specific learning task. It evaluates factors such as the potential impact of the client’s data and updates on improving the model’s generalization performance(egtgsv24iwcmc). By strategically selecting clients with the most valuable contributions, this approach accelerates long-term convergence, requiring fewer communication rounds to achieve the target performance.\nTo exemplify, the paper in(shi2023efficient)enables the quantification of individual client contributions to the broader global model. The authors explore the Combinatorial Multi-Arm Bandit(MAB) strategies to propose the CU-CS scheme that intelligently allocates resources based on clients’ impact. On a related reference(huang2023active), the ACFL method pinpoints highly informative clients within each cluster through Active Learning (AL) metrics, to enhance cluster-specific models.\n\nClient Number Maximization.\n\nIntuitively, increasing the number of participating clients should decrease the time required to achieve convergence. This ”time-to-converge” is essentially determined by the number of communication rounds needed in order to reach the desired FL performance. Although this might seem promising, it is worth noting that simply maximizing the number of clients will not necessarily achieve excellent FL system efficiency without undesirable costs (e.g., the impact on the overall non-IIDness and the model uploading waiting delays).\nDue to the conflicting-objective nature of this problem, its proper formulation necessitatesmulti-objective optimizationfunctions.\nThe authors in(ji2022client)formulate a mixed-integer optimization for wireless FL, focusing on client selection and bandwidth allocation. The resulting Perround Energy Drift Plus Cost (PEDPC) algorithm translates the original offline problem into an online perspective for minimizing latency and accuracy degradation in the long run. In a related context, a recent study(wu2023fedab)proposes FedAB, an incentive mechanism for FL that promotes user engagement, effectiveness, fairness, and reciprocity. It leverages a combination of multi-attribute reverse auction and combinatorial MAB strategies. Notably, FedAB incorporates Upper Confidence Bound (UCB)-based client selection, balancing the exploitation of past reliable clients with the exploration of promising new clients.\n\nSynch: Synchronization mode {Synchronous, Asynchronous}.Users: Maximum active users used in experiments.Archi: Architecture {Centralized, Decentralized(P2P), Hierarchical}.Cm. E.: Communication Efficiency.Cp. E.: Computation Efficiency.Conv: Convergence Analysis.Pers: Personalization.Gen: Generalization.Fair: Fairness.Heter: Heterogeneity.Sec: Security.Priv: Privacy.Scal: Scalability.\n\n\n================================================================================\n4.3.Strategies for Security and Privacy Concerns\n================================================================================\nGiven the significant risks associated with FL security and privacy attack surfaces, as discussed in Section3.3, it is crucial to survey the defense mechanisms to attract attention to this line of interest and inspire further research. In this section, we will furnish an exhaustive breakdown of various detection and defense measures, particularly emphasizing those that directly impact FL aggregation. Although attack detection and defense are two different phases, we treat them as the same in this survey since they usually work together to protect FL. Our proposed taxonomy for FL security and privacy mechanisms synthesizes multiple perspectives for a comprehensive view, as illustrated in Fig.19.\n\nA straightforward and intuitive solution to defend against aggregation attacks is to analyze the components involved in FL aggregation, such as the clients’ local updates and training rules. The central idea behind this class of solutions is that, even without direct access to the client’s data or complete control over their behaviors, for privacy reasons, the central aggregator in an FL system can identify abnormalities and mitigate them by implementing appropriate evaluation mechanisms for reliability verification. Table2outlines the proposed taxonomy of security and privacy solutions in FL, highlighting relevant contemporary research.\n\nAnomaly Detection.\n\nAnomaly detection mechanisms play an active role in identifying and mitigating the impact of suspicious behavior from individual users, thereby safeguarding the FL aggregation process. The main perspectives of anomaly detection are twofold. First, it involves detecting outliers that significantly deviate from expected behavior or exhibit patterns indicative of potential attacks or data anomalies. Second, it considers monitoring the communication and network activities of clients. For example, unusual communication patterns, excessive data transfer, or suspicious network behavior can serve as signals for detecting malicious activity or unauthorized access attempts. For a comprehensive overview, we categorize proactive anomaly detectors in to two families:\n\nSupervised Anomaly Detection.Supervised anomaly detection techniques require labeled data during the classifier training. These methods utilize historical data that encompasses both normal and deviant instances, enabling the classifier to learn and differentiate between them.Spectral-based methodsare widely employed in anomaly detection tasks. These techniques embed both benign and malicious data into a lower-dimensional space using spectral analysis. For instance, both studies in(gu2022fedcut)and(zeng2022never)leverage spectral analysis as a means to detect and alleviate Byzantine misbehavior and backdoors.\nLikewise, theentropy-based methodsoffer insights into the unusual patterns within the data. However, it relies on entropy, a measure of uncertainty or randomness in the data. By calculating the entropy of different features or data distributions, these methods can detect instances with abnormally high or low entropy values. The Sageflow(park2021sageflow)and ELITE(wang2021elite)frameworks compare the entropy of clients’ local updates to a threshold value, excluding potential outliers from aggregation. This process prevents harmful updates from impacting the final global model.\n\nUnsupervised Anomaly Detection.In contrast to the previous detectors, unsupervised anomaly detection techniques perform independently of labeled data. They aim to identify anomalies by learning the underlying structure or patterns in the data that deviate significantly from expected behavior. These methods assume that anomalous data are infrequent and distinct from benign ones.\nFor instance, DL-based anomaly detection often operates usingautoencoders, a specialized type of neural network architecture. An autoencoder comprises two main components: an encoder and a decoder. In the encoding phase, the encoder compresses input data into a lower-dimensional representation, aiming to capture essential features of the data. Subsequently, the decoder reconstructs the original input from this compressed format, striving for minimal error in the reconstruction process. This process facilitates anomaly identification by discerning variations between the reconstructed data and the original data. The data instance is then classified as an anomaly if the computed error surpasses a predetermined threshold. Notably, autoencoders have proven their superiority over traditional linear algebra-based methods like Principal Component Analysis (PCA) when handling intricate and nonlinear data problems.\nExtensive research has been conducted in this area(liu2022privacy;vucovich2022anomaly). For instance, the work in(liu2022privacy), introduces an autoencoder to estimate the anomaly score before each aggregation round.\nAnother commonly employed strategy in this class involves the use ofDNN-based detectors(wang2023federated). The binary implementation of this technique operates in two steps. First, the DNN is trained on normal training data to recognize the patterns associated with expected behavior. Then, during the testing phase, each new instance is fed into the trained DNN. If the DNN accepts the input, it is considered non-anomalous, whereas if the DNN network rejects the instance, it is identified as an anomaly. The proposal in(ma2021federated)exemplifies this approach. Similarly, Through DNN utilization in privacy-preserving recommender systems(wang2022fast), the proposed PrivRec and DP-PrivRec models attain intricate user and item representations, facilitating swift adaptation to new users while safeguarding privacy.\n\nVerification.\n\nZero-knowledge Proofs.ZKPs offer a powerful tool for verifiability on private data. In essence, they enable a ”prover” to demonstrate knowledge of specific information without disclosing the underlying details to a ”verifier.” In federated learning, probabilistic ZKP assessments enable participants to prove that their submitted model updates adhere to predefined criteria, such as specified ranges and authentic features. This validation ensures the accuracy and correctness of their computations while yielding their sensitive data preserved(yang2023fedzkp;xing2023zero).\n\nSniper.To address the problem of distributed poisoning attacks, where multiple attackers collude to inject malicious samples into the training data, potentially causing significant harm to FL, the work in(cao2019understanding)presents the Sniper paradigm. The Sniper scheme uses a two-phase verification approach based on a validation dataset to detect and eliminate potentially poisoned models. The authors advocate that their proposal dramatically decreases the success rate of poisoning attacks even when more than one attacker is involved.\n\nEnhanced Model Training.\n\nThe defense paradigms that fall into this class strive to improve the training of FL models using innovative methods that surpass conventional methodologies and surmount unresolved limitations. Researchers have actively sought solutions from diverse disciplines, adapting them to the unique challenges of FL.\n\nPruning.The pruning technique reduces the size of neural networks by eliminating unnecessary connections or parameters without sacrificing performance. Parameters are evaluated based on their impact on the network’s accuracy, and those deemed less crucial or present negligible contributions are pruned. This results in a more lightweight and efficient learned model. Pruning is a suitable technique in FL, where users often have limited resources incapable of training large neural networks. To offer a global overview of this method, the authors in(wei2023securing)describe two simple pruning approaches:Threshold-Based PruningandRandom Pruning. For enhanced model training, the authors in(wei2023securing)describe two simple pruning approaches:Threshold-Based PruningandRandom Pruning. In a similar vein, the Large Gradient Pruning (LGP) method(zhang2023preserving)involves setting a threshold for gradient magnitudes and removing gradients below this\nthreshold. By doing so, the LGP framework retains informative updates while reducing the risk of privacy breaches through gradient inversion attacks. Similar work can be found in(zhao2022cork)(stripelis2022towards)to defend against both security and privacy breaches.\n\nAdversarial Training (AT).Adversarial training incorporates specially manipulated adversarial examples alongside the regular data during the model training process. The goal is to expose the model to various attacks during training, teaching it to be more cautious and resilient when dealing with such attacks in real-world scenarios. For example, in(hallaji2023label), this training policy is applied to strengthen the robustness of neural network models against label poisoning attacks. Similarly,(zhang2023secure)presents a novel vertical federated learning approach explicitly designed to thwart label inference attacks as one of the significant privacy threats in vertical FL systems.\n\nFederated Distillation (FD).As opposed to standard FL exchanges of model parameters, Federated Distillation (FD)(seo202216)only requires the transmission of model outputs, which are significantly smaller in size. The concept of FD draws inspiration from Knowledge Distillation (KD), which focuses on transferring knowledge from a fully trained, large, and complex model (teacher) to a smaller and simpler model (student). In communication resource-constrained settings, federated distillation emerges as a highly appealing solution for sharing knowledge among participants.\nPrevious proposals in this regard are presented in FedMD(li2019fedmd), FedKD(seo202216), and FedGEN(zhu2021data). However, recent investigations have revealed that solely relying on gradient hiding leaves the FL system prone to threats like single-point-of-failure and membership information leakage(yang2023fd). In light of this, researchers have sought to combine knowledge distillation with emerging solutions like blockchain(li2023hbmd)and edge computing(yang2023edge). One notable work(shao2023selective)takes FD to the next level through a selective knowledge-sharing mechanism that is able to handle heterogeneous data. Selective-FD employs client-side and server-side selectors to identify and filter misleading or unreliable contributions during knowledge sharing.\n\nFederated Multi-Task Learning (FMTL).In multi-task learning (MTL), the objective is to train a single model that can effectively handle multiple related tasks simultaneously, rather than building separate models for each task. Federated multi-task learning combines the benefits of MLT with the advantages of FL to address the challenges of learning models for numerous related activities on non-iid data. For instance, the authors in(yi2022hfedmtl)designed HFedMTL, an FMTL system using a primal-dual method for task reduction, enhancing MTL flexibility on massive terminals. Another FMTL scheduling mechanism is developed in(liu2023federated)harnesses a trusted computing sandbox within the blockchain framework.\n\nSynch: Synchronization mode {Synchronous, Asynchronous}.Users: Maximum active users used in experiments.Archi: Architecture {Centralized, Decentralized(P2P), Hierarchical}.Cm. E.: Communication Efficiency.Cp. E.: Computation Efficiency.Conv: Convergence Analysis.Pers: Personalization.Gen: Generalization.Fair: Fairness.Heter: Heterogeneity.Sec: Security.Priv: Privacy.Scal: Scalability.AT: Adversarial Training.FD: Federated Distillation.FMTL: Federated Multi-Task Learning\n\nSecuring the FL aggregation procedure is of utmost importance. The proposals in this category aim for a resilient pipeline against communication issues, client dropouts, and malicious actors. Upon our literature review, we have organized these efforts into three primary categories: robust and secure aggregation, a modified version of the standard aggregation process, and a well-protected execution environment. These categories as well as their sub-categories are summarized in Table2to form a selection of relevant work in the literature.\n\nRobust Aggregation.\n\nRobust aggregation remediates the FL system against security and privacy attacks by detecting and mitigating malicious or inaccurate client models. These practices operate under the assumption that poisoned and benign models exhibit distinguishable features. Their objective is to accomplish this task without jeopardizing performance or introducing communication bottlenecks. The literature explores two main approaches:\n\nMetrics-based Aggregation Methods.The term ”metrics” here refers to specific criteria used to evaluate the quality of local updates, such as trust, reliability, and similarity. The FL server scrutinizes individual models provided by each clientccand compare their performance metrics to a validation dataset using the aggregated model derived from all updates except for that of clientcc. Consequently, the FL server can flag anomalous updates that diminish the model’s utility based on predefined rules or thresholds and potentially discard them. It is worth noting that here, the FL server requires access to a validation dataset, which may not always be feasible in FL. For instance, the FLTrust(cao2020fltrust)exemplifies a trust-based mechanism. It treats client updates as vectors and employs ReLU cosine similarity to assess their alignment with the server model, potentially flagging dissimilar updates. Unlike prior cosine-based methods(ma2022shieldfl), the CosDefense algorithm(yaldiz2023secure)utilizes cosine similarity scores and requires only the updates themselves without requiring additional information. However, the authors in(mao2021romoa)argue that simply calculating distance or similarity is not suﬃcient, proposing hybrid similarity measures with a look-ahead strategy. A similar voting-based strategy is presented in(yue2022federated).\n\nStatistic-based Aggregation Methods.An alternative (or a supplementary) approach to metrics-based verification methods consists of evaluating the statistical properties of update magnitudes such as geometric median(pillutla2022robust), trimmed mean(yin2018byzantine), Krum/multi-Krum(blanchard2017machine), Bulyan(guerraoui2018hidden), and FoolsGold(fung2020limitations). Such indicators filter only valid updates. Nonetheless, it’s important to highlight that these straightforward statistical techniques have demonstrated their vulnerabilities(zizzo2020fat). Consequently, this has led researchers to explore sophisticated methodologies, such as blockchain(liu2022federated), clustering(li2022enhancing), and fair detection(singh2023fair)to boost the FL security.\n\nProcess Modification\n\nMoving Target.Moving Target Defense (MTD) mechanisms orchestrate perturbal adjustments continuously to the system components and parameters, making it more challenging and costly for potential attackers. These proactive measures offer robust protection against intrusions at the server, the network, and the application levels, effectively bolstering the system’s resilience. Inspired by MTD(zhou2021augmented), researchers in(zhou2021augmented)proposed ADS-MTD to achieve CIA security (confidentiality, integrity, and availability) in FL. ADS-MTD uses hierarchical dual shuffling: primary model shuffling and augmented client shuffling. The former anonymizes client contributions, making it difficult for attackers to identify which client contributed to which part of the final global model. While the lateraugmented shufflingdynamically removes malicious clients to ensure model integrity and availability.\n\nPeer-To-Peer Aggregation.Other research has emphasized the advantages of an alternative decentralized solution in federated learning, as it eliminates vulnerabilities to attacks targeting the central hub of the FL system. Therefore, there has been a growing interest in exploring peer-to-peer (or decentralized) aggregation. Nevertheless, it is crucial to consider the implications of such a decentralized aggregation scheme. As such, delegating the monitoring responsibility to individual clients leads to limiting global monitoring capabilities.\nCasting light on traditional FL limitations in mobile robotics, a recent paper(zhou2023decentralized)offers PPAFL, a P2P FL approach in 5G and beyond networks. This secure solution incorporates a Secret Sharing-based communication, a Secure Stochastic Gradient Descent scheme integrated with an Autoencoder, and a Gaussian mechanism to address data leakage. In the same spirit, the study(lu2022privacy)presents a privacy-preserving consensus-based algorithm for decentralized FL, in which learners share their local models exclusively with their one-hub peers. This area of research was extensively explored due to its potential for strengthening FL security and efficiency(wang2023sparsfa;piotrowski2023towards;chen2022cfl).\n\nBlockchain.As defined by(javed2022integration), blockchain technology functions as a distributed and accessible database that acts as a verifiable and tamper-proof ledger. Its application in securing the aggregation process in federated learning yields numerous advantages. Firstly, it cultivates trust among clients and incentivizes the best contributors by rewarding their valuable involvement. Secondly, it reinforces the resilience of the aggregation process, minimizing the risk of vulnerabilities and potential failures, thanks to its remarkable properties of verifiability, traceability, and privacy preservation. Fig.20showcases a seamless integration of blockchain technology within an edge-based FL system(mao2023security). For example, The VFChain proposal(peng2021vfchain)engages blockchain for enhanced security through verifiability and auditability. VFChain replaces central servers with a blockchain-selected verifier committee for aggregation. Also, it introduces an authenticated data structure for efficient verification and secure committee rotation.\nSeveral recent studies have capitalized on this promising approach for various objectives and domains, including healthcare services(samuel2022iomt), Industrial Internet of Things (IIoT) networks(yazdinejad2022block).\n\nTrusted Execution Environment (TEE).\n\nTEEs refer to trusted and secure FL ecosystems that allow only authorized parties to perform attested operations and protect their communications. More specifically, TEE provides a cryptographic and isolated environment where authenticated code can run safely. Additionally, the TEE service is in charge of checking the authenticity and managing the access rights of the participant clients. Thus, the TEE ensures the learning process’s integrity and confidentiality, preventing any tampering or manipulation. For instance, in(mo2021ppfl), the TEEs strategy plays a vital role at both the client and server levels. On the client side, the authors employ a robust greedy layer-wise training approach to keep sensitive information hidden from adversaries. Meanwhile, on the server side, TEEs enable secure aggregation using a cryptographic protocol.\nThe paper presented in(chen2020training)also leverages the isolated enclave of TEEs to ensure the learning process integrity on both the client and server sides. In contrast, the work described in(rieger2022close)focuses, specifically, on the client side and introduces CrowdGuard to combat targeted attacks.\n\nSynch: Synchronization mode {Synchronous, Asynchronous}.Users: Maximum active users used in experiments.Archi: Architecture {Centralized, Decentralized(P2P), Hierarchical}.Cm. E.: Communication Efficiency.Cp. E.: Computation Efficiency.Conv: Convergence Analysis.Pers: Personalization.Gen: Generalization.Fair: Fairness.Heter: Heterogeneity.Sec: Security.Priv: Privacy.Scal: Scalability.\n\n\n================================================================================\n4.4.Data Privacy-Oriented\n================================================================================\nAmidst the conflict between the privacy-by-design aspect of FL and the inherent privacy hurdles associated with its distributed nature, a pressing demand arises: extracting insights while upholding the privacy of data holders. Existing research centers on securing users’ private data, local model updates, and the final deployed model to guarantee that no sensitive information has been revealed. These solutions foster trust among the diverse actors within the federated network, carefully addressing the crucial challenge of harmonizing privacy preservation with knowledge sharing. We summarize in Table2a comprehensive array of strategies and scholarly papers published in this regard.\n\nPerturbations.\n\nThe perturbation mechanisms in FL strategically inject controlled noise to the data or the local model before sharing it with other participants at the expense of a slight degradation in model accuracy. The goal is to protect data privacy and prevent unauthorized access or disclosure of sensitive information.Differential Privacy (DP)stands as one of the most prominent perturbation methods in this domain. Its rigorous mathematical-based proof and flexible privacy-utility trade-offs made it relevant to many privacy-preserving applications in FL. According to(zhang2023systematic), the DP techniques in FL can be divided into three categories: (i) FL with central differential privacy: a trusted central server injects noise into the global parameters. (ii) FL with local differential privacy: each client incorporates noise into their local parameters. (iii) federated learning with distributed differential privacy: address the shortcomings of the two classes above by introducing only a small amount of noise locally and using a secure aggregation technique. From another perspective(zhang2023systematic), the field of DP research can be classified into two distinct categories: DP analysis(zhang2022understanding)and DP proposals(ho2022fedsgdcovid;zhang2023two). Building on DP, the Poisson Binomial Mechanism (BPM) algorithm(chen2022poisson)adds calibrated noise to FL updates, shielding device data from even in the presence of an untrusted aggregator. In particular, the injected noise is meticulously fine-tuned using quantified parameters for privacy (privacy epsilon, privacy budget), resulting in an unbiased yet optimal privacy-accuracy framework. Similarly,(zhang2023two)leverages this strategy within an end-edge-cloud system. Researchers established a flexible two-stage DP policy that can be applied individually or synergistically. Initially, a randomized response algorithm perturbs the feature data. Then, edge servers infuse noise into the model, bolstering security.\n\nHomomorphic Encryption.\n\nHomomorphic Encryption (HE) is an advanced cryptographic technique that facilitates computation on encrypted data without prior decryption. Within the context of FL, HE permits active devices to encrypt their local models, building a formidable barrier against sensitive information breaches. Hence, the aggregator can confidently execute arithmetic operations directly on the encrypted data in a seamlessly emulated fashion as if they were performed on plaintext data, preserving the privacy of individual contributors. Moreover, homomorphic encryption unfolds into three distinctive classes depending on the type and number of ciphertext operations configured: (i)Partially Homomorphic Encryption (PHE)supports one single operation, either addition or multiplication, for infinite times. (ii)Somewhat Homomorphic Encryption (SHE)enables both addition and multiplication, albeit with limitations on the number of computations. (iii)Fully Homomorphic Encryption (FHE)can perform any number of operations in the ciphertext space but requires advanced techniques and it is known to be computationally intensive. Numerous studies in the existing literature have utilized this intricate encryption method to establish robust federated learning frameworks, as shown in(zhang2022homomorphic), ShieldFL(ma2022shieldfl), and FedML-HE(jin2023fedml).\n\nSecure Aggregation.\n\nSecure aggregation plays a pivotal role in upholding the privacy of FL users, guaranteeing that no party discloses its model update in the clear, even to the aggregator. The concern of secure aggregation has been extensively researched, with scholars employing diverse strategies to protect the aggregation process through the lens of privacy, including data perturbations, encryption, secure multi-party aggregation, and blockchain solutions.\n\nSecure Multi-Party Computation (SMPC).SMPC is a sub-field of cryptography wherein a consortium of data owners who do not mutually trust each other jointly perform computations for a specific task. This collaborative effort is underpinned by the strict condition that the confidentiality of the entities’ data remains unbreached throughout the process. The main relevant techniques for implementing the SMPC include Secret Sharing (SS), Garbled Circuit (CC), and Oblivious Transfer (OT). To showcase this potent tool, we reference(tian2022flvoogd), which introduced FLVoogd to enhance efficiency and reduce resource-intensive operations. FLVoogd effectively rejects malicious uploads while protecting sensitive data, utilizing SMPC coupled with DP and Density-based Spatial Clustering of Applications with Noise (DBSCAN). Refer also to(piotrowski2023towards)for a similar study.\n\nSynch: Synchronization mode {Synchronous, Asynchronous}.Users: Maximum active users used in experiments.Archi: Architecture {Centralized, Decentralized(P2P), Hierarchical}.Cm. E.: Communication Efficiency.Cp. E.: Computation Efficiency.Conv: Convergence Analysis.Pers: Personalization.Gen: Generalization.Fair: Fairness.Heter: Heterogeneity.Sec: Security.Priv: Privacy.Scal: Scalability.\n\nTo summarize, we provide in Table2, a summary of the common FL attacks along with their corresponding defense mechanisms, emphasizing the key findings of this section.\n\nAD: Anomaly Detection.ZKPs: Zero Knowledge Proofs.AT: Adversarial Training.FD: Federated Distillation.FMTL: Federated Multi-Task Learning.RA: Robust Aggregation.MT: Moving Target.P2PPeer-to-Peer Aggregation.BC: Blockchain.TEE: Trusted Execution Environment.DP: Differential Privacy.HE: Homomorphic Encryption.SMPC: Secure Multi-Party Computation.\n\n\n================================================================================\n5.Experiments and Results\n================================================================================\nIn this section, we unveil the experimental findings of our study, where we assessed a range of aggregation methods using benchmarking datasets and leveraging PyTorch for implementation. Our primary aim is to provide valuable insights for fellow researchers into evaluating novel FL aggregation proposals in real-world settings.\n\nInitially, we explore the relevant parameters crucial for validating the correctness and efficiency of proposed solutions. These include the hyperparameters of DL models, benchmark datasets, real-world data distributions, and other unique FL parameters like the number of clients and various heterogeneity types. Following this, we examine the responsiveness trends of different aggregation algorithms, each from a distinct class of solution, in order to understand how various variables in the FL ecosystem impact overall performance. Simultaneously, we discuss how each algorithm, representing various classes, responds to variations in the considered variables.\nIn other words, we objectively compare the performance results of the selected algorithms under these relevant settings.\n\nIn essence, we endeavor to offer a nuanced perspective that aids in the holistic understanding of FL practical implementation, providing researchers with a valuable resource for evaluating the aggregation performance of their proposals within realistic simulation scenarios.\n\nFor the sake of simplicity and due to the absence of universally recognized benchmark datasets, we chose to use some of the widely adopted datasets for image classification in the research community. Our selection criteria focused on datasets with a rich number of samples, allowing us to partition the data into hundreds of clients while ensuring each client had sufficient data for adequate training. By employing diverse datasets for the same task (image classification), we aimed to explore varying levels of complexity exhibited in terms of shapes, textures, and patterns. Table2summarizes the characteristics of the employed datasets.\n\nCIFAR-10 and CIFAR-100(krizhevsky2009learning)are computer vision datasets widely used in the field. They consist of 60,000 color images, each with a dimension of 32x32 pixels. CIFAR-10 is composed of images representing 10 different classes, including ubiquitous objects like animals, vehicles, household items, and other categories. CIFAR-100 expands the scope with 100 different classes covering a wider range of objects for more challenging multi-task classification.\n\nFashionMNIST is a popular dataset(xiao2017fashion)that comprises 60,000 grayscale images, each with a resolution of 28x28 pixels, covering 10 distinct classes. However, instead of depicting general objects, FashionMNIST specializes in clothing and accessories items.\n\nMedMNIST(yang2021medmnist;yang2023medmnist)is large-scale MNIST-like biomedical images, including 12 datasets for 2D and six datasets for 3D. All images are 28 × 28 (2D) or 28 × 28 × 28 (3D). For our experiments, we select three datasets: OrganAMNIST, OrganCMNIST, and OrganSMNIST, as in(lu2022personalized). These three datasets are all about Abdominal CT images illustrating 11 distinct classes with 58,850, 23,660, and 25,221 samples, respectively.\n\nThe evaluation of the FL ecosystem must encompass diverse data distribution scenarios, accounting for heterogeneity among clients. Therefore, it is vital to explore non-IID partitions that more accurately mirror real-world conditions besides the simplistic IID distribution that serves as a baseline. However, it is worth noting that numerous research works often lack explicit details regarding the specific non-IID partitions they use despite the various possible schemes for creating such diverse setups. In our simulations, we drew inspiration from the FedLab framework(JMLR:v24:22-0440), which provides eight (8) distinct classes of data distribution for FL settings, as summarized in Table2. From this set, we selected the most suitable categories, includingIID-Balancedfor baseline comparison,Unbalanced-Dirichlet, andQuantity-based Label Distribution Skewfor varying levels of statistical heterogeneity. Fig.21(a)illustrates the data samples assigned to the first 10 clients under the IID-Balanced partition when involving 100 clients and the CIFAR-10 dataset. While Fig.21(b)and Fig.22depict the data samples resulting from the Unbalanced-Dirichlet and Quantity-based Label Distribution Skew partitions, for CIFAR-10 and FashionMNIST, respectively.\n\nP1: Number of samples for each client,P2: distribution for different class samples at each client.\n\nWe have employed CNNs as our deep learning models. Specifically, we used AlexNet(krizhevsky2012imagenet)for the CIFAR dataset and LeNet-5(lecun1998gradient)for the FashionMNIST and MedMNIST datasets. AlexNet and LeNet-5 are renowned architectures tailored for computer vision tasks. AlexNet consists of eight layers, while LeNet-5 consists of seven layers. In all our experiments, we standardize the number of epochs to 5 after fine-tuning from options of [1,3,5], the batch size to 16 or 32 depending on the specific configuration, chosen from a range of [1,16,32,64]. We conducted the training for 300 iterations (number of rounds) after considering several options [100,200,300,400] with a fixed learning rate of10−310^{-3}(refer to Table2). It’s important to note that our fine-tuning simulations were based only on the best performance achieved using FedAvg.\n\nRecognizing the impracticality of assessing all available aggregation methods, we have limited our evaluation of FL aggregation algorithms to four distinct approaches. While the literature boasts a multitude of pioneering aggregation strategies, our intention is to furnish a comprehensive yet focused evaluation of representative approaches that encapsulate the fundamental characteristics and trends. Specifically, for our selection criteria, we have focused on two key factors. Firstly, we aimed to encompass a wide range of contributions families provided by the picked set of algorithms, prioritizing the selection of only one algorithm per solution family. Secondly, we considered the availability of their implementation. As a result, we determined the following set of algorithms for our study:\n\nFedAvg(mcmahan2017communication)The server aggregates all client models through a basic averaging process.\n\nFedDyn(acar2021federated)The algorithm uses regularization terms to speed up convergence and prevent local models from deviating significantly from the global model. Notably, we assess FedDyn over other well-established regularization-based aggregation methods, such as FedProx and Scaffold, given their extensive usage in prior evaluation experiments documented in the literature.\n\nFedBN(li2021fedbn)It employs batch normalization to improve generalization.\n\nPower-of-Choice(cho2020client)The aggregation process relies on client selection determined by loss.\n\nIn Table2, we present the functions employed on both the client and server sides for each algorithm.\n\nIn our initial investigation of parameters, we focus on understanding how the number of clients affects the aggregation process. To isolate this factor and exclusively observe its effect on FL performance, we conducted experiments using an IID data distribution with the CIFAR10 dataset for the FedAvg, Fedbn, and FedDyn algorithms.\n\nIncreasing the number of clients, from 10 to 250, as depicted in Fig.23(a), significantly reduces accuracy. In our specific scenario, this decrement leads to a performance drop of up to 70% with 250 clients. This illustration emphasizes the pivotal role played by the number of clients, which reflects the scale of aggregation a given algorithm can handle effectively. Another vital metric to consider when assessing FL aggregation strategies is the variation in accuracy across participant clients. This measure helps to verify if the global model exhibits robust generalization capabilities, ensuring fair performance without favoring specific clients. Lower accuracy variance indicates a more consistent and fair model. In our scenario, we observed that increasing the number of clients led to higher variance, but there were no significant differences among the three aggregation methods for each client count, as shown in Fig.23(b). Notably, our data distribution was non-heterogeneous in this setup. However, the concerns of accuracy variance typically arise when clients possess heterogeneous data and varied computational resources.\n\nIn essence, the factor of client number necessitates careful caution when designing new FL aggregation proposals. Hence, researchers must exercise precision when discussing the suitability of an aggregation method initially designed for cross-silo federated learning in the cross-device context. Neglecting this adaptation can result in a pronounced decline in performance, as highlighted by our empirical findings.\n\nAddressing the issue of data heterogeneity, we subjected the four chosen algorithms to evaluation under non-IID distribution. To rigorously assess severe cases of data heterogeneity and discern how each algorithm navigates this intricate obstacle, we employed a quantity-based label distribution skew partition across the FashionMNIST dataset. This approach allowed us to create scenarios where the total sample number and the number of samples per class on each client showcased significant imbalances, as visually represented in Fig.22. Given that each client possessed only a specific number of sample classes, we structured our experimentation around thenumber of major classesparameter, which dictates the number of distinct labels each client could hold, spanning from 2 to 8. Additionally, we set the alpha parameter to 0.3, controlling the extent of imbalance in the Dirichlet distribution across 40 clients.\n\nFig.24displays the performance of all assessed algorithms when confronted with escalating levels of data heterogeneity. Visibly, both Fedbn and Powerofchoice demonstrate a more adept ability to navigate this type of heterogeneity, even when the task complexity increases. Conversely, Fedavg and Feddyn experience a significant decline in accuracy, a trend that becomes more pronounced when thenumber of major classesparameter exceeds 5. This disparity in performance can be ascribed to the effectiveness of simple yet influential modifications, such as refined client selection policies (as exemplified in Powerofchoice) or batch normalization technique (as seen in Feddyn). While such enhancements may appear relatively modest in terms of what they bring to the standard Fedavg, they undeniably play a pivotal role in overcoming the formidable challenge posed by data heterogeneity.\n\nAs illustrated in Fig.24(c), the observed disparity in trends between variance and accuracy stems from variations in data distribution among clients, particularly evident in highly imbalanced class scenarios. For instance, when a client’s dataset contains only 2 or 3 classes, data distribution tends to be more diverse, with uneven distribution among those limited classes, resulting in divergent performance levels among clients. Conversely, as the data distribution becomes more balanced with an increase in the number of labels per client, the variance in training accuracy tends to decrease despite potential imbalances in sample distribution across clients. In summary, while high accuracy results may indicate overall performance, they do not account for fairness in individual client contributions. Hence, considering metrics such as variance is essential for a more nuanced understanding of each client’s participation in the collaborative process.\n\nTo simulate system heterogeneity, with a specific focus on the diversity of device resources, we adopted a methodology similar to that outlined in(li2020federatedprox). We kept a fixed number of epochs, denoted as E. Then, we created instances where some devices executed fewer updates than the specified E epoch, considering the restrictions imposed by each device’s current system capabilities. Specifically, In our experimentation, we allocate a certain number of epochs, determined uniformly at random from the range of [1, E], and assigned it to a percentage of active devices. To introduce different levels of resource heterogeneity, we progressively varied this percentage from 0% to 90% in increments of 10%. Scenarios where 0% of devices performed fewer than E epochs represented environments devoid of system heterogeneity. On the other hand, instances where up to 90% of devices executed partial training conveyed highly heterogeneous settings.\n\nUpon analyzing the outcomes presented in Fig.25, it becomes apparent that all the evaluated aggregation methods maintain strong performance as we incrementally introduce system heterogeneity from 0% to 40%. Nevertheless, a notable decline in Fedavg’s performance is observed beyond this threshold, whereas the other algorithms show a modest reduction in average accuracy. This behavior is attributed to Fedavg’s limited capacity to handle significant device heterogeneity. Notably, recent aggregation techniques introduced in the literature, such as Fedbn, Feddyn, and Powerofchoice, have proven their ability to accommodate such disparities.\n\nThe choice of hyperparameters significantly influences the federated learning process. One critical parameter we put under study is the number of communication rounds or iterations. In our experiment, we utilized the MedMNIST dataset with ten (10) clients, partitioning the data according to a Dirichlet distribution with an alpha parameter of 0.3. We ranged the number of iterations from 100 to 600 and analyzed the results in Fig.26(a).\n\nThe tendencies observed for FedAvg, FedBN, and FedDyn are quite similar. These three algorithms exhibit improved accuracy when increasing the number of iterations from 100 to 200 and subsequently from 200 to 300, which is logical as more iterations allow the local models to learn better from the data. However, after surpassing 300 rounds, performance begins to decline due to overfitting. In other words, the models tend to perform exceptionally well on the training data but struggle with unseen data (test data).\n\nThe second hyperparameter under investigation was the learning rate, with the same experimental setup as previously described. We varied the learning rate across the range [0.0001, 0.001, 0.01, 0.02, 0.03, 0.1]. As illustrated in Fig.26(b), it becomes evident that as the learning rate increases, the average loss also rises for all algorithms. This finding implies that for this specific scenario, the optimal learning rate tends to be below 0.001. Typically, this value should be carefully tuned based on the task’s requirements and dataset characteristics.\n\n\n================================================================================\n5.1.Experimental Goals\n================================================================================\nIn this section, we unveil the experimental findings of our study, where we assessed a range of aggregation methods using benchmarking datasets and leveraging PyTorch for implementation. Our primary aim is to provide valuable insights for fellow researchers into evaluating novel FL aggregation proposals in real-world settings.\n\nInitially, we explore the relevant parameters crucial for validating the correctness and efficiency of proposed solutions. These include the hyperparameters of DL models, benchmark datasets, real-world data distributions, and other unique FL parameters like the number of clients and various heterogeneity types. Following this, we examine the responsiveness trends of different aggregation algorithms, each from a distinct class of solution, in order to understand how various variables in the FL ecosystem impact overall performance. Simultaneously, we discuss how each algorithm, representing various classes, responds to variations in the considered variables.\nIn other words, we objectively compare the performance results of the selected algorithms under these relevant settings.\n\nIn essence, we endeavor to offer a nuanced perspective that aids in the holistic understanding of FL practical implementation, providing researchers with a valuable resource for evaluating the aggregation performance of their proposals within realistic simulation scenarios.\n\n\n================================================================================\n5.2.Experimental Baseline\n================================================================================\nFor the sake of simplicity and due to the absence of universally recognized benchmark datasets, we chose to use some of the widely adopted datasets for image classification in the research community. Our selection criteria focused on datasets with a rich number of samples, allowing us to partition the data into hundreds of clients while ensuring each client had sufficient data for adequate training. By employing diverse datasets for the same task (image classification), we aimed to explore varying levels of complexity exhibited in terms of shapes, textures, and patterns. Table2summarizes the characteristics of the employed datasets.\n\nCIFAR-10 and CIFAR-100(krizhevsky2009learning)are computer vision datasets widely used in the field. They consist of 60,000 color images, each with a dimension of 32x32 pixels. CIFAR-10 is composed of images representing 10 different classes, including ubiquitous objects like animals, vehicles, household items, and other categories. CIFAR-100 expands the scope with 100 different classes covering a wider range of objects for more challenging multi-task classification.\n\nFashionMNIST is a popular dataset(xiao2017fashion)that comprises 60,000 grayscale images, each with a resolution of 28x28 pixels, covering 10 distinct classes. However, instead of depicting general objects, FashionMNIST specializes in clothing and accessories items.\n\nMedMNIST(yang2021medmnist;yang2023medmnist)is large-scale MNIST-like biomedical images, including 12 datasets for 2D and six datasets for 3D. All images are 28 × 28 (2D) or 28 × 28 × 28 (3D). For our experiments, we select three datasets: OrganAMNIST, OrganCMNIST, and OrganSMNIST, as in(lu2022personalized). These three datasets are all about Abdominal CT images illustrating 11 distinct classes with 58,850, 23,660, and 25,221 samples, respectively.\n\nThe evaluation of the FL ecosystem must encompass diverse data distribution scenarios, accounting for heterogeneity among clients. Therefore, it is vital to explore non-IID partitions that more accurately mirror real-world conditions besides the simplistic IID distribution that serves as a baseline. However, it is worth noting that numerous research works often lack explicit details regarding the specific non-IID partitions they use despite the various possible schemes for creating such diverse setups. In our simulations, we drew inspiration from the FedLab framework(JMLR:v24:22-0440), which provides eight (8) distinct classes of data distribution for FL settings, as summarized in Table2. From this set, we selected the most suitable categories, includingIID-Balancedfor baseline comparison,Unbalanced-Dirichlet, andQuantity-based Label Distribution Skewfor varying levels of statistical heterogeneity. Fig.21(a)illustrates the data samples assigned to the first 10 clients under the IID-Balanced partition when involving 100 clients and the CIFAR-10 dataset. While Fig.21(b)and Fig.22depict the data samples resulting from the Unbalanced-Dirichlet and Quantity-based Label Distribution Skew partitions, for CIFAR-10 and FashionMNIST, respectively.\n\nP1: Number of samples for each client,P2: distribution for different class samples at each client.\n\nWe have employed CNNs as our deep learning models. Specifically, we used AlexNet(krizhevsky2012imagenet)for the CIFAR dataset and LeNet-5(lecun1998gradient)for the FashionMNIST and MedMNIST datasets. AlexNet and LeNet-5 are renowned architectures tailored for computer vision tasks. AlexNet consists of eight layers, while LeNet-5 consists of seven layers. In all our experiments, we standardize the number of epochs to 5 after fine-tuning from options of [1,3,5], the batch size to 16 or 32 depending on the specific configuration, chosen from a range of [1,16,32,64]. We conducted the training for 300 iterations (number of rounds) after considering several options [100,200,300,400] with a fixed learning rate of10−310^{-3}(refer to Table2). It’s important to note that our fine-tuning simulations were based only on the best performance achieved using FedAvg.\n\nRecognizing the impracticality of assessing all available aggregation methods, we have limited our evaluation of FL aggregation algorithms to four distinct approaches. While the literature boasts a multitude of pioneering aggregation strategies, our intention is to furnish a comprehensive yet focused evaluation of representative approaches that encapsulate the fundamental characteristics and trends. Specifically, for our selection criteria, we have focused on two key factors. Firstly, we aimed to encompass a wide range of contributions families provided by the picked set of algorithms, prioritizing the selection of only one algorithm per solution family. Secondly, we considered the availability of their implementation. As a result, we determined the following set of algorithms for our study:\n\nFedAvg(mcmahan2017communication)The server aggregates all client models through a basic averaging process.\n\nFedDyn(acar2021federated)The algorithm uses regularization terms to speed up convergence and prevent local models from deviating significantly from the global model. Notably, we assess FedDyn over other well-established regularization-based aggregation methods, such as FedProx and Scaffold, given their extensive usage in prior evaluation experiments documented in the literature.\n\nFedBN(li2021fedbn)It employs batch normalization to improve generalization.\n\nPower-of-Choice(cho2020client)The aggregation process relies on client selection determined by loss.\n\nIn Table2, we present the functions employed on both the client and server sides for each algorithm.\n\n\n================================================================================\n5.3.Experimental Results\n================================================================================\nIn our initial investigation of parameters, we focus on understanding how the number of clients affects the aggregation process. To isolate this factor and exclusively observe its effect on FL performance, we conducted experiments using an IID data distribution with the CIFAR10 dataset for the FedAvg, Fedbn, and FedDyn algorithms.\n\nIncreasing the number of clients, from 10 to 250, as depicted in Fig.23(a), significantly reduces accuracy. In our specific scenario, this decrement leads to a performance drop of up to 70% with 250 clients. This illustration emphasizes the pivotal role played by the number of clients, which reflects the scale of aggregation a given algorithm can handle effectively. Another vital metric to consider when assessing FL aggregation strategies is the variation in accuracy across participant clients. This measure helps to verify if the global model exhibits robust generalization capabilities, ensuring fair performance without favoring specific clients. Lower accuracy variance indicates a more consistent and fair model. In our scenario, we observed that increasing the number of clients led to higher variance, but there were no significant differences among the three aggregation methods for each client count, as shown in Fig.23(b). Notably, our data distribution was non-heterogeneous in this setup. However, the concerns of accuracy variance typically arise when clients possess heterogeneous data and varied computational resources.\n\nIn essence, the factor of client number necessitates careful caution when designing new FL aggregation proposals. Hence, researchers must exercise precision when discussing the suitability of an aggregation method initially designed for cross-silo federated learning in the cross-device context. Neglecting this adaptation can result in a pronounced decline in performance, as highlighted by our empirical findings.\n\nAddressing the issue of data heterogeneity, we subjected the four chosen algorithms to evaluation under non-IID distribution. To rigorously assess severe cases of data heterogeneity and discern how each algorithm navigates this intricate obstacle, we employed a quantity-based label distribution skew partition across the FashionMNIST dataset. This approach allowed us to create scenarios where the total sample number and the number of samples per class on each client showcased significant imbalances, as visually represented in Fig.22. Given that each client possessed only a specific number of sample classes, we structured our experimentation around thenumber of major classesparameter, which dictates the number of distinct labels each client could hold, spanning from 2 to 8. Additionally, we set the alpha parameter to 0.3, controlling the extent of imbalance in the Dirichlet distribution across 40 clients.\n\nFig.24displays the performance of all assessed algorithms when confronted with escalating levels of data heterogeneity. Visibly, both Fedbn and Powerofchoice demonstrate a more adept ability to navigate this type of heterogeneity, even when the task complexity increases. Conversely, Fedavg and Feddyn experience a significant decline in accuracy, a trend that becomes more pronounced when thenumber of major classesparameter exceeds 5. This disparity in performance can be ascribed to the effectiveness of simple yet influential modifications, such as refined client selection policies (as exemplified in Powerofchoice) or batch normalization technique (as seen in Feddyn). While such enhancements may appear relatively modest in terms of what they bring to the standard Fedavg, they undeniably play a pivotal role in overcoming the formidable challenge posed by data heterogeneity.\n\nAs illustrated in Fig.24(c), the observed disparity in trends between variance and accuracy stems from variations in data distribution among clients, particularly evident in highly imbalanced class scenarios. For instance, when a client’s dataset contains only 2 or 3 classes, data distribution tends to be more diverse, with uneven distribution among those limited classes, resulting in divergent performance levels among clients. Conversely, as the data distribution becomes more balanced with an increase in the number of labels per client, the variance in training accuracy tends to decrease despite potential imbalances in sample distribution across clients. In summary, while high accuracy results may indicate overall performance, they do not account for fairness in individual client contributions. Hence, considering metrics such as variance is essential for a more nuanced understanding of each client’s participation in the collaborative process.\n\nTo simulate system heterogeneity, with a specific focus on the diversity of device resources, we adopted a methodology similar to that outlined in(li2020federatedprox). We kept a fixed number of epochs, denoted as E. Then, we created instances where some devices executed fewer updates than the specified E epoch, considering the restrictions imposed by each device’s current system capabilities. Specifically, In our experimentation, we allocate a certain number of epochs, determined uniformly at random from the range of [1, E], and assigned it to a percentage of active devices. To introduce different levels of resource heterogeneity, we progressively varied this percentage from 0% to 90% in increments of 10%. Scenarios where 0% of devices performed fewer than E epochs represented environments devoid of system heterogeneity. On the other hand, instances where up to 90% of devices executed partial training conveyed highly heterogeneous settings.\n\nUpon analyzing the outcomes presented in Fig.25, it becomes apparent that all the evaluated aggregation methods maintain strong performance as we incrementally introduce system heterogeneity from 0% to 40%. Nevertheless, a notable decline in Fedavg’s performance is observed beyond this threshold, whereas the other algorithms show a modest reduction in average accuracy. This behavior is attributed to Fedavg’s limited capacity to handle significant device heterogeneity. Notably, recent aggregation techniques introduced in the literature, such as Fedbn, Feddyn, and Powerofchoice, have proven their ability to accommodate such disparities.\n\nThe choice of hyperparameters significantly influences the federated learning process. One critical parameter we put under study is the number of communication rounds or iterations. In our experiment, we utilized the MedMNIST dataset with ten (10) clients, partitioning the data according to a Dirichlet distribution with an alpha parameter of 0.3. We ranged the number of iterations from 100 to 600 and analyzed the results in Fig.26(a).\n\nThe tendencies observed for FedAvg, FedBN, and FedDyn are quite similar. These three algorithms exhibit improved accuracy when increasing the number of iterations from 100 to 200 and subsequently from 200 to 300, which is logical as more iterations allow the local models to learn better from the data. However, after surpassing 300 rounds, performance begins to decline due to overfitting. In other words, the models tend to perform exceptionally well on the training data but struggle with unseen data (test data).\n\nThe second hyperparameter under investigation was the learning rate, with the same experimental setup as previously described. We varied the learning rate across the range [0.0001, 0.001, 0.01, 0.02, 0.03, 0.1]. As illustrated in Fig.26(b), it becomes evident that as the learning rate increases, the average loss also rises for all algorithms. This finding implies that for this specific scenario, the optimal learning rate tends to be below 0.001. Typically, this value should be carefully tuned based on the task’s requirements and dataset characteristics.\n\n\n================================================================================\nNumber of Iteration\n================================================================================\nThe choice of hyperparameters significantly influences the federated learning process. One critical parameter we put under study is the number of communication rounds or iterations. In our experiment, we utilized the MedMNIST dataset with ten (10) clients, partitioning the data according to a Dirichlet distribution with an alpha parameter of 0.3. We ranged the number of iterations from 100 to 600 and analyzed the results in Fig.26(a).\n\nThe tendencies observed for FedAvg, FedBN, and FedDyn are quite similar. These three algorithms exhibit improved accuracy when increasing the number of iterations from 100 to 200 and subsequently from 200 to 300, which is logical as more iterations allow the local models to learn better from the data. However, after surpassing 300 rounds, performance begins to decline due to overfitting. In other words, the models tend to perform exceptionally well on the training data but struggle with unseen data (test data).\n\n\n================================================================================\nLearning Rate\n================================================================================\nThe second hyperparameter under investigation was the learning rate, with the same experimental setup as previously described. We varied the learning rate across the range [0.0001, 0.001, 0.01, 0.02, 0.03, 0.1]. As illustrated in Fig.26(b), it becomes evident that as the learning rate increases, the average loss also rises for all algorithms. This finding implies that for this specific scenario, the optimal learning rate tends to be below 0.001. Typically, this value should be carefully tuned based on the task’s requirements and dataset characteristics.\n\n\n================================================================================\n6.Future Directions\n================================================================================\nIn recent years, the Large Language Models (LLMs) field has witnessed remarkable advancements. Notable LLM models, such as Google’s BERT(devlin2018bert), OpenAI’s ChatGPT-3 and ChatGPT-4(openGPT4), TII’s FlaconLLM(almazrouei2023falcon), and Meta’s LLaMA(touvron2023llama), excel in understanding human language, engaging in life-like conversations, and generating coherent, contextually relevant responses. These models have left an indelible mark on a multitude of AI applications. However, their development and deployment face significant challenges. On the one hand, access to large-scale and high-quality public data is a bottleneck, often impeded by privacy concerns and fierce commercial competition. Additionally, the demand for outstanding computational resources is insatiable. On the other hand, research has shown that amplifying the scale of LLMs in terms of both model parameters and training data yields substantial performance gains, especially for handling complex tasks(ferrag2023securefalcon).\n\nIn light of these constraints, FL emerges as a beacon of promise, introducing a decentralized AI paradigm that could revolutionize the LLM domain. FL offers a spectrum of benefits spanning over the entire lifecycle of LLMs, from pre-training and fine-tuning to deployment and downstream applications(chen2023federated). Thanks to its contemporary techniques like parameter-efficient training methods, prompt tuning, and advanced model compression, FL facilitates the distribution of the computational workload across multiple participants. Moreover, ensuring the fluid embodiment of trustworthy FL mechanisms within the LLM ecosystem is pivotal for encountering limitations tied to privacy, security, robustness, and bias concerns(zhuang2023foundation). Therefore, these hot research topics, at the crossroads of FL and LLMs, hold tantalizing prospects for exploration and practical implementation. Unleashing the potential of this harmonious collaboration promises to unlock a trove of impressive advantages(zhang2023gpt).\n\nIn the wake of 5G’s transformative impact on the networking landscape, as it continues to be deployed globally, the spotlight is now on the next-gen wireless revolution, i.e., Sixth-generation (6G)(letaief2019roadmap). As its core, 6G promises to deliver ubiquitous, seamless, and high-performance connectivity, all while prioritizing security and privacy. The ultimate aim is to mark a shift from ”connected things” to ”connected intelligence” in modern network systems(dang2020should). Furthermore, driven by Industry 5.0 principles and advanced AI technologies, 6G is poised to introduce groundbreaking benefits in the ears of new media, new services, and new infrastructure(liu2020federated).\n\nIn this context, FL emerges as a captivating avenue of exploration, bearing immense potential for empowering 6G with AI capabilities, yet FL is still in the nascent stages and confronts novel challenges when embedded into 6G scenarios. One such issue lies in communication efficiency, as the current infrastructure strains to support FL-enabled 6G across a wider geographic area, necessitating the development of innovative, communication-efficient methodologies, practically, for cross-device FL. Besides, the security and privacy of FL within the 6G ecosystem demand vigilant attention. Robust aggregation techniques, tailored defense strategies, and the creation of heterogeneity-tolerant environments are imperative to ensure the success of FL in the 6G era, guarding against numerous vulnerabilities exploited by malicious FL actors.\n\nA digital twin (DT) is a virtual emulation of a physical system, mirroring its elements and dynamics in real-time. The fundamental idea behind DT is to forge a digital system replica, seamlessly connected to its real-world counterpart through bidirectional links. Consequently, this simulation ensures that the DT remains a precise and up-to-date representation of its physical system(khan2022digital). In contexts such as IoT-enabled 6G systems, DT plays a pivotal role in achieving low latency, reliable connectivity, high performance, and energy efficiency. Moreover, when paired with data analytics and ML techniques, DT facilitates the adept management of complex systems and enhances decision-making processes for flight systems, the military, smart cities, healthcare, and others. However, integrating DT modeling into IoT and edge computing applications poses notable challenges. Firstly, DT relies on extensive distributed data, a feat hindered by privacy concerns, rendering data amalgamation from diverse devices nearly unattainable. Secondly, the imperative real-time interplay between DTs and their corresponding entities requires frequent device communication. Yet, conventional centralized ML network architectures often falter in this regard(yang2022optimizing).\n\nAcknowledging the distinctive merits of FL, including its decentralization, privacy preservation, data wealth, efficiency, and security aspects, some researchers have ventured into employing FL to construct DT models. Nevertheless, the current literature lacks a comprehensive examination of this promising fusion of FL and DT. As DT is emerging as one of the most influential technologies in the coming decades(al2023edge), researchers are encouraged to investigate the potential synergy between FL and DT, unveiling numerous possibilities for mutual empowerment.\n\nIn response to the shortcomings of data-hungry ML techniques, researchers are actively exploring novel approaches, particularly few-shot learning, to reduce data requirements while enhancing model performance. In effect, few-shot learning presents a compelling method that trains models to rapidly adapt to new tasks using minimal data and fewer training iterations(griva2023model). Meta-learning, often known as ”learning how to learn”, has gained popularity in pursuit of this goal. In contrast to standard AI approaches that solve tasks from scratch using fixed learning algorithms, meta-learning seeks to improve the learning algorithm itself, leveraging insights gained from previous learning experiences. In other words, it involves distilling knowledge from multiple learning episodes, often spanning various related tasks, to improve future learning performance. This results in improved data efficiency, better knowledge transfer, and enhanced unsupervised learning when training DL models(gharoun2023meta).\n\nIntegrating meta-learning into the FL framework brings numerous gains. Remarkably, federated meta-learning swiftly adapts to new heterogenous tasks even with small datapoints, all while conserving computational resources and training time. Moreover, as exemplified in(finn2017model), the emergence of optimization meta-learning algorithms, designed to learn and fine-tune FL-related components like selected clients and regularization terms, represents a promising area of research. To fully harness the potential of this dynamic field and its related areas, such as domain adaptation and domain generalization(hospedales2021meta), further research is essential to unlock the myriad opportunities they offer within the FL.\n\nIn current federated learning approaches, there is an implicit assumption that client data remains static and unaltered. However, this premise frequently diverges from reality. Users often operate in dynamic environments where local data continuously evolve due to sensor observations, resulting in the incremental inclusion of new classes into the training data. When confronted with this scenario, conventional training and aggregation methods struggle with a challenge known as ”catastrophic forgetting.” This phenomenon results in a significant decline in overall performance as new classes are introduced incrementally. Traditional NN models require the entire dataset, including old and new class samples, to be available during training. Wearers, this requirement becomes rapidly impractical as the number of classes expands. An ideal approach to address this issue isincremental learning, as referred to in the literature. The core concept of incremental learning is to train incrementally on an infinitely expanding set of classes while maintaining accuracy and the same number of model parameters(castro2018end). Consequently, the combination of federated learning and incremental learning becomes an intriguing area for investigation(liu2023recent).\n\nAnother set of assumptions about datasets used in FL settings are unimodal (containing a singular data type: image, audio, or tabular inputs) and completely labeled (comprising readily available labeled data in the standard format). However, many practical application domains involve clients with multimodal data(lin2023federated)and limited access to ground-truth labels(ding2022federated). Dealing with data incompleteness, its dynamic and multimodal aspects in FL remains largely unexplored but holds significant promise. Therefore, research efforts in these directions can bring innovative solutions that benefit the broader federated learning community.\n\n\n================================================================================\n6.1.Federated Learning-Empowred Large Language Models\n================================================================================\nIn recent years, the Large Language Models (LLMs) field has witnessed remarkable advancements. Notable LLM models, such as Google’s BERT(devlin2018bert), OpenAI’s ChatGPT-3 and ChatGPT-4(openGPT4), TII’s FlaconLLM(almazrouei2023falcon), and Meta’s LLaMA(touvron2023llama), excel in understanding human language, engaging in life-like conversations, and generating coherent, contextually relevant responses. These models have left an indelible mark on a multitude of AI applications. However, their development and deployment face significant challenges. On the one hand, access to large-scale and high-quality public data is a bottleneck, often impeded by privacy concerns and fierce commercial competition. Additionally, the demand for outstanding computational resources is insatiable. On the other hand, research has shown that amplifying the scale of LLMs in terms of both model parameters and training data yields substantial performance gains, especially for handling complex tasks(ferrag2023securefalcon).\n\nIn light of these constraints, FL emerges as a beacon of promise, introducing a decentralized AI paradigm that could revolutionize the LLM domain. FL offers a spectrum of benefits spanning over the entire lifecycle of LLMs, from pre-training and fine-tuning to deployment and downstream applications(chen2023federated). Thanks to its contemporary techniques like parameter-efficient training methods, prompt tuning, and advanced model compression, FL facilitates the distribution of the computational workload across multiple participants. Moreover, ensuring the fluid embodiment of trustworthy FL mechanisms within the LLM ecosystem is pivotal for encountering limitations tied to privacy, security, robustness, and bias concerns(zhuang2023foundation). Therefore, these hot research topics, at the crossroads of FL and LLMs, hold tantalizing prospects for exploration and practical implementation. Unleashing the potential of this harmonious collaboration promises to unlock a trove of impressive advantages(zhang2023gpt).\n\n\n================================================================================\n6.2.Federated Learning for 6G and Beyond Technologies\n================================================================================\nIn the wake of 5G’s transformative impact on the networking landscape, as it continues to be deployed globally, the spotlight is now on the next-gen wireless revolution, i.e., Sixth-generation (6G)(letaief2019roadmap). As its core, 6G promises to deliver ubiquitous, seamless, and high-performance connectivity, all while prioritizing security and privacy. The ultimate aim is to mark a shift from ”connected things” to ”connected intelligence” in modern network systems(dang2020should). Furthermore, driven by Industry 5.0 principles and advanced AI technologies, 6G is poised to introduce groundbreaking benefits in the ears of new media, new services, and new infrastructure(liu2020federated).\n\nIn this context, FL emerges as a captivating avenue of exploration, bearing immense potential for empowering 6G with AI capabilities, yet FL is still in the nascent stages and confronts novel challenges when embedded into 6G scenarios. One such issue lies in communication efficiency, as the current infrastructure strains to support FL-enabled 6G across a wider geographic area, necessitating the development of innovative, communication-efficient methodologies, practically, for cross-device FL. Besides, the security and privacy of FL within the 6G ecosystem demand vigilant attention. Robust aggregation techniques, tailored defense strategies, and the creation of heterogeneity-tolerant environments are imperative to ensure the success of FL in the 6G era, guarding against numerous vulnerabilities exploited by malicious FL actors.\n\n\n================================================================================\n6.3.Federated Learning Integrated Digital Twin Systems\n================================================================================\nA digital twin (DT) is a virtual emulation of a physical system, mirroring its elements and dynamics in real-time. The fundamental idea behind DT is to forge a digital system replica, seamlessly connected to its real-world counterpart through bidirectional links. Consequently, this simulation ensures that the DT remains a precise and up-to-date representation of its physical system(khan2022digital). In contexts such as IoT-enabled 6G systems, DT plays a pivotal role in achieving low latency, reliable connectivity, high performance, and energy efficiency. Moreover, when paired with data analytics and ML techniques, DT facilitates the adept management of complex systems and enhances decision-making processes for flight systems, the military, smart cities, healthcare, and others. However, integrating DT modeling into IoT and edge computing applications poses notable challenges. Firstly, DT relies on extensive distributed data, a feat hindered by privacy concerns, rendering data amalgamation from diverse devices nearly unattainable. Secondly, the imperative real-time interplay between DTs and their corresponding entities requires frequent device communication. Yet, conventional centralized ML network architectures often falter in this regard(yang2022optimizing).\n\nAcknowledging the distinctive merits of FL, including its decentralization, privacy preservation, data wealth, efficiency, and security aspects, some researchers have ventured into employing FL to construct DT models. Nevertheless, the current literature lacks a comprehensive examination of this promising fusion of FL and DT. As DT is emerging as one of the most influential technologies in the coming decades(al2023edge), researchers are encouraged to investigate the potential synergy between FL and DT, unveiling numerous possibilities for mutual empowerment.\n\n\n================================================================================\n6.4.Federated Meta-Learning\n================================================================================\nIn response to the shortcomings of data-hungry ML techniques, researchers are actively exploring novel approaches, particularly few-shot learning, to reduce data requirements while enhancing model performance. In effect, few-shot learning presents a compelling method that trains models to rapidly adapt to new tasks using minimal data and fewer training iterations(griva2023model). Meta-learning, often known as ”learning how to learn”, has gained popularity in pursuit of this goal. In contrast to standard AI approaches that solve tasks from scratch using fixed learning algorithms, meta-learning seeks to improve the learning algorithm itself, leveraging insights gained from previous learning experiences. In other words, it involves distilling knowledge from multiple learning episodes, often spanning various related tasks, to improve future learning performance. This results in improved data efficiency, better knowledge transfer, and enhanced unsupervised learning when training DL models(gharoun2023meta).\n\nIntegrating meta-learning into the FL framework brings numerous gains. Remarkably, federated meta-learning swiftly adapts to new heterogenous tasks even with small datapoints, all while conserving computational resources and training time. Moreover, as exemplified in(finn2017model), the emergence of optimization meta-learning algorithms, designed to learn and fine-tune FL-related components like selected clients and regularization terms, represents a promising area of research. To fully harness the potential of this dynamic field and its related areas, such as domain adaptation and domain generalization(hospedales2021meta), further research is essential to unlock the myriad opportunities they offer within the FL.\n\n\n================================================================================\n6.5.Multimodal and Dynamic Federated Learning\n================================================================================\nIn current federated learning approaches, there is an implicit assumption that client data remains static and unaltered. However, this premise frequently diverges from reality. Users often operate in dynamic environments where local data continuously evolve due to sensor observations, resulting in the incremental inclusion of new classes into the training data. When confronted with this scenario, conventional training and aggregation methods struggle with a challenge known as ”catastrophic forgetting.” This phenomenon results in a significant decline in overall performance as new classes are introduced incrementally. Traditional NN models require the entire dataset, including old and new class samples, to be available during training. Wearers, this requirement becomes rapidly impractical as the number of classes expands. An ideal approach to address this issue isincremental learning, as referred to in the literature. The core concept of incremental learning is to train incrementally on an infinitely expanding set of classes while maintaining accuracy and the same number of model parameters(castro2018end). Consequently, the combination of federated learning and incremental learning becomes an intriguing area for investigation(liu2023recent).\n\nAnother set of assumptions about datasets used in FL settings are unimodal (containing a singular data type: image, audio, or tabular inputs) and completely labeled (comprising readily available labeled data in the standard format). However, many practical application domains involve clients with multimodal data(lin2023federated)and limited access to ground-truth labels(ding2022federated). Dealing with data incompleteness, its dynamic and multimodal aspects in FL remains largely unexplored but holds significant promise. Therefore, research efforts in these directions can bring innovative solutions that benefit the broader federated learning community.\n\n\n================================================================================\n7.Conclusions\n================================================================================\nIn this survey, we concentrate on three primary clusters of contributions around the federated learning paradigm: personalization, optimization, and robustness. Within this high-level classification, we dissect our investigation to delve into the challenges and potential solutions found in the literature. Consequently, we propose multi-level and well-structured classification schemes that better organize the content within the classes and sub-classes of each cluster, resulting in six (06) distinct taxonomy schemes with up to four (04) layers each.\nSpecifically, we examine various facets of federated learning, including diverse types of heterogeneity, efficiency, security, and privacy concerns. Then, we down-break the contemporary strategies addressing these topics into three-level taxonomies, mainly focused on aggregation methods. Additionally, we illustrate the exploration of these promising strategies with recent work published over the past three years. Distinguishing our survey from others is our hybrid methodology for selecting state-of-the-art papers. We combined bibliometric analysis using CiteSpace to understand the trends and dynamics of FL with systematic scrutiny to include only the most relevant and exceptional work. These scholarly publications illustrate the myriad application areas of FL, including healthcare, industry, robotics, and recommendation systems. Additionally, they demonstrate the emergence of FL coupling with other cutting-edge technologies, such as blockchain, edge, fog, IoT, and many more. To facilitate efficient content navigation, we have evaluated and summarised the features of most surveyed literature in informative yet concise tables with a total of 14 criteria corresponding to two distinct families (i.e., proposal environment and verified goals). The resulting nine (09) tables encompass 85 carefully selected papers. We further perform extensive simulations to evaluate the performance of four popular aggregation algorithms, including FedAvg, FedBn, FedDyn, and Powerofchoice, across six (06) real-world scenarios. Our experimental findings align closely with our theoretical analysis regarding scalability, generalization, fairness, statistical heterogeneity, system heterogeneity, and DL hyperparameter tuning. To conclude our navigation in the FL landscape, we present a compelling set of future research directions, encouraging fellow researchers to dive deeper into these captivating areas of investigation.\n\nIn summary, we believe that our survey is the most comprehensive in its coverage of challenges and techniques. Simultaneously, it carefully structures the content with a high degree of hierarchical organization to assist researchers in navigating specific topics of their interest. Moreover, it pioneers an aggregation-centric approach to the FL domain and furnishes detailed guidelines for evaluating novel proposals within practical settings.\n\n",
      "stats": {
        "characters": 318758,
        "tokens": 59624,
        "lines": 1373
      }
    },
    {
      "id": 2,
      "metadata": {
        "source": "arxiv_html",
        "paper_id": "2308.11841v2",
        "title": "A Survey for Federated Learning Evaluations:Goals and Measures",
        "authors": [
          "Di Chai*{}^{*}start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT,\nLeye Wang*{}^{*}start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT,\nLiu Yang,\nJunxue Zhang,\nKai Chen,\nQiangYang*{}^{*}start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPTEqual Contribution"
        ],
        "url": "https://arxiv.org/html/2308.11841v2",
        "abstract": "AbstractEvaluation is a systematic approach to assessing how well a system achieves its intended purpose. Federated learning (FL) is a novel paradigm for privacy-preserving machine learning that allows multiple parties to collaboratively train models without sharing sensitive data. However, evaluating FL is challenging due to its interdisciplinary nature and diverse goals, such as utility, efficiency, and security. In this survey, we first review the major evaluation goals adopted in the existing studies and then explore the evaluation metrics used for each goal. We also introduceFedEval, an open-source platform that provides a standardized and comprehensive evaluation framework for FL algorithms in terms of their utility, efficiency, and security. Finally, we discuss several challenges and future research directions for FL evaluation."
      },
      "content": "Title: A Survey for Federated Learning Evaluations:Goals and Measures\nAuthors: Di Chai*{}^{*}start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT,\nLeye Wang*{}^{*}start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT,\nLiu Yang,\nJunxue Zhang,\nKai Chen,\nQiangYang*{}^{*}start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPTEqual Contribution\nAbstract:\nAbstractEvaluation is a systematic approach to assessing how well a system achieves its intended purpose. Federated learning (FL) is a novel paradigm for privacy-preserving machine learning that allows multiple parties to collaboratively train models without sharing sensitive data. However, evaluating FL is challenging due to its interdisciplinary nature and diverse goals, such as utility, efficiency, and security. In this survey, we first review the major evaluation goals adopted in the existing studies and then explore the evaluation metrics used for each goal. We also introduceFedEval, an open-source platform that provides a standardized and comprehensive evaluation framework for FL algorithms in terms of their utility, efficiency, and security. Finally, we discuss several challenges and future research directions for FL evaluation.\n\n\n================================================================================\nIIntroduction\n================================================================================\nFederated learning (FL) is an emerging technology that aims to address data privacy concerns in real-world applications.\n Data privacy has become an increasingly severe issue today as more and more real-life applications are driven by cross-domain private data. Companies that fail to protect users’ privacy may face a hefty fine. For instance, the Federal Trade Commission (FTC) fined Facebook $5 billion to force new privacy measures[1], and Luxembourg’s National Commission for Data Protection (CNPD) imposed a record-breaking fine of $887 million on Amazon for misusing customer data for targeted advertising purposes[2].\nIn this situation, federated learning (FL) has received many research and industry interests as a new paradigm of privacy-preserving machine learning[3]. Rather than collecting massive user data for model training, FL sets up a joint training scenario in which the clients’ devices participate in model training under a joint agreement with a central authority. The client devices only upload specific model parameters to the cloud server for aggregation. Recently, FL has appeared on the Gartner ‘Hype Cycle for Data Science and Machine Learning’ at the innovation trigger stage, indicating the importance and widespread acceptance of the FL technique[4].\n\nEvaluation plays a critical role in designing various FL algorithms and systems, owing to the need for rigorous performance assessment, providing comparative analysis between different algorithms, ensuring robustness across diverse environments, and identifying limitations for further improvement.\n\nConceptually, evaluation is a systematic method to investigate how well a model, framework, or system meets its intended purposes. Essentially, two fundamental questions must be answered during the evaluation process: (1)what are thegoalsthat need to be achieved?, and (2)how can the ability to achieve these goals bemeasured?For example, in the case of image classification, achievinghigh accuracyis a primary goal; to measure accuracy, many research works have evaluated their models on the well-known public dataset, ImageNet, leading to the creation of the ImageNet leaderboard.111https://paperswithcode.com/sota/image-classification-on-imagenetIn this article, we aim to provide clarity on the two evaluation issues for FL systems, namely goals and measurements.\nBy doing so, we hope to assist researchers in conducting FL system evaluations in a more comprehensive and accessible manner and contribute to the healthy development of the entire FL community.\n\nThe evaluation of FL is challenging as it is a multi-objective and cross-domain research topic that leverages techniques from machine learning, distributed systems, cryptography,etc. The typical FL process usually contains three steps[3]: 1) all parties perform local updates using private data; 2) all parties send the locally updated parameters to a third-party server, which will perform an aggregation on the received updates to produce the global updated parameter; 3) all parties download the global parameter to replace the local one and continue the next round of training. Generally, studies from the machine learning domain aim to improve the model utility, studies from distributed systems aim to improve efficiency, and privacy-preserving researchers mainly focus on privacy protections. Existing studies[5,6]have shown that these targets are not independent objectives and exhibit substantial interrelation. Enhancing one target usually has negative impacts on the other targets[5,6]. For example, increasing the number of local updates before global synchronization (i.e., reducing global synchronization frequency) can improve communication efficiency but harm model accuracy. With more local updates, a model trained on heterogeneous, non-identical-and-independent distributed (non-IID) data across clients will deviate further from the global optimum, which is known as the non-IID issue[7]. This illustrates the trade-off between communication efficiency and model utility, and we will discuss more trade-offs between different targets inSectionII-D. Appropriate and comprehensive evaluations can guide our future research directions by fully revealing the tradeoffs between different objectives, as well as the theoretical upper and lower bounds on the performance of different methods under varying conditions (e.g., different data distributions).\n\nAppropriate evaluation is crucial to not only promote the healthy development of FL, but the evaluations themselves can enable further applications.\n\nEvaluation as Quality Control.Real-world applications prefer FL models with excellent performance. FL models with significant issues, such as private data leakage, are unsuitable for practical applications. Therefore, FL system evaluation serves as a quality control measure for FL models before they can be used in real-world scenarios.\n\nEvaluation for Incentive Design.FL system evaluation can also work with incentive mechanisms during federated training. Specifically, the contribution of each data provider needs to be quantitatively evaluated, and then the payoff of the federation can be allocated fairly according to these evaluations[8,9].\n\nEvaluation as Online Verification.Existing FL studies often make assumptions, particularly for security-related assumptions such as semi-honest behavior. However, these assumptions may not always hold in practice. FL system evaluation can serve as an online verification tool to ensure that FL participants adhere strictly to the pre-defined protocol.\n\nIn contrast, the inappropriate evaluation will produce biased assessments, and the undiscovered limitations in FL algorithms or systems will damage real-world applications. For example, undiscovered privacy vulnerabilities will not only leak data providers’ privacy but also decrease people’s trust and willingness to further contribute data in the federated systems; FL algorithms untested under different data distributions may achieve poor model quality in applications as the data distribution in real-world applications can be highly heterogeneous[7,10,11,12,13,14,15,16]; FL systems not evaluated on real-world network conditions may fail to achieve expected efficiency in applications due to the limited bandwidth and high latency in real-world applications.\n\nIn this survey, we first summarize the evaluation goals for FL. We then introduce various well-studied metrics and procedures for measuring these evaluation goals. Furthermore, we will present an open-source platform for FL evaluation calledFedEval.222https://github.com/Di-Chai/FedEvalThis platform can aid researchers in implementing a standardized and comprehensive FL evaluation procedure with ease. Finally, we will discuss the challenges and future directions for FL system evaluations.\n\nNecessity of our evaluation surveyThe fast development of FL has motivated many survey studies to summarize the advances and challenges of FL. Specifically, existing FL survey studies[3,17,18,19,20]introduced the concepts and applications of FL,[21]emphasized the non-IID studies,[22,23,24]focused on the security and privacy in FL,[25]focused on the incentive design,[26,27,28,29]emphasized the internet of things (IoT) scenario,[30,31,32]summarized the medical and health case applications of FL,[33]and[34]introduced the application of smart city and graph learning, respectively. Existing FL surveys focus on elaborating the new techniques and applications of FL, and the survey study on the evaluation of FL has been lacking. However, the evaluation of FL is a complicated problem since FL is a cross-domain topic that consists of machine learning, distributed systems, and privacy-preserving techniques, making the evaluation of FL contains many targets,e.g., utility, robustness, privacy preservation,etc. An unreasonable evaluation process will cause an unjustified assessment of FL methods and may bring severe issues in real-world applications,e.g., one not well-evaluated FL algorithm in the health care application can cause medical accidents. Thus, the survey study on the evaluation of FL to comprehensively analyze the evaluation targets and uncover the challenges in FL evaluation is urgently required to promote the healthy development of FL.\n\n\n================================================================================\nIIFederated Learning Evaluation Goals\n================================================================================\nIn this section, we summarize all the goals that need to be considered in the evaluation of FL (Figure1).\nIn general, there are two main types of FL processes: horizontal federated learning (HFL) and vertical federated learning (VFL). HFL assumes that parties have the same feature space but different sample spaces; generally, HFL is applied in edge computing scenarios,e.g., different edge users collaboratively train the next-word-prediction model[35].\nVFL assumes that parties have the same sample space but different feature spaces; VFL is typically a to-business paradigm of FL, which happens between organizations,e.g., banks need data from online shopping companies to decide whether to approve one user’s credit card application.\nThe evaluation goals and measures presented in this survey do not restrict the type of FL and work with both HFL and VFL.\n\nFL generally learns a model based on data from multiple parties without directly collecting data together to meet data protection requirements in many laws and regulations.\nHence, the primary goal is to obtain a federated model with almost the same predictive power as the model directly trained from all parties’ data to ensure the highutilityof the FL model.\nWe discuss utility from two aspects:effectivenessandrobustness.\n\nGoal 1.1: Effectiveness. FL aims to train a global model collaboratively using data distributed across participants. Ideally, the FL training should be able to achieve the same prediction accuracy as centralized training (i.e., collecting all the data in one place).\nFor the FL system that can approximate a centralized model’s predictive power, we then call this FL system withhigh effectiveness.\n\nGoal 1.2: Robustness. In practice, FL systems cannot always run in an ideal experimental environment, and various incidents may occasionally happen.\nHence, a comprehensive evaluation of the FL system should pre-define such scenarios as much as possible to reflect the system’srobustnessin practice.\nIn particular, many participants indicate a significant disparity in devices. Data distributions, communication networks (3G, 4G, WiFi), computing resources (CPU, GPU),etc, may vary among parties. These diversities and uncertainties could cause issues that significantly affect the FL system[36].\n\nUnlike conventional distributed machine learning, which is carried out on different machines in one data center[37], FL is performed on cross-data-center machines or edge devices, which have lower networking or computing resources[36].\nConsequently, a deep neural network that could be trained in minutes using centralized machines may take hours to finish the training in FL[38]. Thus, efficiency is essential in FL and needs to be carefully evaluated.\nBased on existing works, we categorize the efficiency evaluation into two aspects:communicationefficiency andcomputationefficiency.\n\nGoal 2.1: Communication Efficiency. In HFL, the edge devices have limited networking resources,e.g., low bandwidth and high latency, making the communication between the server and devices expensive[36]. In VFL, the federation usually consists of machines from different data centers (i.e., from different companies). The cross-data-center communication is slow and has high latency[39]. Moreover, each party, in both HFL and VFL, may join more than one federation, and the FL training tasks from different federations will compete for resources[9,40], making the communication efficiency issue more severe.\n\nGoal 2.2: Computation Efficiency. In HFL, although the edge devices tend to have more powerful hardware, they still cannot match the ability of centralized computing servers, especially when dealing with large models[41]. Thus, the low computation efficiency problem cannot be dismissed in the federated learning scenario. Moreover, different parties often hold distinct computation resources, which may incur significant differences in computation speed between parties[42]. This can further impact the whole FL method’s efficiency in a complicated manner.\n\nSecurity and privacy are the foundation of FL systems. HFL algorithms,e.g., FedAvg, perform aggregation on model parameters, and the risk of private data leakage can be reduced since the users’ data never leaves their devices. However, recent works have shown that gradients can reveal input data and labels[43,44]. Apart from the private data leakage threats to data holders, there are also model security threats to model users. Malicious edge parties could use data poisoning or model poisoning attacks to damage or backdoor the model. Specifically, FL is often expected to achieve the following two security and privacy goals:\n\nGoal 3.1: Data Privacy. FL enables different parties to jointly train machine learning models without exchanging raw data, and only intermediate results are exchanged. However, recent works have shown that the intermediate results (e.g., gradients) could be used to recover FL parties’ private data[43,44]when no privacy-preserving techniques are adopted (e.g., homomorphic encryption), resulting in the data privacy issue.Goal 3.2: Model Security. Federated learning happens over a bunch of distributed parties (e.g., mobile devices), and there is no root of trust in existing methods,i.e., every party could be malicious from the model users’ perspective. Thus, the participants could easily attack the model using poisoning methods, resulting in the model security issue[45,46].\n\nIt is worth noting that an FL system may not simultaneously improve all the goals, includingutility,efficiency, andsecurity & privacy. While a new algorithm improves one goal, it remains essential to comprehensively evaluate performance on other goals as well since trade-offs exist between different goals. The comprehensive analysis helps determine whether an algorithm represents unambiguous progress over state-of-the-art solutions by improving one aspect without detriment to others or gains on one goal induce losses on others, reflecting an ambiguous contribution.\n\nTo this end, comprehensively evaluating an FL system from all three aspects becomes extremely important to deeply understand the advantages and disadvantages of FL systems (algorithms, models). Next, we would like to demonstrate more details about the trade-offs between the goals.\n\nUtility vs. Efficiency.Federated SGD (FedSGD) and Federated Average (FedAvg) are two mostly well-known FL methods proposed by Google[35]. FedSGD inherits the settings of large-batch synchronous SGD (the state-of-the-art machine learning method used in data centers). In FedSGD, all clients synchronize the gradients before updating the local model weights. In contrast, only part of the clients participate in each round of training in FedAvg and the clients perform multiple rounds of local training before the synchronization.\n\nFedSGD and FedAvg reveal the trade-off of utility and efficiency in FL. On the one hand, FedAvg improves communication efficiency (i.e., fewer communication rounds) by increasing clients’ local training rounds before the global synchronization. On the other hand, the increased clients’ local training rounds unexpectedly drift the global model away from the global optimum under heterogeneous data distributions, making FedAvg reach worse model utility than FedSGD.\n\nApart from FedSGD and FedAvg, there are also other FL studies that encounter the trade-off between utility and efficiency. For example, some studies utilize gradient compression techniques to improve communication efficiency[12]; however, the model utility may decrease since only partial model parameters are synchronized.\n\nEfficiency vs. Security & Privacy.While many privacy-preserving techniques are adopted in FL to enhance privacy and security protection, there is no free lunch.\nPrivacy protection generally downgrades the efficiency of the system.\n\nHomomorphic Encryption (HE): HE is a special encryption algorithm that enables us to perform computations directly on encrypted numbers without decryption. HE is widely applied in FL to protect the intermediate results,e.g., the gradients[47,48]. The encrypted numbers (i.e., ciphertext) bring the efficiency overhead in two aspects. First, the ciphertext consumes larger storage space than plaintext, which brings communication overhead. Second, the computation on ciphertext is more complicated than plaintext, which brings computation overhead.\n\nSecret Sharing (SS)[49]: SS is a secure multi-party computation framework, in which different participants secretly share their data among all participants. Each participant only holds one data partition, which leaks no private information about the raw data. Basic operations, like addition and multiplication, are defined under the partitioned data, and then computations like polynomial functions could be carried out. SS mainly brings communication overhead, especially when doing multiplication[50]. More specially, SS is very sensitive to the networking latency.\n\nSecure Aggregation (SA):\nSA is utilized in horizontal FL to combine the parameter updates from clients in a manner that protects the privacy of the individual client’s local updates from a semi-honest server[51].\nSA operates in a way similar to the addition operation in SS but with the added benefit of enhancing the resilience of the aggregation process when some clients may disconnect.\nSimilar to SS, SA also introduces communication overhead.\n\nIt is worth noting that, the above protection techniques can often be incorporated into various FL algorithms[35,52]to further enhance the protection level. Meanwhile, it would incur communication and/or computation overhead. Hence, in practice, the FL system designer should decide whether these extra protection methods are necessary according to the application scenario to balance efficiency and privacy protection.\n\nUtility vs. Security & Privacy.In addition to efficiency, some privacy-preserving techniques may also degrade the utility of FL systems.\n\nDifferential Privacy (DP): a well-known privacy-preserving technique adopted in FL is differential privacy (DP)[53]. Clients locally add DP noise to the data or model to protect the private data. DP-based FL solutions reveal the trade-off between model utility and privacy. Adding more noise will have better privacy preservation, however, will significantly downgrade the model’s utility.\n\nPartial Homomorphic Encryption (PHE): another case of the trade-off between model utility and security & privacy in FL is adopting partial homomorphic encryption (PHE) in vertical federated logistic regression (LR)[54], in which PHE is utilized to protect the intermediate results. Since PHE cannot support non-linear functions (e.g., Sigmoid activation function), Taylor polynomials are used to approximate the non-linear functions, which bring nonnegligible loss of model utility.\n\nBased on our survey, we highly recommend new FL algorithm or systems to perform a comprehensive analysis on all the goals, including security and privacy, utility, and efficiency, for two reasons: 1) comprehensive analysis is the foundation of a fair comparison, and 2) comprehensive analysis is the key to find all the limitations before applied in real-world applications. Specifically, the comparison between different FL studies on partial goals is unfair because different goals form trade-offs and superiority in partial goals does not mean superiority in all goals. For instance, many works do not analyze privacy protection, which will bring unfair efficiency comparisons. Because FL algorithms’ efficiency varies greatly under different privacy-protection methods. For example, differential privacy (DP) and homomorphic encryption (HE) employ different privacy mechanisms and have very different efficiencies. However, claiming the DP-based method is much more efficient than the HE-based method as a major innovation is problematic without understanding their relative privacy guarantees. The major disadvantage of DP is that it harms model utility while HE does not. Comprehensive analysis is also essential to thoroughly assess one algorithm or system and discover all the limitations, such that the issue (e.g., privacy or efficiency problems) could be fixed before being applied in real-world applications.\n\nThe major challenge of performing comprehensive analysis is the workload required for evaluations. To address this, we propose two solutions: 1) We develop a standardized evaluation platform, FedEval, to produce comparable and comprehensive results while reducing evaluation workload, and the detailed is introducedSectionIV; 2) For incremental methods that only improve one or two goals based on an existing solution, another option is to analyze that the remaining goals have identical performance to prior studies that already reported comprehensive evaluation results. However, if the remaining goals were also not previously evaluated, assessments across all goals remain necessary.\n\n\n================================================================================\nII-AGoal 1: Utility\n================================================================================\nFL generally learns a model based on data from multiple parties without directly collecting data together to meet data protection requirements in many laws and regulations.\nHence, the primary goal is to obtain a federated model with almost the same predictive power as the model directly trained from all parties’ data to ensure the highutilityof the FL model.\nWe discuss utility from two aspects:effectivenessandrobustness.\n\nGoal 1.1: Effectiveness. FL aims to train a global model collaboratively using data distributed across participants. Ideally, the FL training should be able to achieve the same prediction accuracy as centralized training (i.e., collecting all the data in one place).\nFor the FL system that can approximate a centralized model’s predictive power, we then call this FL system withhigh effectiveness.\n\nGoal 1.2: Robustness. In practice, FL systems cannot always run in an ideal experimental environment, and various incidents may occasionally happen.\nHence, a comprehensive evaluation of the FL system should pre-define such scenarios as much as possible to reflect the system’srobustnessin practice.\nIn particular, many participants indicate a significant disparity in devices. Data distributions, communication networks (3G, 4G, WiFi), computing resources (CPU, GPU),etc, may vary among parties. These diversities and uncertainties could cause issues that significantly affect the FL system[36].\n\n\n================================================================================\nII-BGoal 2: Efficiency\n================================================================================\nUnlike conventional distributed machine learning, which is carried out on different machines in one data center[37], FL is performed on cross-data-center machines or edge devices, which have lower networking or computing resources[36].\nConsequently, a deep neural network that could be trained in minutes using centralized machines may take hours to finish the training in FL[38]. Thus, efficiency is essential in FL and needs to be carefully evaluated.\nBased on existing works, we categorize the efficiency evaluation into two aspects:communicationefficiency andcomputationefficiency.\n\nGoal 2.1: Communication Efficiency. In HFL, the edge devices have limited networking resources,e.g., low bandwidth and high latency, making the communication between the server and devices expensive[36]. In VFL, the federation usually consists of machines from different data centers (i.e., from different companies). The cross-data-center communication is slow and has high latency[39]. Moreover, each party, in both HFL and VFL, may join more than one federation, and the FL training tasks from different federations will compete for resources[9,40], making the communication efficiency issue more severe.\n\nGoal 2.2: Computation Efficiency. In HFL, although the edge devices tend to have more powerful hardware, they still cannot match the ability of centralized computing servers, especially when dealing with large models[41]. Thus, the low computation efficiency problem cannot be dismissed in the federated learning scenario. Moreover, different parties often hold distinct computation resources, which may incur significant differences in computation speed between parties[42]. This can further impact the whole FL method’s efficiency in a complicated manner.\n\n\n================================================================================\nII-CGoal 3: Security & Privacy\n================================================================================\nSecurity and privacy are the foundation of FL systems. HFL algorithms,e.g., FedAvg, perform aggregation on model parameters, and the risk of private data leakage can be reduced since the users’ data never leaves their devices. However, recent works have shown that gradients can reveal input data and labels[43,44]. Apart from the private data leakage threats to data holders, there are also model security threats to model users. Malicious edge parties could use data poisoning or model poisoning attacks to damage or backdoor the model. Specifically, FL is often expected to achieve the following two security and privacy goals:\n\nGoal 3.1: Data Privacy. FL enables different parties to jointly train machine learning models without exchanging raw data, and only intermediate results are exchanged. However, recent works have shown that the intermediate results (e.g., gradients) could be used to recover FL parties’ private data[43,44]when no privacy-preserving techniques are adopted (e.g., homomorphic encryption), resulting in the data privacy issue.Goal 3.2: Model Security. Federated learning happens over a bunch of distributed parties (e.g., mobile devices), and there is no root of trust in existing methods,i.e., every party could be malicious from the model users’ perspective. Thus, the participants could easily attack the model using poisoning methods, resulting in the model security issue[45,46].\n\n\n================================================================================\nII-DTrade-off between Utility, Efficiency, and Security & Privacy\n================================================================================\nIt is worth noting that an FL system may not simultaneously improve all the goals, includingutility,efficiency, andsecurity & privacy. While a new algorithm improves one goal, it remains essential to comprehensively evaluate performance on other goals as well since trade-offs exist between different goals. The comprehensive analysis helps determine whether an algorithm represents unambiguous progress over state-of-the-art solutions by improving one aspect without detriment to others or gains on one goal induce losses on others, reflecting an ambiguous contribution.\n\nTo this end, comprehensively evaluating an FL system from all three aspects becomes extremely important to deeply understand the advantages and disadvantages of FL systems (algorithms, models). Next, we would like to demonstrate more details about the trade-offs between the goals.\n\nUtility vs. Efficiency.Federated SGD (FedSGD) and Federated Average (FedAvg) are two mostly well-known FL methods proposed by Google[35]. FedSGD inherits the settings of large-batch synchronous SGD (the state-of-the-art machine learning method used in data centers). In FedSGD, all clients synchronize the gradients before updating the local model weights. In contrast, only part of the clients participate in each round of training in FedAvg and the clients perform multiple rounds of local training before the synchronization.\n\nFedSGD and FedAvg reveal the trade-off of utility and efficiency in FL. On the one hand, FedAvg improves communication efficiency (i.e., fewer communication rounds) by increasing clients’ local training rounds before the global synchronization. On the other hand, the increased clients’ local training rounds unexpectedly drift the global model away from the global optimum under heterogeneous data distributions, making FedAvg reach worse model utility than FedSGD.\n\nApart from FedSGD and FedAvg, there are also other FL studies that encounter the trade-off between utility and efficiency. For example, some studies utilize gradient compression techniques to improve communication efficiency[12]; however, the model utility may decrease since only partial model parameters are synchronized.\n\nEfficiency vs. Security & Privacy.While many privacy-preserving techniques are adopted in FL to enhance privacy and security protection, there is no free lunch.\nPrivacy protection generally downgrades the efficiency of the system.\n\nHomomorphic Encryption (HE): HE is a special encryption algorithm that enables us to perform computations directly on encrypted numbers without decryption. HE is widely applied in FL to protect the intermediate results,e.g., the gradients[47,48]. The encrypted numbers (i.e., ciphertext) bring the efficiency overhead in two aspects. First, the ciphertext consumes larger storage space than plaintext, which brings communication overhead. Second, the computation on ciphertext is more complicated than plaintext, which brings computation overhead.\n\nSecret Sharing (SS)[49]: SS is a secure multi-party computation framework, in which different participants secretly share their data among all participants. Each participant only holds one data partition, which leaks no private information about the raw data. Basic operations, like addition and multiplication, are defined under the partitioned data, and then computations like polynomial functions could be carried out. SS mainly brings communication overhead, especially when doing multiplication[50]. More specially, SS is very sensitive to the networking latency.\n\nSecure Aggregation (SA):\nSA is utilized in horizontal FL to combine the parameter updates from clients in a manner that protects the privacy of the individual client’s local updates from a semi-honest server[51].\nSA operates in a way similar to the addition operation in SS but with the added benefit of enhancing the resilience of the aggregation process when some clients may disconnect.\nSimilar to SS, SA also introduces communication overhead.\n\nIt is worth noting that, the above protection techniques can often be incorporated into various FL algorithms[35,52]to further enhance the protection level. Meanwhile, it would incur communication and/or computation overhead. Hence, in practice, the FL system designer should decide whether these extra protection methods are necessary according to the application scenario to balance efficiency and privacy protection.\n\nUtility vs. Security & Privacy.In addition to efficiency, some privacy-preserving techniques may also degrade the utility of FL systems.\n\nDifferential Privacy (DP): a well-known privacy-preserving technique adopted in FL is differential privacy (DP)[53]. Clients locally add DP noise to the data or model to protect the private data. DP-based FL solutions reveal the trade-off between model utility and privacy. Adding more noise will have better privacy preservation, however, will significantly downgrade the model’s utility.\n\nPartial Homomorphic Encryption (PHE): another case of the trade-off between model utility and security & privacy in FL is adopting partial homomorphic encryption (PHE) in vertical federated logistic regression (LR)[54], in which PHE is utilized to protect the intermediate results. Since PHE cannot support non-linear functions (e.g., Sigmoid activation function), Taylor polynomials are used to approximate the non-linear functions, which bring nonnegligible loss of model utility.\n\n\n================================================================================\nII-ENecessity of comprehensively analyzing all the goals.\n================================================================================\nBased on our survey, we highly recommend new FL algorithm or systems to perform a comprehensive analysis on all the goals, including security and privacy, utility, and efficiency, for two reasons: 1) comprehensive analysis is the foundation of a fair comparison, and 2) comprehensive analysis is the key to find all the limitations before applied in real-world applications. Specifically, the comparison between different FL studies on partial goals is unfair because different goals form trade-offs and superiority in partial goals does not mean superiority in all goals. For instance, many works do not analyze privacy protection, which will bring unfair efficiency comparisons. Because FL algorithms’ efficiency varies greatly under different privacy-protection methods. For example, differential privacy (DP) and homomorphic encryption (HE) employ different privacy mechanisms and have very different efficiencies. However, claiming the DP-based method is much more efficient than the HE-based method as a major innovation is problematic without understanding their relative privacy guarantees. The major disadvantage of DP is that it harms model utility while HE does not. Comprehensive analysis is also essential to thoroughly assess one algorithm or system and discover all the limitations, such that the issue (e.g., privacy or efficiency problems) could be fixed before being applied in real-world applications.\n\nThe major challenge of performing comprehensive analysis is the workload required for evaluations. To address this, we propose two solutions: 1) We develop a standardized evaluation platform, FedEval, to produce comparable and comprehensive results while reducing evaluation workload, and the detailed is introducedSectionIV; 2) For incremental methods that only improve one or two goals based on an existing solution, another option is to analyze that the remaining goals have identical performance to prior studies that already reported comprehensive evaluation results. However, if the remaining goals were also not previously evaluated, assessments across all goals remain necessary.\n\n\n================================================================================\nIIIFederated Learning Evaluation Measures\n================================================================================\nIn this section, we review existing evaluation measures for different goals, including utility, efficiency, and security & privacy.\nFor each goal, we introduce the commonly adopted evaluation measurements and factors considered in the literature.\n\nFor utility evaluation, we care about the predictive power of the obtained machine learning model. Adequate data is usually an indispensable condition for achieving satisfactory prediction accuracy, especially when deep learning is applied. However, such a condition usually cannot be satisfied in the real world due to privacy-preserving restrictions. Each data owner can only access their local data, also known as the isolated data islands problem[3]. FL systems should be able to break such isolation and achieve performance,FL Effectiveness, better thanLocal Effectiveness(i.e., training model locally without joining any federations).\nIn FL, we typically learn the global model by solving the following problem[35]:\n\nwhereN𝑁Nitalic_Nis the number of clients,pk≥0subscript𝑝𝑘0p_{k}\\geq 0italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ≥ 0and∑kpk=1subscript𝑘subscript𝑝𝑘1\\sum_{k}p_{k}=1∑ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = 1.Fk⁢(w)subscript𝐹𝑘𝑤F_{k}(w)italic_F start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_w )is defined as the empirical loss over the local data samples,i.e.,Fk⁢(w)=1nk⁢∑i=1nkli⁢(w)subscript𝐹𝑘𝑤1subscript𝑛𝑘superscriptsubscript𝑖1subscript𝑛𝑘subscript𝑙𝑖𝑤F_{k}(w)=\\frac{1}{n_{k}}\\sum_{i=1}^{n_{k}}l_{i}(w)italic_F start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_w ) = divide start_ARG 1 end_ARG start_ARG italic_n start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_w )[55], wherenksubscript𝑛𝑘n_{k}italic_n start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPTis the number of samples at thek𝑘kitalic_k-th party, and we setpk=nk/nsubscript𝑝𝑘subscript𝑛𝑘𝑛p_{k}=n_{k}/nitalic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = italic_n start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT / italic_nwheren=∑knk𝑛subscript𝑘subscript𝑛𝑘n=\\sum_{k}n_{k}italic_n = ∑ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT italic_n start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPTis the total number of samples.\n\nWe define the FL effectiveness as∑k=1Npk⋅A⁢c⁢c⁢(h⁢(w,xk),yk)superscriptsubscript𝑘1𝑁normal-⋅subscript𝑝𝑘𝐴𝑐𝑐ℎ𝑤subscript𝑥𝑘subscript𝑦𝑘\\sum_{k=1}^{N}p_{k}\\cdot Acc(h(w,x_{k}),y_{k})∑ start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ⋅ italic_A italic_c italic_c ( italic_h ( italic_w , italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) , italic_y start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ), wherew𝑤witalic_wis the model parameter learned from Equation1,h⁢(w,xk)ℎ𝑤subscript𝑥𝑘h(w,x_{k})italic_h ( italic_w , italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT )outputs a probability distribution over the classes or categories that can be assigned toxk∼Dksimilar-tosubscript𝑥𝑘subscript𝐷𝑘x_{k}\\sim D_{k}italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ∼ italic_D start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT,A⁢c⁢c𝐴𝑐𝑐Accitalic_A italic_c italic_cfunction computes accuracy ofh⁢(w,xk)ℎ𝑤subscript𝑥𝑘h(w,x_{k})italic_h ( italic_w , italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT )regarding the labelyksubscript𝑦𝑘y_{k}italic_y start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT, and we setpk=nk/nsubscript𝑝𝑘subscript𝑛𝑘𝑛p_{k}=n_{k}/nitalic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = italic_n start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT / italic_n.\n\nUsing the same notation in Definition1, we define the local effectiveness as∑k=1Npk⋅A⁢c⁢c⁢(h⁢(wk,xk),yk)superscriptsubscript𝑘1𝑁normal-⋅subscript𝑝𝑘𝐴𝑐𝑐ℎsubscript𝑤𝑘subscript𝑥𝑘subscript𝑦𝑘\\sum_{k=1}^{N}p_{k}\\cdot Acc(h(w_{k},x_{k}),y_{k})∑ start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ⋅ italic_A italic_c italic_c ( italic_h ( italic_w start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) , italic_y start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ), wherewksubscript𝑤𝑘w_{k}italic_w start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPTis the local model parameter learned by minimizing the local objective:wk=arg⁡minw⁡Fk⁢(w)subscript𝑤𝑘subscript𝑤subscript𝐹𝑘𝑤w_{k}=\\arg\\min_{w}F_{k}(w)italic_w start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = roman_arg roman_min start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT italic_F start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_w ), and we setpk=nk/nsubscript𝑝𝑘subscript𝑛𝑘𝑛p_{k}=n_{k}/nitalic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = italic_n start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT / italic_n.\n\nWe define the central effectiveness asA⁢c⁢c⁢(h⁢(w,x),y)𝐴𝑐𝑐ℎ𝑤𝑥𝑦Acc(h(w,x),y)italic_A italic_c italic_c ( italic_h ( italic_w , italic_x ) , italic_y ), wherew𝑤witalic_wis the model parameter trained byminw⁡F⁢(w):=𝔼x∼D⁢[f⁢(w,x)]assignsubscript𝑤𝐹𝑤subscript𝔼similar-to𝑥𝐷delimited-[]𝑓𝑤𝑥\\min_{w}F(w):=\\mathbb{E}_{x\\sim D}[f(w,x)]roman_min start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT italic_F ( italic_w ) := blackboard_E start_POSTSUBSCRIPT italic_x ∼ italic_D end_POSTSUBSCRIPT [ italic_f ( italic_w , italic_x ) ],x𝑥xitalic_xrepresents data that collected from all the clients, andD𝐷Ditalic_Dis the global data distribution.333Centralized data collection and training is only an ideal experimental situation that represents a theoretical accuracy upper bound. In reality, we usually cannot put all the data in one place due to the restriction of privacy regulations.\n\nEffectiveness. We can compareF⁢E𝐹𝐸FEitalic_F italic_EandC⁢E𝐶𝐸CEitalic_C italic_E/L⁢E𝐿𝐸LEitalic_L italic_Eto measure the improvement brought by FL. The definition of central effectiveness (i.e.,Definition3) follows accuracy definition from conventional machine learning,i.e., the ratio of correctly predicted samples in the whole evaluation dataset[56]. While the definitions of local effectiveness (LE) and FL effectiveness (FE) are more complicated since the data is distributed across the clients. Empirically, we can compute the effectiveness of each client and then aggregate all clients’ results[57,58,55,59,60,61,62,63,64,65,66,67,68,69,70,71,72]. One problem is how to set the aggregation weights, which intuitively have two approaches: uniform weights or weighted by the number of samples. Very few studies explain which approach they use in the evaluation, but we see both types of implementations when investigating the open-sourced code on GitHub (e.g.,[57]444https://github.com/desternylin/perfedused weights by sample and[58]555https://github.com/yaodongyu/TCTused uniform weights). Theoretically, these two types of weights are identical if all clients hold the same number of samples. However, the number of data samples held by each client could be very heterogeneous in real-world applications, making these two weights produce incompatible results. In this survey, we recommend using weights by the number of samples, the reasons are 1) weights by the number of samples matches the loss of FL[35], which is also weighted averaged by the number of training samples; 2) uniform weights could produce biased evaluation since the clients with very small amount of data may dominate the final accuracy; If the system is specifically optimized for clients with small amount of data, we recommend to report effectiveness for these clients separately, instead of mixing with other rich-data clients. In this survey, to produce standardized and compatible measures, we use weights by the number of samples to define the effectiveness of FL and local training, which is formulated inDefinition1andDefinition2.\n\nFE vs. CE. FL systems aim to obtain approximately the same accuracy as centralized machine learning systems, meaning thatF⁢E≤C⁢E𝐹𝐸𝐶𝐸FE\\leq CEitalic_F italic_E ≤ italic_C italic_Ein general cases. IfF⁢E≈C⁢E𝐹𝐸𝐶𝐸FE\\approx CEitalic_F italic_E ≈ italic_C italic_E, then the FL system demonstrates no significant decline in accuracy compared to centralized learning, which is often the optimal case for an FL algorithm.\n\nFE vs. LE. For a practically useful FL system,F⁢E𝐹𝐸FEitalic_F italic_Eshould be larger thanL⁢E𝐿𝐸LEitalic_L italic_E, meaning that FL gets performance improvements compared to learning only on local data. IfF⁢E≤L⁢E𝐹𝐸𝐿𝐸FE\\leq LEitalic_F italic_E ≤ italic_L italic_E, the FL system fails to leverage the distributed knowledge to improve the model performance and should not be used in the application.\n\nRobustness.\nIn practice, various factors may vary to impact the performance of FL systems. Hence, these factors need to be clearly configured to evaluate an FL system’s utility.\n\nNon-IID Data & Model Personalization. FL aims at fitting a model to data generated by different participants. Each participant collects the data in a non-IID manner across the network. The amount of data held by each participant may also significantly differ. The non-IID issue poses challenges to the training of FL. The model will be more difficult to reach convergence under non-IID data distribution, which could be further categorized into two main types[73].\n\nNon-IID feature setting: TheP⁢(y|x)𝑃conditional𝑦𝑥P(y|x)italic_P ( italic_y | italic_x )of different parties are the same while theP⁢(x)𝑃𝑥P(x)italic_P ( italic_x )are different. For example, in the FEMNIST dataset, different clients hold the same label space containing the same set of symbols, but they have different handwriting styles on the same symbols.\n\nNon-IID label setting: TheP⁢(x|y)𝑃conditional𝑥𝑦P(x|y)italic_P ( italic_x | italic_y )of different parties are the same while theP⁢(y)𝑃𝑦P(y)italic_P ( italic_y )are different. For instance, in the MNIST dataset, the non-IID data is usually simulated by allocating different labels to different parties[35]such thatP⁢(y)𝑃𝑦P(y)italic_P ( italic_y )are different while the feature distributions under the same label are the same.\n\nThese two non-IID settings may impact model performance differently, so it is desirable to consider both of them for a robustness experiment on an FL system.\nBesides, non-IID data distribution may also lead to the necessity ofmodel personalization,i.e., each party attempts to learn a personalized model suitable to its local data distribution for better utility. We can measure the effectiveness of personalization by comparing a personalized model with a non-personalized (global) one.\n\nStragglers. FL stragglers are defined as participants that fall behind the others regarding submitting the computation results[36]. FL stragglers could be caused by low computing power or small network bandwidth, which widely exist in practical FL system deployments. Suppose an FL system does not consider stragglers in its algorithm design (e.g., relying on a purely synchronous updating strategy). In that case, stragglers may bring significant utility loss to the FL system[74]. If the FL follows a synchronous updating strategy, the stragglers will bring large efficiency overhead to the system. In the evaluation, stragglers could be simulated using the random delay to a certain part of the participants. Then, evaluate how the system efficiency is affected by the stragglers.\n\nDropout. FL dropouts are defined as participants that fail to submit the computation results in training (e.g., out of battery)[36]. Dropouts could be caused by networking drop-off or system out of service. Dropouts unexpectedly change the data distribution during the FL training, which may cause a convergence issue.\nA typical way of evaluating dropouts is by simulating dropout clients in the system and observing the influence on model performance.\n\nExisting Works on Utility Evaluation.TableIoutlines representative FL studies and their evaluation measures for utility.\nOur analysis reveals that most studies have at least one experiment focused on utility, such as comparing FL prediction accuracy with centralized, local, or other baseline FL methods’ prediction accuracy.\nThis is particularly true for papers published in database and AI conferences, where utility is usually the primary evaluation goal. Meanwhile, regarding the robustness evaluation, most of the AI studies focused on evaluating the performance under the non-IID data and overlooked the evaluation of heterogeneous systems,i.e., when systems contain stragglers and dropouts. Specifically, only two papers[62,72]evaluated the heterogeneous system in the surveyed representative studies. Experiments on straggler and dropout impact primarily appear in system papers[38,41], while non-IID issues are mainly addressed by AI papers. One major reason is that the impact of non-IID data is usually modeled as a learning problem[74,60,103,104,71], and various solutions are proposed by AI studies. However, the system heterogeneity is an essential challenge in FL since real-world FL applications usually deal with millions of clients, making it challenging to coordinate[38,41], and the heterogeneous system could decrease both efficiency and utility[38]. Thus the evaluation of heterogeneous systems is overlooked by existing studies and should be strengthened in future studies.\n\nSince efficiency entails both communication and computation aspects, we provide an overview of their respective measures one by one.\n\nCommunication. Communication efficiency evaluation usually involves the following two metrics:\n\nCommunication Round (CR): CR measures how many rounds of communication are needed to jointly train a machine learning model from scratch to converge. Many research works draw CR-to-Accuracy curves to compare communication efficiency[35,74,109,110,111]. In some cases if the model requires a long time to converge, we can also fix a certain number of communication rounds and compare the accuracy[35,61]. For instance, we may fix the CR to 500, methodA𝐴Aitalic_Ahas better communication rounds efficiency than methodB𝐵Bitalic_BifA𝐴Aitalic_Ashows higher accuracy thanB𝐵Bitalic_Bafter 500 rounds of training.\n\nCommunication Amount (CA): CA measures the amount of data transmitted during the FL training. Less CA could reduce the burden brought by the limited network bandwidth. A frequently used evaluation method is plotting the CA-to-Accuracy curve, which shows how much data is transmitted when reaching a certain model accuracy[109,12].\n\nComputation. Computation efficiency evaluation typically employs the following two measures:\n\nTheoretical Complexity Analysis:FL carries out a privacy-preserving distributed model training, which unavoidably brings computation overhead. For example, FedAvg brings computation overhead regarding server aggregation. Apart from the computation overhead brought by the distributed training, the widely adopted privacy-preserving techniques in FL,e.g., homomorphic encryption, also bring large computation overhead and need careful analysis[112,48]. One fundamental method to evaluate computational efficiency is doing computation complexity analysis. MethodA𝐴Aitalic_Ais better thanB𝐵Bitalic_BifA𝐴Aitalic_Ahas a lower order of computation complexity.\n\nTime Consumption:Apart from the complexity analysis, experimental time consumption results are also frequently used to evaluate the efficiency of FL methods. Generally, we can draw a time-to-accuracy curve to compare the time consumption of different methods when reaching the same model performance[38,106]. It is worth noting that computation time is influenced by the software and hardware environments.\nSome studies also report the time consumption by considering both communication and computation,i.e., the total time consumption of an FL system[113].\nThus, when reviewing an FL paper’s time consumption results, it is crucial to comprehend how time consumption is calculated.\n\nFL applications can involve numerous participants, such as Google’s federated mobile keyboard prediction with millions of participants[35].\nHence, To evaluate the practical efficiency of an FL system, conducting large-scale participant experiments may be necessary.\nAn ideal solution would be to conduct experiments directly on a large number of devices, where each device represents a participant.\nHowever, only a few research institutions have the capacity to maintain and conduct evaluations on a large number of devices.\nA practical alternative is simulating all participants using a few computing servers.\nSpecifically, virtual machine techniques, such asDockercontainers[114], are commonly used to simulate multiple FL participants on a single server.\nIt is also important to note that some efficiency measurements (e.g., time consumption) can be affected by the hardware and software used in developing and deploying the system.\nTherefore, when conducting a comprehensive efficiency evaluation of FL systems, it is important to configure experiment parameters (e.g., network bandwidth) during simulation.\n\nExisting Works on Efficiency Evaluation.TableIIlists the efficiency evaluation considerations in representative studies. Most of the studies report efficiency evaluation regarding communication or computation since efficiency is an essential metric that highly affects the practicality of FL methods. It is worth noting that about 75% of the surveyed representative FL studies do not evaluate efficiency regarding both communication and computation, which could lead to biased conclusions regarding the efficiency of FL systems. For example, communication rounds are commonly used as an efficiency metric in literature, but they may not always reflect the overall efficiency of the FL method. In particular, increasing local training rounds for every update in FedAvg[35]can reduce communication rounds but may not decrease overall time consumption, as it requires more local computation time for each party[115]. Another example that demonstrates the necessity of considering communication and computation simultaneously in the efficiency evaluation is when comparing the efficiency of two different privacy protection techniques: SS[116,78,94,66]and HE[48,94]. Intuitively, HE has higher computation complexity than SS but is more communication efficient than SS[117]. Biased efficiency comparison may happen if we compare HE and SS towards only one aspect of computation and communication. Regarding the number of clients used in the evaluation, we found that∼similar-to\\sim∼20% of studies used thousands of clients,∼similar-to\\sim∼20% used hundreds of clients, and∼similar-to\\sim∼60% used fewer than one hundred clients.\n\nThe evaluation of FL methods regarding security and privacy could be generally conducted from both theoretical and empirical aspects:\n\nTheoretical: Are there privacy proofs analyzing the security and privacy of proposed methods?\n\nEmpirical: Are there experiment results showing that the proposed methods can protect participants against existing attack methods?\n\nWhile theoretical analysis is a mathematically rigorous way of validating security and privacy protection, it is still rare in existing FL papers.666We investigated 60+ FL papers published on NeurIPS, ICML, ICLR, KDD, CCS, NDSS, OSDI,etc. in the last five years, and found that less than 10% provided rigorous proofs.In addition, security and privacy measures are typically evaluated in an adversarial manner, assuming certain types of attacks.\nCommon threats considered in existing literature include:\n\n[Data Privacy] Data Reconstruction Attacks.In FL, exchanging intermediate results is necessary for jointly training a machine learning model while keeping private data locally. Some pioneering FL studies leave these intermediate results unprotected, such as uploading local updates without protection in FedAvg[35].\nFollow-up studies have shown that raw private data could be recovered from these exchanged intermediate results, including gradients and model parameters[43,44,52,118,119]. Moreover, malicious participants may be able to reconstruct training data using model inversion attacks with only the final FL model[120,121].[Data Privacy] Inference Attack.: In some cases, the intermediate training results and the final FL models are not enough to recover raw data precisely, but some sensitive attributes can still be inferred. For instance, adversaries can utilize intermediate information to train an attack model that infers whether a party/sample participates in FL model training, which is known as membership inference attack[122,123].[Data Privacy] ID Leakage.In VFL, directly sending sample IDs and computing the intersection could leak sensitive information about a party’s customers. Hence, most VFL methods use private set intersection (PSI) for ID alignment[3]. However, PSI still leaks the sample IDs inside the intersection, revealing which users have registered accounts with other participants.\n\n[Model Security] Byzantine Attacks.Malicious parties can launch data or model poisoning attacks during the federated training process so as to downgrade the FL model’s performance, which is known asByzantine attacks[45].\nData poisoning attacks involve injecting malicious data samples before the learning process starts, while model poisoning attacks assume that adversaries can directly manipulate the model parameters sent from FL parties to the server.[Model Security] Backdoor Attacks.Backdoor attacksaim to control an FL model’s prediction for an attacker-chosen subtask[46]. Specifically, such attacks can cause a backdoored FL model to misclassify a data sample to an attacker-chosen label. In facial recognition applications, this could allow an attacker to generate a fake ID, posing significant security risks.\nDifferent from Byzantine attacks, backdoor attacks aim to modify the model’s behavior on a small portion of data without affecting the overall prediction accuracy significantly. Hence, backdoor attacks can be particularly challenging to detect since they often do not show up during normal FL evaluation and testing procedures.\n\nThreat Model.It is worth noting that a research paper on FL usually defends against only partial attacks from the above list. It is essential to first define what are the threats (i.e., the threat model) before analyzing the security & privacy. Typically, the following assumptions would be made for potential adversaries:\n\nSecurity Definition: The security definition defines the degree of honesty of participants. Generally, two types of security definitions are used in FL studies:\n\nHonest But Curious (Semi-Honest): The honest but curious setting, also known as semi-honest, assumes that the participants strictly adhere to the pre-defined protocol but attempt to learn as much information as possible from the received messages. This setting is commonly considered in security and privacy analyses presented in FL papers.\n\nMalicious: The malicious participants will not strictly follow the pre-defined protocol, and take any action to achieve their goal. To model malicious behavior during joint model training in FL, it is necessary to consider the specific threats that need to be protected against. However, defending against such parties is challenging, and only a few FL studies have considered them.\n\nCollusion Party Number: The ability of an FL system’s defense against attacks from a single party does not guarantee protection against collusion between multiple parties. Therefore, it is essential to consider the number of parties that could collude to conduct attacks when evaluating an FL system’s privacy and security levels.\n\nExisting Works on Security & Privacy Evaluation.TableIIIsummarizes the security and privacy evaluation measures in representative FL papers. It is notable that papers published in security conferences prioritize security and privacy evaluations.\nIn addition, database papers also give significant attention to security and privacy concerns in their method design.\nExisting work mainly has two approaches to evaluate data privacy: 1) Provide theoretically proofs to show that the solutions are differentially private (e.g.,[80,84,89,100]) or all the intermediate results are protected by HE (e.g.,[48]) and secret sharing (e.g.,[78,94,66]); 2) Perform empirical attack experiments to show that the solutions are secure against the state-of-the-art (SOTA) attacks (e.g.,[95,69]).\nRegarding the model security, existing studies also explored the evaluation in two ways: 1) Provide security analysis to show solutions’ ability to defend the attacks (e.g., the utility loss is bounded under the poisoning attacks[75,78,85]); 2) Perform empirically poisoning attacks to show the solutions’ utility loss under the attacks (e.g.,[45,83,95]).\nWe also observe that most FL papers presented at AI conferences do not explicitly discuss security and privacy issues.\nConsidering that security and privacy are primary motivations for developing FL systems, we suggest that AI papers should also give more attention to these concerns.\n\n\n================================================================================\nIII-AUtility Evaluation Measures\n================================================================================\nFor utility evaluation, we care about the predictive power of the obtained machine learning model. Adequate data is usually an indispensable condition for achieving satisfactory prediction accuracy, especially when deep learning is applied. However, such a condition usually cannot be satisfied in the real world due to privacy-preserving restrictions. Each data owner can only access their local data, also known as the isolated data islands problem[3]. FL systems should be able to break such isolation and achieve performance,FL Effectiveness, better thanLocal Effectiveness(i.e., training model locally without joining any federations).\nIn FL, we typically learn the global model by solving the following problem[35]:\n\nwhereN𝑁Nitalic_Nis the number of clients,pk≥0subscript𝑝𝑘0p_{k}\\geq 0italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ≥ 0and∑kpk=1subscript𝑘subscript𝑝𝑘1\\sum_{k}p_{k}=1∑ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = 1.Fk⁢(w)subscript𝐹𝑘𝑤F_{k}(w)italic_F start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_w )is defined as the empirical loss over the local data samples,i.e.,Fk⁢(w)=1nk⁢∑i=1nkli⁢(w)subscript𝐹𝑘𝑤1subscript𝑛𝑘superscriptsubscript𝑖1subscript𝑛𝑘subscript𝑙𝑖𝑤F_{k}(w)=\\frac{1}{n_{k}}\\sum_{i=1}^{n_{k}}l_{i}(w)italic_F start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_w ) = divide start_ARG 1 end_ARG start_ARG italic_n start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_w )[55], wherenksubscript𝑛𝑘n_{k}italic_n start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPTis the number of samples at thek𝑘kitalic_k-th party, and we setpk=nk/nsubscript𝑝𝑘subscript𝑛𝑘𝑛p_{k}=n_{k}/nitalic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = italic_n start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT / italic_nwheren=∑knk𝑛subscript𝑘subscript𝑛𝑘n=\\sum_{k}n_{k}italic_n = ∑ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT italic_n start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPTis the total number of samples.\n\nWe define the FL effectiveness as∑k=1Npk⋅A⁢c⁢c⁢(h⁢(w,xk),yk)superscriptsubscript𝑘1𝑁normal-⋅subscript𝑝𝑘𝐴𝑐𝑐ℎ𝑤subscript𝑥𝑘subscript𝑦𝑘\\sum_{k=1}^{N}p_{k}\\cdot Acc(h(w,x_{k}),y_{k})∑ start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ⋅ italic_A italic_c italic_c ( italic_h ( italic_w , italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) , italic_y start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ), wherew𝑤witalic_wis the model parameter learned from Equation1,h⁢(w,xk)ℎ𝑤subscript𝑥𝑘h(w,x_{k})italic_h ( italic_w , italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT )outputs a probability distribution over the classes or categories that can be assigned toxk∼Dksimilar-tosubscript𝑥𝑘subscript𝐷𝑘x_{k}\\sim D_{k}italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ∼ italic_D start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT,A⁢c⁢c𝐴𝑐𝑐Accitalic_A italic_c italic_cfunction computes accuracy ofh⁢(w,xk)ℎ𝑤subscript𝑥𝑘h(w,x_{k})italic_h ( italic_w , italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT )regarding the labelyksubscript𝑦𝑘y_{k}italic_y start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT, and we setpk=nk/nsubscript𝑝𝑘subscript𝑛𝑘𝑛p_{k}=n_{k}/nitalic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = italic_n start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT / italic_n.\n\nUsing the same notation in Definition1, we define the local effectiveness as∑k=1Npk⋅A⁢c⁢c⁢(h⁢(wk,xk),yk)superscriptsubscript𝑘1𝑁normal-⋅subscript𝑝𝑘𝐴𝑐𝑐ℎsubscript𝑤𝑘subscript𝑥𝑘subscript𝑦𝑘\\sum_{k=1}^{N}p_{k}\\cdot Acc(h(w_{k},x_{k}),y_{k})∑ start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ⋅ italic_A italic_c italic_c ( italic_h ( italic_w start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) , italic_y start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ), wherewksubscript𝑤𝑘w_{k}italic_w start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPTis the local model parameter learned by minimizing the local objective:wk=arg⁡minw⁡Fk⁢(w)subscript𝑤𝑘subscript𝑤subscript𝐹𝑘𝑤w_{k}=\\arg\\min_{w}F_{k}(w)italic_w start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = roman_arg roman_min start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT italic_F start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_w ), and we setpk=nk/nsubscript𝑝𝑘subscript𝑛𝑘𝑛p_{k}=n_{k}/nitalic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = italic_n start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT / italic_n.\n\nWe define the central effectiveness asA⁢c⁢c⁢(h⁢(w,x),y)𝐴𝑐𝑐ℎ𝑤𝑥𝑦Acc(h(w,x),y)italic_A italic_c italic_c ( italic_h ( italic_w , italic_x ) , italic_y ), wherew𝑤witalic_wis the model parameter trained byminw⁡F⁢(w):=𝔼x∼D⁢[f⁢(w,x)]assignsubscript𝑤𝐹𝑤subscript𝔼similar-to𝑥𝐷delimited-[]𝑓𝑤𝑥\\min_{w}F(w):=\\mathbb{E}_{x\\sim D}[f(w,x)]roman_min start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT italic_F ( italic_w ) := blackboard_E start_POSTSUBSCRIPT italic_x ∼ italic_D end_POSTSUBSCRIPT [ italic_f ( italic_w , italic_x ) ],x𝑥xitalic_xrepresents data that collected from all the clients, andD𝐷Ditalic_Dis the global data distribution.333Centralized data collection and training is only an ideal experimental situation that represents a theoretical accuracy upper bound. In reality, we usually cannot put all the data in one place due to the restriction of privacy regulations.\n\nEffectiveness. We can compareF⁢E𝐹𝐸FEitalic_F italic_EandC⁢E𝐶𝐸CEitalic_C italic_E/L⁢E𝐿𝐸LEitalic_L italic_Eto measure the improvement brought by FL. The definition of central effectiveness (i.e.,Definition3) follows accuracy definition from conventional machine learning,i.e., the ratio of correctly predicted samples in the whole evaluation dataset[56]. While the definitions of local effectiveness (LE) and FL effectiveness (FE) are more complicated since the data is distributed across the clients. Empirically, we can compute the effectiveness of each client and then aggregate all clients’ results[57,58,55,59,60,61,62,63,64,65,66,67,68,69,70,71,72]. One problem is how to set the aggregation weights, which intuitively have two approaches: uniform weights or weighted by the number of samples. Very few studies explain which approach they use in the evaluation, but we see both types of implementations when investigating the open-sourced code on GitHub (e.g.,[57]444https://github.com/desternylin/perfedused weights by sample and[58]555https://github.com/yaodongyu/TCTused uniform weights). Theoretically, these two types of weights are identical if all clients hold the same number of samples. However, the number of data samples held by each client could be very heterogeneous in real-world applications, making these two weights produce incompatible results. In this survey, we recommend using weights by the number of samples, the reasons are 1) weights by the number of samples matches the loss of FL[35], which is also weighted averaged by the number of training samples; 2) uniform weights could produce biased evaluation since the clients with very small amount of data may dominate the final accuracy; If the system is specifically optimized for clients with small amount of data, we recommend to report effectiveness for these clients separately, instead of mixing with other rich-data clients. In this survey, to produce standardized and compatible measures, we use weights by the number of samples to define the effectiveness of FL and local training, which is formulated inDefinition1andDefinition2.\n\nFE vs. CE. FL systems aim to obtain approximately the same accuracy as centralized machine learning systems, meaning thatF⁢E≤C⁢E𝐹𝐸𝐶𝐸FE\\leq CEitalic_F italic_E ≤ italic_C italic_Ein general cases. IfF⁢E≈C⁢E𝐹𝐸𝐶𝐸FE\\approx CEitalic_F italic_E ≈ italic_C italic_E, then the FL system demonstrates no significant decline in accuracy compared to centralized learning, which is often the optimal case for an FL algorithm.\n\nFE vs. LE. For a practically useful FL system,F⁢E𝐹𝐸FEitalic_F italic_Eshould be larger thanL⁢E𝐿𝐸LEitalic_L italic_E, meaning that FL gets performance improvements compared to learning only on local data. IfF⁢E≤L⁢E𝐹𝐸𝐿𝐸FE\\leq LEitalic_F italic_E ≤ italic_L italic_E, the FL system fails to leverage the distributed knowledge to improve the model performance and should not be used in the application.\n\nRobustness.\nIn practice, various factors may vary to impact the performance of FL systems. Hence, these factors need to be clearly configured to evaluate an FL system’s utility.\n\nNon-IID Data & Model Personalization. FL aims at fitting a model to data generated by different participants. Each participant collects the data in a non-IID manner across the network. The amount of data held by each participant may also significantly differ. The non-IID issue poses challenges to the training of FL. The model will be more difficult to reach convergence under non-IID data distribution, which could be further categorized into two main types[73].\n\nNon-IID feature setting: TheP⁢(y|x)𝑃conditional𝑦𝑥P(y|x)italic_P ( italic_y | italic_x )of different parties are the same while theP⁢(x)𝑃𝑥P(x)italic_P ( italic_x )are different. For example, in the FEMNIST dataset, different clients hold the same label space containing the same set of symbols, but they have different handwriting styles on the same symbols.\n\nNon-IID label setting: TheP⁢(x|y)𝑃conditional𝑥𝑦P(x|y)italic_P ( italic_x | italic_y )of different parties are the same while theP⁢(y)𝑃𝑦P(y)italic_P ( italic_y )are different. For instance, in the MNIST dataset, the non-IID data is usually simulated by allocating different labels to different parties[35]such thatP⁢(y)𝑃𝑦P(y)italic_P ( italic_y )are different while the feature distributions under the same label are the same.\n\nThese two non-IID settings may impact model performance differently, so it is desirable to consider both of them for a robustness experiment on an FL system.\nBesides, non-IID data distribution may also lead to the necessity ofmodel personalization,i.e., each party attempts to learn a personalized model suitable to its local data distribution for better utility. We can measure the effectiveness of personalization by comparing a personalized model with a non-personalized (global) one.\n\nStragglers. FL stragglers are defined as participants that fall behind the others regarding submitting the computation results[36]. FL stragglers could be caused by low computing power or small network bandwidth, which widely exist in practical FL system deployments. Suppose an FL system does not consider stragglers in its algorithm design (e.g., relying on a purely synchronous updating strategy). In that case, stragglers may bring significant utility loss to the FL system[74]. If the FL follows a synchronous updating strategy, the stragglers will bring large efficiency overhead to the system. In the evaluation, stragglers could be simulated using the random delay to a certain part of the participants. Then, evaluate how the system efficiency is affected by the stragglers.\n\nDropout. FL dropouts are defined as participants that fail to submit the computation results in training (e.g., out of battery)[36]. Dropouts could be caused by networking drop-off or system out of service. Dropouts unexpectedly change the data distribution during the FL training, which may cause a convergence issue.\nA typical way of evaluating dropouts is by simulating dropout clients in the system and observing the influence on model performance.\n\nExisting Works on Utility Evaluation.TableIoutlines representative FL studies and their evaluation measures for utility.\nOur analysis reveals that most studies have at least one experiment focused on utility, such as comparing FL prediction accuracy with centralized, local, or other baseline FL methods’ prediction accuracy.\nThis is particularly true for papers published in database and AI conferences, where utility is usually the primary evaluation goal. Meanwhile, regarding the robustness evaluation, most of the AI studies focused on evaluating the performance under the non-IID data and overlooked the evaluation of heterogeneous systems,i.e., when systems contain stragglers and dropouts. Specifically, only two papers[62,72]evaluated the heterogeneous system in the surveyed representative studies. Experiments on straggler and dropout impact primarily appear in system papers[38,41], while non-IID issues are mainly addressed by AI papers. One major reason is that the impact of non-IID data is usually modeled as a learning problem[74,60,103,104,71], and various solutions are proposed by AI studies. However, the system heterogeneity is an essential challenge in FL since real-world FL applications usually deal with millions of clients, making it challenging to coordinate[38,41], and the heterogeneous system could decrease both efficiency and utility[38]. Thus the evaluation of heterogeneous systems is overlooked by existing studies and should be strengthened in future studies.\n\n\n================================================================================\nIII-BEfficiency Evaluation Measures\n================================================================================\nSince efficiency entails both communication and computation aspects, we provide an overview of their respective measures one by one.\n\nCommunication. Communication efficiency evaluation usually involves the following two metrics:\n\nCommunication Round (CR): CR measures how many rounds of communication are needed to jointly train a machine learning model from scratch to converge. Many research works draw CR-to-Accuracy curves to compare communication efficiency[35,74,109,110,111]. In some cases if the model requires a long time to converge, we can also fix a certain number of communication rounds and compare the accuracy[35,61]. For instance, we may fix the CR to 500, methodA𝐴Aitalic_Ahas better communication rounds efficiency than methodB𝐵Bitalic_BifA𝐴Aitalic_Ashows higher accuracy thanB𝐵Bitalic_Bafter 500 rounds of training.\n\nCommunication Amount (CA): CA measures the amount of data transmitted during the FL training. Less CA could reduce the burden brought by the limited network bandwidth. A frequently used evaluation method is plotting the CA-to-Accuracy curve, which shows how much data is transmitted when reaching a certain model accuracy[109,12].\n\nComputation. Computation efficiency evaluation typically employs the following two measures:\n\nTheoretical Complexity Analysis:FL carries out a privacy-preserving distributed model training, which unavoidably brings computation overhead. For example, FedAvg brings computation overhead regarding server aggregation. Apart from the computation overhead brought by the distributed training, the widely adopted privacy-preserving techniques in FL,e.g., homomorphic encryption, also bring large computation overhead and need careful analysis[112,48]. One fundamental method to evaluate computational efficiency is doing computation complexity analysis. MethodA𝐴Aitalic_Ais better thanB𝐵Bitalic_BifA𝐴Aitalic_Ahas a lower order of computation complexity.\n\nTime Consumption:Apart from the complexity analysis, experimental time consumption results are also frequently used to evaluate the efficiency of FL methods. Generally, we can draw a time-to-accuracy curve to compare the time consumption of different methods when reaching the same model performance[38,106]. It is worth noting that computation time is influenced by the software and hardware environments.\nSome studies also report the time consumption by considering both communication and computation,i.e., the total time consumption of an FL system[113].\nThus, when reviewing an FL paper’s time consumption results, it is crucial to comprehend how time consumption is calculated.\n\nFL applications can involve numerous participants, such as Google’s federated mobile keyboard prediction with millions of participants[35].\nHence, To evaluate the practical efficiency of an FL system, conducting large-scale participant experiments may be necessary.\nAn ideal solution would be to conduct experiments directly on a large number of devices, where each device represents a participant.\nHowever, only a few research institutions have the capacity to maintain and conduct evaluations on a large number of devices.\nA practical alternative is simulating all participants using a few computing servers.\nSpecifically, virtual machine techniques, such asDockercontainers[114], are commonly used to simulate multiple FL participants on a single server.\nIt is also important to note that some efficiency measurements (e.g., time consumption) can be affected by the hardware and software used in developing and deploying the system.\nTherefore, when conducting a comprehensive efficiency evaluation of FL systems, it is important to configure experiment parameters (e.g., network bandwidth) during simulation.\n\nExisting Works on Efficiency Evaluation.TableIIlists the efficiency evaluation considerations in representative studies. Most of the studies report efficiency evaluation regarding communication or computation since efficiency is an essential metric that highly affects the practicality of FL methods. It is worth noting that about 75% of the surveyed representative FL studies do not evaluate efficiency regarding both communication and computation, which could lead to biased conclusions regarding the efficiency of FL systems. For example, communication rounds are commonly used as an efficiency metric in literature, but they may not always reflect the overall efficiency of the FL method. In particular, increasing local training rounds for every update in FedAvg[35]can reduce communication rounds but may not decrease overall time consumption, as it requires more local computation time for each party[115]. Another example that demonstrates the necessity of considering communication and computation simultaneously in the efficiency evaluation is when comparing the efficiency of two different privacy protection techniques: SS[116,78,94,66]and HE[48,94]. Intuitively, HE has higher computation complexity than SS but is more communication efficient than SS[117]. Biased efficiency comparison may happen if we compare HE and SS towards only one aspect of computation and communication. Regarding the number of clients used in the evaluation, we found that∼similar-to\\sim∼20% of studies used thousands of clients,∼similar-to\\sim∼20% used hundreds of clients, and∼similar-to\\sim∼60% used fewer than one hundred clients.\n\n\n================================================================================\nIII-CSecurity & Privacy Evaluation Measures\n================================================================================\nThe evaluation of FL methods regarding security and privacy could be generally conducted from both theoretical and empirical aspects:\n\nTheoretical: Are there privacy proofs analyzing the security and privacy of proposed methods?\n\nEmpirical: Are there experiment results showing that the proposed methods can protect participants against existing attack methods?\n\nWhile theoretical analysis is a mathematically rigorous way of validating security and privacy protection, it is still rare in existing FL papers.666We investigated 60+ FL papers published on NeurIPS, ICML, ICLR, KDD, CCS, NDSS, OSDI,etc. in the last five years, and found that less than 10% provided rigorous proofs.In addition, security and privacy measures are typically evaluated in an adversarial manner, assuming certain types of attacks.\nCommon threats considered in existing literature include:\n\n[Data Privacy] Data Reconstruction Attacks.In FL, exchanging intermediate results is necessary for jointly training a machine learning model while keeping private data locally. Some pioneering FL studies leave these intermediate results unprotected, such as uploading local updates without protection in FedAvg[35].\nFollow-up studies have shown that raw private data could be recovered from these exchanged intermediate results, including gradients and model parameters[43,44,52,118,119]. Moreover, malicious participants may be able to reconstruct training data using model inversion attacks with only the final FL model[120,121].[Data Privacy] Inference Attack.: In some cases, the intermediate training results and the final FL models are not enough to recover raw data precisely, but some sensitive attributes can still be inferred. For instance, adversaries can utilize intermediate information to train an attack model that infers whether a party/sample participates in FL model training, which is known as membership inference attack[122,123].[Data Privacy] ID Leakage.In VFL, directly sending sample IDs and computing the intersection could leak sensitive information about a party’s customers. Hence, most VFL methods use private set intersection (PSI) for ID alignment[3]. However, PSI still leaks the sample IDs inside the intersection, revealing which users have registered accounts with other participants.\n\n[Model Security] Byzantine Attacks.Malicious parties can launch data or model poisoning attacks during the federated training process so as to downgrade the FL model’s performance, which is known asByzantine attacks[45].\nData poisoning attacks involve injecting malicious data samples before the learning process starts, while model poisoning attacks assume that adversaries can directly manipulate the model parameters sent from FL parties to the server.[Model Security] Backdoor Attacks.Backdoor attacksaim to control an FL model’s prediction for an attacker-chosen subtask[46]. Specifically, such attacks can cause a backdoored FL model to misclassify a data sample to an attacker-chosen label. In facial recognition applications, this could allow an attacker to generate a fake ID, posing significant security risks.\nDifferent from Byzantine attacks, backdoor attacks aim to modify the model’s behavior on a small portion of data without affecting the overall prediction accuracy significantly. Hence, backdoor attacks can be particularly challenging to detect since they often do not show up during normal FL evaluation and testing procedures.\n\nThreat Model.It is worth noting that a research paper on FL usually defends against only partial attacks from the above list. It is essential to first define what are the threats (i.e., the threat model) before analyzing the security & privacy. Typically, the following assumptions would be made for potential adversaries:\n\nSecurity Definition: The security definition defines the degree of honesty of participants. Generally, two types of security definitions are used in FL studies:\n\nHonest But Curious (Semi-Honest): The honest but curious setting, also known as semi-honest, assumes that the participants strictly adhere to the pre-defined protocol but attempt to learn as much information as possible from the received messages. This setting is commonly considered in security and privacy analyses presented in FL papers.\n\nMalicious: The malicious participants will not strictly follow the pre-defined protocol, and take any action to achieve their goal. To model malicious behavior during joint model training in FL, it is necessary to consider the specific threats that need to be protected against. However, defending against such parties is challenging, and only a few FL studies have considered them.\n\nCollusion Party Number: The ability of an FL system’s defense against attacks from a single party does not guarantee protection against collusion between multiple parties. Therefore, it is essential to consider the number of parties that could collude to conduct attacks when evaluating an FL system’s privacy and security levels.\n\nExisting Works on Security & Privacy Evaluation.TableIIIsummarizes the security and privacy evaluation measures in representative FL papers. It is notable that papers published in security conferences prioritize security and privacy evaluations.\nIn addition, database papers also give significant attention to security and privacy concerns in their method design.\nExisting work mainly has two approaches to evaluate data privacy: 1) Provide theoretically proofs to show that the solutions are differentially private (e.g.,[80,84,89,100]) or all the intermediate results are protected by HE (e.g.,[48]) and secret sharing (e.g.,[78,94,66]); 2) Perform empirical attack experiments to show that the solutions are secure against the state-of-the-art (SOTA) attacks (e.g.,[95,69]).\nRegarding the model security, existing studies also explored the evaluation in two ways: 1) Provide security analysis to show solutions’ ability to defend the attacks (e.g., the utility loss is bounded under the poisoning attacks[75,78,85]); 2) Perform empirically poisoning attacks to show the solutions’ utility loss under the attacks (e.g.,[45,83,95]).\nWe also observe that most FL papers presented at AI conferences do not explicitly discuss security and privacy issues.\nConsidering that security and privacy are primary motivations for developing FL systems, we suggest that AI papers should also give more attention to these concerns.\n\n\n================================================================================\nIVFedEval: A Platform for FL System Evaluation\n================================================================================\nAfter reviewing existing FL studies, it is clear that a standard and easy-to-reproduce procedure for comprehensive evaluation of utility, efficiency, and security & privacy is still lacking.\nWe have developed an open-source platform calledFedEvalto standardize and simplify the evaluation of FL algorithms. An overview of our evaluation platform is presented inFigure2. To use FedEval, users only need to provide a single script that contains the necessary FL functions or callback functions, such as how the server aggregates the parameters from different clients, to evaluate a new FL algorithm or test new attack/defense methods. The platform consists of three key modules.\n\nData Config and theFedDatamodule: FedEval currently provides seven standard FL datasets, including MNIST, CIFAR10, CIFAR100, FEMNIST, CelebA, Sentiment140, and Shakespeare. Different data settings (e.g., non-IID data) can be implemented by changing the data configs. Self-defined data is also supported. We only need to inherit theFedDataclass and define theload_datafunction to add a new dataset, which will share the same processing functions with the built-in datasets.\n\nModel Config and theKeras.Modelmodule: Currently, three machine learning models are built inside our system, includingMLP,LeNet, andStackedLSTM. We use TensorFlow[124]as the backend, and all the models are made via subclassing the Keras model. Thus, adding new machine learning models is very simple in FedEval.\n\nRuntime Config and thestrategymodule: One of the essential components in FedEval is thestrategymodule, which defines the protocol of the federated training. Briefly, the FL strategy module supports the following customization:\n\nCustomized uploading message,i.e., which parameters are uploaded to the server from the clients.\n\nCustomized server aggregation method,e.g., weighted average.\n\nCustomized training method for clients,e.g., the clients’ model can be trained using regular gradient descent method or other solutions like knowledge distillation.\n\nCustomized method for incorporating the global and local model,e.g., one popularly used method is replacing the local model with the global one before training.\n\nCompared with conventional machine learning, the major challenge of obtaining standard FL evaluation metrics is how to appropriately simulate heterogeneous clients and capture metrics (e.g., communication costs) that reflect real-world conditions. We introduce the FedEval platform’s approach to addressing this challenge.\n\nParticipants and Network Simulation. A widely-used method for simulating multiple participants is using multiprocessing, but we think it has the following problems: 1) it is hard to control the hardware resources (e.g., CPU and memory) used by each process; 2) it is hard to evaluate the performance under different network settings (i.e., bandwidth and latency). Our solution is putting all the participants into different docker containers, in which the hardware resources used by each participant could be fully controlled, including the CPU, GPU, memory, disk storage,etc. The server and clients from different containers communicate through WebSocket. Container networks bridge the communication between containers. Under such an architecture design, it is easy to change the network settings (i.e., bandwidth and latency) by directly configuring the virtual network interface card (NIC).\n\nCommunication Evaluation. Communication size is an essential evaluation metric for FL algorithms since the participants in FL tend to have limited network bandwidth, and a large communication size may bring significant efficiency overhead. A naive solution for evaluating the communication size, which is used in many existing FL studies, is directly measuring the size of the transmitted objects in the memory, and many utility packages (e.g., the ”getsizeof()” function in Python) could be used. However, such evaluation implementation may have two issues: 1) Different packages usually have different results; 2) Not all the objects could be accurately assessed using this method. To solve these problems, we measure the communication size by directly collecting data from the virtual NIC, which automatically records the amount of data sent out and received. Compared with measuring the transmitted data size in memory, our solution is more accurate and significantly reduces the implementation complexity.\n\nTime Evaluation.\n The implementation of time evaluation in FL is challenging because it may have many variations based on different purposes. For example, apart from the overall time consumption in each training round, we would also like to provide other time consumption statistics to help the users improve the FL algorithms,e.g., the computation and communication time of the clients, the aggregation time at the server,etc. The naive implementation of these time evaluation metrics is complicated and requires significant modifications to the platform’s source code. Our solution is providing a flexible time evaluation by collecting a group of timestamps, through which multiple time evaluation metrics could be calculated. Specifically, as illustrated inFigure3, we put four timestamps in the platform, which are the time of server sends parameters (t1subscript𝑡1t_{1}italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT), clients receive parameters (t2subscript𝑡2t_{2}italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT), clients send parameters (t3subscript𝑡3t_{3}italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT), and server receives parameters (t4subscript𝑡4t_{4}italic_t start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT). Assuming we havek𝑘kitalic_kclients in the training, then{(t1i,t2i,t3i,t4i)|1≤i≤k}nsubscriptconditional-setsuperscriptsubscript𝑡1𝑖superscriptsubscript𝑡2𝑖superscriptsubscript𝑡3𝑖superscriptsubscript𝑡4𝑖1𝑖𝑘𝑛\\{(t_{1}^{i},t_{2}^{i},t_{3}^{i},t_{4}^{i})|1\\leq i\\leq k\\}_{n}{ ( italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT , italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT , italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT , italic_t start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT ) | 1 ≤ italic_i ≤ italic_k } start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPTrepresents all the timestamps collected in thei𝑖iitalic_i-th round. Different combinations of these timestamps have different meanings:\n\nClient computation time (average):1k⁢∑i=1k(t3i−t2i)1𝑘superscriptsubscript𝑖1𝑘superscriptsubscript𝑡3𝑖superscriptsubscript𝑡2𝑖\\frac{1}{k}\\sum_{i=1}^{k}(t_{3}^{i}-t_{2}^{i})divide start_ARG 1 end_ARG start_ARG italic_k end_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT - italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT ).\n\nServer aggregation time in then𝑛nitalic_n-th round:s⁢a=m⁢i⁢n⁢({t1i|1≤i≤k}n)−m⁢a⁢x⁢({t4i|1≤i≤k}n+1)𝑠𝑎𝑚𝑖𝑛subscriptconditional-setsuperscriptsubscript𝑡1𝑖1𝑖𝑘𝑛𝑚𝑎𝑥subscriptconditional-setsuperscriptsubscript𝑡4𝑖1𝑖𝑘𝑛1sa=min(\\{t_{1}^{i}|1\\leq i\\leq k\\}_{n})-max(\\{t_{4}^{i}|1\\leq i\\leq k\\}_{n+1})italic_s italic_a = italic_m italic_i italic_n ( { italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT | 1 ≤ italic_i ≤ italic_k } start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) - italic_m italic_a italic_x ( { italic_t start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT | 1 ≤ italic_i ≤ italic_k } start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT )\n\nReal-world time consumption in then𝑛nitalic_n-th round:m⁢i⁢n⁢({t1i|1≤i≤k}n)−m⁢i⁢n⁢({t1i|1≤i≤k}n+1)𝑚𝑖𝑛subscriptconditional-setsuperscriptsubscript𝑡1𝑖1𝑖𝑘𝑛𝑚𝑖𝑛subscriptconditional-setsuperscriptsubscript𝑡1𝑖1𝑖𝑘𝑛1min(\\{t_{1}^{i}|1\\leq i\\leq k\\}_{n})-min(\\{t_{1}^{i}|1\\leq i\\leq k\\}_{n+1})italic_m italic_i italic_n ( { italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT | 1 ≤ italic_i ≤ italic_k } start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) - italic_m italic_i italic_n ( { italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT | 1 ≤ italic_i ≤ italic_k } start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT )\n\nFederated time consumption in then𝑛nitalic_n-th round:s⁢a+m⁢a⁢x⁢({t4i−t1i|1≤i≤k}n)𝑠𝑎𝑚𝑎𝑥subscriptconditional-setsuperscriptsubscript𝑡4𝑖superscriptsubscript𝑡1𝑖1𝑖𝑘𝑛sa+max(\\{t_{4}^{i}-t_{1}^{i}|1\\leq i\\leq k\\}_{n})italic_s italic_a + italic_m italic_a italic_x ( { italic_t start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT - italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT | 1 ≤ italic_i ≤ italic_k } start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT )\n\nOur platform records all the timestamps and outputs the real-world and federated time consumption. The users can compute more metrics based on these timestamps.\n\nWith appropriate client simulation, resource control, and efficiency\n measurements, the other metrics could be easily obtained. For example, the straggler evaluation in the utility could also be done by allocating clients with heterogeneous computing or networking resources.\n The entire system is open-sourced, and the essential components, such as datasets, ML models, and FL strategies, can be easily used or self-defined.\nResearchers can easily implement their new FL method ideas and evaluate them with FedEval (e.g.,FedSVD[113]).\n\nTo demonstrate the usability of FedEval, we present its detailed workflow when evaluating customized algorithms inFigure3. As illustrated in the figure, the researchers can provide strategy functions to customize the behaviors of the FL algorithm,e.g., how the parameters are aggregated at the server and how to set the global updates to the local model. Meanwhile, the researchers can use customized callback functions to perform experiments of attacking and defending against the attacks. On the client side, we can use callback functions to poison the data before local training or poison the model before uploading local updates. On the server side, we can use callback functions to perform data-revealing attacks when receiving individual client updates and detect the poisoning updates before the aggregation. Due to the space limitation, we put the full description of the function interface of FedEval in the appendix.\n\nAn important characteristic of FedEval is its capability to evaluate an FL algorithm’s performance from a holistic perspective including utility, efficiency, and security & privacy. We have tested representative FL algorithms, including FedSGD[35], FedAvg[35], FedProx[74], FedOpt[110],etc.TableIVshows the utility evaluation of these four algorithms,i.e., comparing the effectiveness to local and central training and the effectiveness under non-IID data. The utility evaluation shows that all the tested FL algorithms have significantly better performance than local training and show a small decrease in accuracy compared to centralized training on most datasets. Regarding the robustness under non-IID data setting, FedProx has the best performance and yields the best average effectiveness under non-IID data, which matches the results reported from the original paper.Figure4shows the efficiency comparison of these four algorithms regarding the communication rounds, communication amounts, and time consumption. The efficiency evaluation shows that FedSGD tends to have worse efficiency compared to the other three algorithms, and FedOpt shows superior efficiency on a relatively large dataset (i.e., Shakespeare), which also matches the results report from the original paper.Figure6shows the data reconstruction attack[43]between FedSGD and FedAvg. Theoretically, FedProx and FedOpt have the same attack results as FedAvg since clients in these protocols upload the same information (i.e., parameters after multiple rounds of local updates) to the server.Figure6shows that FedAvg has better performance than FedSGD. The possible reason is that the parameters uploaded in FedAvg contain multiple rounds of local training while FedSGD only has one round of training, and the accumulated local updates in the parameters make it harder to recover the raw data.\n\nWhile the above table and figures independently present the evaluation results regarding utility, efficiency, and privacy, we also attempt to merge the evaluation results into one radar chat to provide an overview as well as highlight the strengths and weaknesses of each algorithm. The final results are presented in Figure5. We put the detailed methods for obtaining the radar charts on an online document777https://fedeval.readthedocs.io/en/latest/benchmark/benchmark.htmldue to the space limitation and ease of future updates,i.e., we will also continue evaluating more algorithms and the radar charts may also be updated accordingly. For more detail of FedEval,e.g., the interface design, please refer to our technical report[115]as well as the online document888https://fedeval.readthedocs.io/.\n\nIn summary, FedEval provides a flexible framework for researchers to produce standardized evaluation results that closely mimic real-world settings using the measurements summarized in this survey. FedEval also reduces the workload required for comprehensive analysis since researchers only need to define the FL workflow (i.e., through scripts), and evaluations can be automatically completed using the built-in metrics on the platform. While being a platform that makes a significant contribution to the evaluation of FL, FedEval also has two limitations. Firstly, while the platform provides good support for utility and efficiency evaluations, the attacks for privacy and security evaluation still need to be enriched. Secondly, the automated evaluation of vertical FL algorithms is currently not supported by FedEval. We will keep updating the platform in the future to solve these two limitations,i.e., adding more attacks regarding the privacy and security evaluation and adding support for the evaluation of vertical FL.\n\n\n================================================================================\nVFuture Directions\n================================================================================\nIn this section, we summarize several challenges and future research directions in FL evaluation.\n\nWhile existing works focus on one or two issues in FL, their evaluation results are also restricted to the corresponding areas. For example, FedAvg[35]tries to reduce the communication rounds by adding the number of clients’ local updates. However, the resulting increased local running time is not evaluated; non-IID issues are not thoroughly tested. FLTrust[75]proposed a Byzantine attack-robust FL framework by carefully verifying clients’ uploaded updates; however, individual updates for verification may bring the risk of private data leakage.\nAs trade-offs widely exist in FL system design (Sec.II-D), only a comprehensive evaluation process can help practitioners make the optimal decision on the design of practical FL systems and applications.\n\nAlthough the comprehensive evaluation gives us a thorough assessment of FL frameworks, comparing different FL studies is still very difficult because the existing evaluation metrics are incompatible.\nDifferent studies usually have different focuses in the evaluation. For example, modelA𝐴Aitalic_Aimproves the FL communication efficiency by 10%, and modelB𝐵Bitalic_Bimproves the FL computation efficiency by 15%. We cannot conclude that modelB𝐵Bitalic_Bis better than modelA𝐴Aitalic_Aand vice versa since none of these two metrics (i.e., communication and computation) are always more important than the other one in different applications.\n\nThus, we need a set of FL evaluation metrics that are commonly agreed to be compatible with different scenarios,i.e., a set ofstandardevaluation metrics.\nIn other words, FL studies could be compared using these standard metrics under different scenarios with no ambiguity.\n\nOne good example of a compatible metric is the energy and carbon footprint[125]since environmental wellness is one of the most important tasks of our society. FL models with fewer carbon emissions are better when achieving the same effectiveness.\n\nThe evaluation of FL systems should be a real-time and continuous process. Specifically, the evaluation system should have the following functionalities:\n\nUtility & Efficiency Evaluation: Requiring an easy-to-use evaluation interface and a group of benchmarking results (e.g., FL leaderboard). The system should enable researchers to evaluate new modes quickly,e.g., by uploading a simple script, and the system will automatically evaluate the new model. The evaluation results could be presented using a leaderboard, from which the researchers could quickly specify the state-of-the-art FL model and make performance comparisons.\n\nSecurity & Privacy Evaluation: Requiring a real-time and continuous verification to detect the attacks. Most of the FL studies use semi-honest security definitions, however, the security under the semi-honest assumption is not good enough for real-world applications because the parties that participated in the distributed training cannot fully trust each other,i.e., they will not believe that the others are semi-honest. Thus, real-time verification is essential to monitor each party’s behavior and detect malicious participants deviating from the protocol. Furthermore, as we mentioned in sectionSectionIII-C, private data leakage or model tampering may happen before, during, and after the FL training. Thus, security and privacy verification should be a real-time and continuous process.\n\nWhile not discussed in detail in this article, the incentive is also significant for FL, as parties work together only when incentives are designed satisfactorily. A suitable incentive mechanism in FL should satisfy the participants’ rationality, meaning that each party’s reward should be greater than the cost of joining the federation. Meanwhile, the parties with more contributions should gain more rewards to achieve fairness. There are also many other targets of designing an incentive mechanism for FL, such as reducing the delay in distributing rewards[9]. The evaluation plays a vital role in the incentive mechanism, especially when evaluating the participants’ contributions. Intuitively, one participant’s contribution could be evaluated by comparing the model performance when trained with and without its datasets,e.g., Shapley values[126]is often adopted. The evaluation system could incorporate real-time contribution evaluation and reward distribution to serve as an incentive mechanism.\n\nFL platforms are those frameworks that support simulating FL algorithms locally for research purposes or running FL in a distributed manner for industry applications. With the development of FL, many platforms have appeared:e.g., FATE[127], FedML[128], FedScale[129],etc. However, in real-world applications or research studies, it is usually hard for users to determine which platform is the best choice under a certain scenario. Thus, evaluating these platforms is essential to benchmark and compare their efficiency and effectiveness under different scenarios. Meanwhile, we can also perform attack experiments on those platforms to assess privacy protection and uncover potential privacy issues before utilizing them in real-world applications. Notably, we can extend the evaluation goals and measures in this survey from evaluating algorithms into platforms, containing utility, security & privacy, and efficiency. We discuss the extensibility of FedEval to evaluate different FL platforms in the appendix.\n\n\n================================================================================\nV-AA Comprehensive Evaluation Procedure\n================================================================================\nWhile existing works focus on one or two issues in FL, their evaluation results are also restricted to the corresponding areas. For example, FedAvg[35]tries to reduce the communication rounds by adding the number of clients’ local updates. However, the resulting increased local running time is not evaluated; non-IID issues are not thoroughly tested. FLTrust[75]proposed a Byzantine attack-robust FL framework by carefully verifying clients’ uploaded updates; however, individual updates for verification may bring the risk of private data leakage.\nAs trade-offs widely exist in FL system design (Sec.II-D), only a comprehensive evaluation process can help practitioners make the optimal decision on the design of practical FL systems and applications.\n\n\n================================================================================\nV-BStandard Evaluation Metrics\n================================================================================\nAlthough the comprehensive evaluation gives us a thorough assessment of FL frameworks, comparing different FL studies is still very difficult because the existing evaluation metrics are incompatible.\nDifferent studies usually have different focuses in the evaluation. For example, modelA𝐴Aitalic_Aimproves the FL communication efficiency by 10%, and modelB𝐵Bitalic_Bimproves the FL computation efficiency by 15%. We cannot conclude that modelB𝐵Bitalic_Bis better than modelA𝐴Aitalic_Aand vice versa since none of these two metrics (i.e., communication and computation) are always more important than the other one in different applications.\n\nThus, we need a set of FL evaluation metrics that are commonly agreed to be compatible with different scenarios,i.e., a set ofstandardevaluation metrics.\nIn other words, FL studies could be compared using these standard metrics under different scenarios with no ambiguity.\n\nOne good example of a compatible metric is the energy and carbon footprint[125]since environmental wellness is one of the most important tasks of our society. FL models with fewer carbon emissions are better when achieving the same effectiveness.\n\n\n================================================================================\nV-CReal-time and Continuous Evaluations\n================================================================================\nThe evaluation of FL systems should be a real-time and continuous process. Specifically, the evaluation system should have the following functionalities:\n\nUtility & Efficiency Evaluation: Requiring an easy-to-use evaluation interface and a group of benchmarking results (e.g., FL leaderboard). The system should enable researchers to evaluate new modes quickly,e.g., by uploading a simple script, and the system will automatically evaluate the new model. The evaluation results could be presented using a leaderboard, from which the researchers could quickly specify the state-of-the-art FL model and make performance comparisons.\n\nSecurity & Privacy Evaluation: Requiring a real-time and continuous verification to detect the attacks. Most of the FL studies use semi-honest security definitions, however, the security under the semi-honest assumption is not good enough for real-world applications because the parties that participated in the distributed training cannot fully trust each other,i.e., they will not believe that the others are semi-honest. Thus, real-time verification is essential to monitor each party’s behavior and detect malicious participants deviating from the protocol. Furthermore, as we mentioned in sectionSectionIII-C, private data leakage or model tampering may happen before, during, and after the FL training. Thus, security and privacy verification should be a real-time and continuous process.\n\n\n================================================================================\nV-DContribution Evaluation for Incentive Design\n================================================================================\nWhile not discussed in detail in this article, the incentive is also significant for FL, as parties work together only when incentives are designed satisfactorily. A suitable incentive mechanism in FL should satisfy the participants’ rationality, meaning that each party’s reward should be greater than the cost of joining the federation. Meanwhile, the parties with more contributions should gain more rewards to achieve fairness. There are also many other targets of designing an incentive mechanism for FL, such as reducing the delay in distributing rewards[9]. The evaluation plays a vital role in the incentive mechanism, especially when evaluating the participants’ contributions. Intuitively, one participant’s contribution could be evaluated by comparing the model performance when trained with and without its datasets,e.g., Shapley values[126]is often adopted. The evaluation system could incorporate real-time contribution evaluation and reward distribution to serve as an incentive mechanism.\n\n\n================================================================================\nV-EEvaluation on FL platforms\n================================================================================\nFL platforms are those frameworks that support simulating FL algorithms locally for research purposes or running FL in a distributed manner for industry applications. With the development of FL, many platforms have appeared:e.g., FATE[127], FedML[128], FedScale[129],etc. However, in real-world applications or research studies, it is usually hard for users to determine which platform is the best choice under a certain scenario. Thus, evaluating these platforms is essential to benchmark and compare their efficiency and effectiveness under different scenarios. Meanwhile, we can also perform attack experiments on those platforms to assess privacy protection and uncover potential privacy issues before utilizing them in real-world applications. Notably, we can extend the evaluation goals and measures in this survey from evaluating algorithms into platforms, containing utility, security & privacy, and efficiency. We discuss the extensibility of FedEval to evaluate different FL platforms in the appendix.\n\n\n================================================================================\nVIConclusion\n================================================================================\nIn this survey, we provide a comprehensive overview of the evaluation goals and measures for FL studies. We categorized the key evaluation goals into utility, efficiency, and security & privacy. For each goal, we reviewed commonly used metrics and evaluation methods from existing literature. We also discussed the necessity of conducting comprehensive evaluations across all goals due to the trade-offs between them. To facilitate such comprehensive analysis, we introduced FedEval, an open-source platform that simplifies implementing standardized FL evaluations.\n\nWe also summarized several open challenges and future directions for FL evaluations. First, establishing standardized evaluation metrics that are compatible with different scenarios would enable fairer comparisons between different FL solutions. Second, developing capabilities for real-time verification of efficiency, utility, and especially security would be highly valuable for practical deployments. Third, evaluating the contributions of participants could support the design of incentive mechanisms.\n\nOverall, as FL continues maturing from the research domain towards real-world applications, strong evaluation methodologies will play an indispensable role in ensuring system quality and user trust. We hope this survey provides a useful reference for future efforts in advancing FL evaluation.\n\n\n================================================================================\nAcknowledgments\n================================================================================\nThe work is supported by the Key-Area Research and Development Program of Guangdong Province (2021B0101400001), the Hong Kong RGC TRS T41-603/20R, the National Key Research and Development Program of China under Grant No.2018AAA0101100.\n\n",
      "stats": {
        "characters": 115563,
        "tokens": 23392,
        "lines": 534
      }
    }
  ]
}